{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GAN_mask_rcnn_cityscapes.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x___6nzE73IJ",
        "outputId": "d7f986e5-88a7-47a1-bc5a-6e8fc90ce59d"
      },
      "source": [
        "# or simply\n",
        "!nvidia-smi -L"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "GPU 0: Tesla T4 (UUID: GPU-b0031612-4d1e-f20e-7735-3e306741e5e9)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zZOFkFcX78Hb",
        "outputId": "77e2655c-5bdf-48d7-93f2-977f76cc3348"
      },
      "source": [
        "%%shell\n",
        "\n",
        "pip install cython\n",
        "# Install pycocotools, the version by default in Colab\n",
        "# has a bug fixed in https://github.com/cocodataset/cocoapi/pull/354\n",
        "pip install -U 'git+https://github.com/cocodataset/cocoapi.git#subdirectory=PythonAPI'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: cython in /usr/local/lib/python3.7/dist-packages (0.29.22)\n",
            "Collecting git+https://github.com/cocodataset/cocoapi.git#subdirectory=PythonAPI\n",
            "  Cloning https://github.com/cocodataset/cocoapi.git to /tmp/pip-req-build-b_ki_cb9\n",
            "  Running command git clone -q https://github.com/cocodataset/cocoapi.git /tmp/pip-req-build-b_ki_cb9\n",
            "Requirement already satisfied, skipping upgrade: setuptools>=18.0 in /usr/local/lib/python3.7/dist-packages (from pycocotools==2.0) (56.1.0)\n",
            "Requirement already satisfied, skipping upgrade: cython>=0.27.3 in /usr/local/lib/python3.7/dist-packages (from pycocotools==2.0) (0.29.22)\n",
            "Requirement already satisfied, skipping upgrade: matplotlib>=2.1.0 in /usr/local/lib/python3.7/dist-packages (from pycocotools==2.0) (3.2.2)\n",
            "Requirement already satisfied, skipping upgrade: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0) (2.8.1)\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.11 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0) (1.19.5)\n",
            "Requirement already satisfied, skipping upgrade: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0) (2.4.7)\n",
            "Requirement already satisfied, skipping upgrade: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0) (1.3.1)\n",
            "Requirement already satisfied, skipping upgrade: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0) (0.10.0)\n",
            "Requirement already satisfied, skipping upgrade: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib>=2.1.0->pycocotools==2.0) (1.15.0)\n",
            "Building wheels for collected packages: pycocotools\n",
            "  Building wheel for pycocotools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pycocotools: filename=pycocotools-2.0-cp37-cp37m-linux_x86_64.whl size=263916 sha256=c1b3e759f40aa6d8551827506bd307ae834f31668fea767faf2957ae9e24b83d\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-x__dzuj2/wheels/90/51/41/646daf401c3bc408ff10de34ec76587a9b3ebfac8d21ca5c3a\n",
            "Successfully built pycocotools\n",
            "Installing collected packages: pycocotools\n",
            "  Found existing installation: pycocotools 2.0.2\n",
            "    Uninstalling pycocotools-2.0.2:\n",
            "      Successfully uninstalled pycocotools-2.0.2\n",
            "Successfully installed pycocotools-2.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              ""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bH21pKco8Aer",
        "outputId": "349ac620-afa7-4167-db6f-46cad475f4c0"
      },
      "source": [
        "%%shell\n",
        "\n",
        "# Download TorchVision repo to use some files from\n",
        "# references/detection\n",
        "git clone https://github.com/pytorch/vision.git\n",
        "cd vision\n",
        "git checkout v0.3.0\n",
        "\n",
        "cp references/detection/utils.py ../\n",
        "cp references/detection/transforms.py ../\n",
        "cp references/detection/coco_eval.py ../\n",
        "#cp references/detection/engine.py ../\n",
        "cp references/detection/coco_utils.py ../"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'vision'...\n",
            "remote: Enumerating objects: 23788, done.\u001b[K\n",
            "remote: Counting objects: 100% (1260/1260), done.\u001b[K\n",
            "remote: Compressing objects: 100% (347/347), done.\u001b[K\n",
            "remote: Total 23788 (delta 911), reused 1188 (delta 889), pack-reused 22528\u001b[K\n",
            "Receiving objects: 100% (23788/23788), 30.84 MiB | 27.80 MiB/s, done.\n",
            "Resolving deltas: 100% (17602/17602), done.\n",
            "Note: checking out 'v0.3.0'.\n",
            "\n",
            "You are in 'detached HEAD' state. You can look around, make experimental\n",
            "changes and commit them, and you can discard any commits you make in this\n",
            "state without impacting any branches by performing another checkout.\n",
            "\n",
            "If you want to create a new branch to retain commits you create, you may\n",
            "do so (now or later) by using -b with the checkout command again. Example:\n",
            "\n",
            "  git checkout -b <new-branch-name>\n",
            "\n",
            "HEAD is now at be376084 version check against PyTorch's CUDA version\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              ""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4aaebi3c8DFE",
        "outputId": "a27fe522-97f4-4f3e-9860-0709fd141e88"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rj4e9n0A8FbK"
      },
      "source": [
        "# !cp '/content/drive/MyDrive/Thesis/Pythorch Mask-RCNN/coco_utils.py' ./\n",
        "!cp '/content/drive/MyDrive/Thesis/Pythorch Mask-RCNN/engine.py' ./"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GYiWUIDaDvCn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ebf4302c-f54e-42c1-9496-18563d96a552"
      },
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\n",
        "\n",
        "\"\"\"## Initial imports\"\"\"\n",
        "\n",
        "from __future__ import print_function\n",
        "#%matplotlib inline\n",
        "import argparse\n",
        "import os\n",
        "import random\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.parallel\n",
        "import torch.backends.cudnn as cudnn\n",
        "import torch.optim as optim\n",
        "import torch.utils.data\n",
        "import torchvision.datasets as dset\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.utils as vutils\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.animation as animation\n",
        "from IPython.display import HTML\n",
        "\n",
        "\"\"\"### install pycocotools\"\"\"\n",
        "\n",
        "# Commented out IPython magic to ensure Python compatibility.\n",
        "# %%shell\n",
        "# \n",
        "# pip install cython\n",
        "# # Install pycocotools, the version by default in Colab\n",
        "# # has a bug fixed in https://github.com/cocodataset/cocoapi/pull/354\n",
        "# pip install -U 'git+https://github.com/cocodataset/cocoapi.git#subdirectory=PythonAPI'\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# from .vision import VisionDataset\n",
        "from PIL import Image\n",
        "import os\n",
        "import os.path\n",
        "from typing import Any, Callable, Optional, Tuple, List\n",
        "\n",
        "from engine import train_one_epoch, evaluate\n",
        "import utils\n",
        "\n",
        "\"\"\"---\n",
        "\n",
        "## Load dataset CityScapes in COCO format using a custom class\n",
        "\"\"\"\n",
        "\n",
        "from pycocotools import mask as maskUtils\n",
        "\n",
        "\"\"\"### create a custom class to load properly the dataset CityScapes in coco format compatible with the train_one_epoch method\"\"\"\n",
        "\n",
        "from torchvision.datasets.vision import VisionDataset\n",
        "from pycocotools import mask as maskUtils\n",
        "\n",
        "class my_CocoDetection(VisionDataset):\n",
        "    \"\"\"`MS Coco Detection <https://cocodataset.org/#detection-2016>`_ Dataset.\n",
        "\n",
        "    Args:\n",
        "        root (string): Root directory where images are downloaded to.\n",
        "        annFile (string): Path to json annotation file.\n",
        "        transform (callable, optional): A function/transform that  takes in an PIL image\n",
        "            and returns a transformed version. E.g, ``transforms.ToTensor``\n",
        "        target_transform (callable, optional): A function/transform that takes in the\n",
        "            target and transforms it.\n",
        "        transforms (callable, optional): A function/transform that takes input sample and its target as entry\n",
        "            and returns a transformed version.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, root, annFile, transforms = None):\n",
        "        self.root = root\n",
        "        self.annFile = annFile\n",
        "        self.transforms = transforms\n",
        "\n",
        "            # root: str,\n",
        "            # annFile: str,\n",
        "            # do_transforms=None\n",
        "            # transform: Optional[Callable] = None,\n",
        "            # target_transform: Optional[Callable] = None,\n",
        "            # transforms: Optional[Callable] = None,\n",
        "    # ) -> None:\n",
        "    #     super(my_CocoDetection, self).__init__(root, annFile) #, transform, target_transform)\n",
        "        from pycocotools.coco import COCO\n",
        "        self.coco = COCO(annFile)\n",
        "        self.ids = list(sorted(self.coco.imgs.keys()))\n",
        "\n",
        "    def __getitem__(self, index: int) -> Tuple[Any, Any]:\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            index (int): Index\n",
        "\n",
        "        Returns:\n",
        "            tuple: Tuple (image, target). target is the object returned by ``coco.loadAnns``.\n",
        "        \"\"\"\n",
        "        coco = self.coco\n",
        "        img_id = self.ids[index]\n",
        "        ann_ids = coco.getAnnIds(imgIds=img_id)\n",
        "        target = coco.loadAnns(ann_ids)\n",
        "\n",
        "        path = coco.loadImgs(img_id)[0]['file_name']\n",
        "        img = Image.open(os.path.join(self.root, path)).convert('RGB')\n",
        "\n",
        "        # # resize the image to lower resolution\n",
        "        # img = img.resize((1024, 512))\n",
        "\n",
        "        width = img.size[0]\n",
        "        heigth = img.size[1]\n",
        "\n",
        "        boxes = []\n",
        "        masks = []\n",
        "        class_ids = []\n",
        "        image_id = index\n",
        "        iscrowd_list = []\n",
        "        areas = []\n",
        "\n",
        "        for elem in target:\n",
        "\n",
        "          if(len(elem['bbox'])<4):\n",
        "            print(\"!!!WARNING!! - found non 4 boxes for element\")\n",
        "            print(\"skipping to next image...\")\n",
        "            continue\n",
        "\n",
        "          # sort the box coordinates in the right order\n",
        "          xmin = elem['bbox'][0] \n",
        "          xmax = xmin + elem['bbox'][2 ]\n",
        "          ymin = elem['bbox'][1] \n",
        "          ymax = ymin + elem['bbox'][3] \n",
        "\n",
        "          # assert xmin < xmax, \"xmin should be less than xmax\"\n",
        "          # assert ymin < ymax, \"ymin should be less than ymax\"\n",
        "\n",
        "          boxes.append([xmin, ymin, xmax, ymax])\n",
        "\n",
        "          mask = self.annToMask(elem['segmentation'], heigth, width)\n",
        "          # # uncomment tp resize mask to match image size\n",
        "          # mask = Image.fromarray(mask) # convert np image in PIL\n",
        "          # mask = mask.resize((1024, 512)) # resize\n",
        "          # mask = np.array(mask) # convert back\n",
        "          masks.append(mask)\n",
        "          class_ids.append(elem['category_id'])\n",
        "          #image_ids.append(elem['image_id'])\n",
        "          iscrowd_list.append(elem['iscrowd'])\n",
        "          # compute area and append to list\n",
        "          areas.append(elem['area']) # np.int(elem['area']/4))\n",
        "\n",
        "        # convert everything into a torch.Tensor\n",
        "        boxes = torch.as_tensor(boxes, dtype=torch.float32)\n",
        "        masks = torch.as_tensor(masks, dtype=torch.uint8)\n",
        "        class_ids = torch.as_tensor(class_ids, dtype=torch.int64)\n",
        "        image_id = torch.tensor(image_id)\n",
        "        iscrowd_list = torch.as_tensor(iscrowd_list, dtype=torch.int64)\n",
        "        areas = torch.as_tensor(areas, dtype=torch.float32)\n",
        "\n",
        "        # changed the name inside brackets because this format is required\n",
        "        # in the train_one_epoch method\n",
        "        gt_instances = {}\n",
        "        gt_instances['boxes'] = boxes\n",
        "        gt_instances['masks'] = masks\n",
        "        gt_instances['labels'] = class_ids\n",
        "        gt_instances['image_id'] = image_id\n",
        "        gt_instances['iscrowd'] = iscrowd_list\n",
        "        gt_instances['area'] = areas\n",
        "\n",
        "\n",
        "        if self.transforms is not None:\n",
        "            img, gt_instances = self.transforms(img, gt_instances)\n",
        "\n",
        "        return img, gt_instances\n",
        "\n",
        "\n",
        "    def __len__(self) -> int:\n",
        "        return len(self.ids)\n",
        "\n",
        "\n",
        "    def annToRLE(self, ann, height, width):\n",
        "        \"\"\"\n",
        "        Convert annotation which can be polygons, uncompressed RLE to RLE.\n",
        "        :return: binary mask (numpy 2D array)\n",
        "        \"\"\"\n",
        "        segm = ann #ann['segmentation']\n",
        "        if isinstance(segm, list):\n",
        "            # polygon -- a single object might consist of multiple parts\n",
        "            # we merge all parts into one mask rle code\n",
        "            rles = maskUtils.frPyObjects(segm, height, width)\n",
        "            rle = maskUtils.merge(rles)\n",
        "        elif isinstance(segm['counts'], list):\n",
        "            # uncompressed RLE\n",
        "            rle = maskUtils.frPyObjects(segm, height, width)\n",
        "        else:\n",
        "            # rle\n",
        "            rle = ann['segmentation']\n",
        "        return rle\n",
        "\n",
        "    def annToMask(self, ann, height, width):\n",
        "        \"\"\"\n",
        "        Convert annotation which can be polygons, uncompressed RLE, or RLE to binary mask.\n",
        "        :return: binary mask (numpy 2D array)\n",
        "        \"\"\"\n",
        "        rle = self.annToRLE(ann, height, width)\n",
        "        m = maskUtils.decode(rle)\n",
        "        return m\n",
        "\n",
        "cityscapes_dataset = my_CocoDetection(root='/content/drive/MyDrive/Thesis/datasets/cityscapes', \n",
        "                                  annFile='/content/drive/MyDrive/Thesis/datasets/cityscapes/annotations/instancesonly_filtered_gtFine_train.json' )\n",
        "\n",
        "# print an instance to check data \n",
        "cityscapes_dataset[2]\n",
        "\n",
        "print(\"Image Count: {}\".format(len(cityscapes_dataset.ids)))\n",
        "\n",
        "# in results I obtain a tuple where the first element if the PIL image \n",
        "# corresponding to that dataset index, and the second element is a dictionary\n",
        "# containing all the field of the GT informations about the image, from \n",
        "# bbox to masks, class id etc.. \n",
        "results = cityscapes_dataset[2]\n",
        "results[0].size\n",
        "\n",
        "print(type(results[1]))\n",
        "results[1].keys()\n",
        "\n",
        "# plot the masks corresponding to the GT instances inside the image, \n",
        "# together with their classes\n",
        "\n",
        "gt_mask = results[1]['masks']\n",
        "gt_mask = gt_mask.mul(255).permute(1, 2, 0).byte().numpy()\n",
        "\n",
        "gt_classes = results[1]['labels']\n",
        "\n",
        "\n",
        "\"\"\"## Defining the model\"\"\"\n",
        "\n",
        "import torchvision\n",
        "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
        "from torchvision.models.detection.mask_rcnn import MaskRCNNPredictor\n",
        "\n",
        "      \n",
        "def get_instance_segmentation_model(num_classes):\n",
        "    # load an instance segmentation model pre-trained on COCO\n",
        "    model = torchvision.models.detection.maskrcnn_resnet50_fpn(pretrained=True)\n",
        "\n",
        "    # get the number of input features for the classifier\n",
        "    in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
        "    # replace the pre-trained head with a new one\n",
        "    model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
        "\n",
        "    # now get the number of input features for the mask classifier\n",
        "    in_features_mask = model.roi_heads.mask_predictor.conv5_mask.in_channels\n",
        "    hidden_layer = 256\n",
        "    # and replace the mask predictor with a new one\n",
        "    model.roi_heads.mask_predictor = MaskRCNNPredictor(in_features_mask,\n",
        "                                                       hidden_layer,\n",
        "                                                       num_classes)\n",
        "\n",
        "    return model\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "Let's write some helper functions for data augmentation / transformation, which leverages the functions in `refereces/detection` that we have just copied:\n",
        "\"\"\"\n",
        "\n",
        "from engine import train_one_epoch, evaluate\n",
        "import utils\n",
        "import transforms as T\n",
        "\n",
        "def get_transform(train):\n",
        "    transforms = []\n",
        "    # converts the image, a PIL image, into a PyTorch Tensor\n",
        "    transforms.append(T.ToTensor())\n",
        "    # if train:\n",
        "    #     # during training, randomly flip the training images\n",
        "    #     # and ground-truth for data augmentation\n",
        "    #     transforms.append(T.RandomHorizontalFlip(0.5))\n",
        "    return T.Compose(transforms)\n",
        "\n",
        "do_transform = get_transform(train=True)\n",
        "\n",
        "\"\"\"Now we have the dataset and the model, let's prepare them for training\"\"\"\n",
        "\n",
        "# use our dataset and defined transformations\n",
        "dataset = my_CocoDetection('/content/drive/MyDrive/Thesis/datasets/cityscapes', \n",
        "                          '/content/drive/MyDrive/Thesis/datasets/cityscapes/annotations/instancesonly_filtered_gtFine_train.json', \n",
        "                          get_transform(train=True))\n",
        "\n",
        "dataset_test = my_CocoDetection('/content/drive/MyDrive/Thesis/datasets/cityscapes', \n",
        "                              '/content/drive/MyDrive/Thesis/datasets/cityscapes/annotations/instancesonly_filtered_gtFine_train.json',\n",
        "                              get_transform(train=True))\n",
        "\n",
        "# split the dataset in train and test set\n",
        "torch.manual_seed(1)\n",
        "indices = torch.randperm(len(dataset)).tolist()\n",
        "\n",
        "dataset_train = torch.utils.data.Subset(dataset, indices[:300])\n",
        "dataset_test = torch.utils.data.Subset(dataset_test, indices[500:800])\n",
        "\n",
        "# define training and validation data loaders\n",
        "data_loader = torch.utils.data.DataLoader(\n",
        "    dataset_train, batch_size=1, shuffle=True, num_workers=2,\n",
        "    collate_fn=utils.collate_fn)\n",
        "\n",
        "\n",
        "data_loader_test = torch.utils.data.DataLoader(\n",
        "    dataset_test, batch_size=1, shuffle=True, num_workers=2,\n",
        "    collate_fn=utils.collate_fn)\n",
        "\n",
        "\n",
        "\n",
        "\"\"\"instantiate the model and the optimizer\"\"\"\n",
        "\n",
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "\n",
        "# our dataset has two classes only - background and person\n",
        "num_classes = 9\n",
        "\n",
        "# get the model using our helper function\n",
        "model = get_instance_segmentation_model(num_classes)\n",
        "# move model to the right device\n",
        "model.to(device)\n",
        "\n",
        "# construct an optimizer\n",
        "params = [p for p in model.parameters() if p.requires_grad]\n",
        "optimizer = torch.optim.SGD(params, lr=0.005,\n",
        "                            momentum=0.9, weight_decay=0.0005)\n",
        "\n",
        "# and a learning rate scheduler which decreases the learning rate by\n",
        "# 10x every 3 epochs\n",
        "lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer,\n",
        "                                               step_size=3,\n",
        "                                               gamma=0.1)\n",
        "\n",
        "## Load the pretrained model\n",
        "# PATH = \"/content/drive/MyDrive/Thesis/Pythorch Mask-RCNN/saved_models/maskrcnn_resnet50_cityscapes_300imgs_epoch_\"\n",
        "PATH = \"/content/drive/MyDrive/Thesis/Pythorch Mask-RCNN/saved_models_cityscapes/GAN_training_100%/generator/generator_300imgs_epoch_\"\n",
        "\n",
        "epoch = 12  # last epoch for which the model was saved\n",
        "checkpoint = torch.load(PATH+str(epoch))\n",
        "model.load_state_dict(checkpoint['model_state_dict'])\n",
        "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "\n",
        "epoch = checkpoint['epoch']\n",
        "\n",
        "model.train()\n",
        "\n",
        "print(\"model loaded at epoch\", str(epoch))\n",
        "\n",
        "\n",
        "\"\"\"Before iterating over the dataset, itâ€™s good to see what the model expects during training and inference time on sample data.\"\"\"\n",
        "\n",
        "# # for training\n",
        "# images,targets = next(iter(data_loader))\n",
        "# images = list(image for image in images)\n",
        "# targets = [{k: v for k, v in t.items()} for t in targets]\n",
        "# output = model(images,targets)   # Returns losses and detections\n",
        "# # for inference\n",
        "# model.eval()\n",
        "# x = [torch.rand(3, 300, 400), torch.rand(3, 500, 400)]\n",
        "# predictions = model(x)\n",
        "\n",
        "\"\"\"We are ready to train the model\"\"\"\n",
        "\n",
        "#PATH = \"./saved_models/maskrcnn_resnet50_cityscapes_500imgs_epoch_\"\n",
        "\n",
        "\n",
        "# if Commented the model has already been trained and saved\n",
        "\n",
        "# let's train it\n",
        "\n",
        "# do just one further epoch and then proceed with GAN training\n",
        "num_epochs = 1\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    # train for one epoch, printing every 10 iterations\n",
        "    train_one_epoch(model, optimizer, data_loader, device, epoch, print_freq=10)\n",
        "    # update the learning rate\n",
        "    lr_scheduler.step()\n",
        "\n",
        "    # if (epoch%3 == 0):\n",
        "    #   torch.save(model, PATH+str(epoch))\n",
        "\n",
        "    # # evaluate on the test dataset\n",
        "    # evaluate(model, data_loader_test, device=device)\n",
        "\n",
        "# torch.save({\n",
        "#             'epoch': epoch,\n",
        "#             'model_state_dict': model.state_dict(),\n",
        "#             'optimizer_state_dict': optimizer.state_dict(),\n",
        "#             #'loss': loss,\n",
        "#             }, PATH+str(epoch))\n",
        "\n",
        "\"\"\"---\n",
        "\n",
        "## Now that the model is saved, it can be loaded to do inference\n",
        "\"\"\"\n",
        "\n",
        "GPU = False\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "  GPU = True\n",
        "\n",
        "# --------- load with disctionary load:\n",
        "\"\"\"\n",
        "epoch = 1 # last epoch for ehich the model was saved\n",
        "\n",
        "model = get_instance_segmentation_model(num_classes)\n",
        "optimizer = optimizer = torch.optim.SGD(params, lr=0.005,\n",
        "                            momentum=0.9, weight_decay=0.0005)\n",
        "\n",
        "checkpoint = torch.load(PATH+str(epoch), map_location=device)\n",
        "model.load_state_dict(checkpoint['model_state_dict'])\n",
        "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "epoch = checkpoint['epoch']\n",
        "#loss = checkpoint['loss']\n",
        "\n",
        "# model.eval()\n",
        "# - or -\n",
        "model.train()\n",
        "\n",
        "print(\"model loaded\")\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "\n",
        "\"\"\"Printing the prediction shows that we have a list of dictionaries. Each element of the list corresponds to a different image. As we have a single image, there is a single dictionary in the list.\n",
        "The dictionary contains the predictions for the image we passed. In this case, we can see that it contains `boxes`, `labels`, `masks` and `scores` as fields.\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def compute_matches(gt_boxes, gt_class_ids, gt_masks,\n",
        "                  pred_boxes, pred_class_ids, pred_scores, pred_masks,\n",
        "                  iou_threshold=0.5, score_threshold=0.0):\n",
        "  \n",
        "  \"\"\"Finds matches between prediction and ground truth instances.\n",
        "  Returns:\n",
        "      gt_match: 1-D array. For each GT box it has the index of the matched\n",
        "                predicted box.\n",
        "      pred_match: 1-D array. For each predicted box, it has the index of\n",
        "                  the matched ground truth box.\n",
        "      overlaps: [pred_boxes, gt_boxes] IoU overlaps.\n",
        "  \"\"\"\n",
        "  # Trim zero padding\n",
        "  # TODO: cleaner to do zero unpadding upstream\n",
        "  gt_boxes = trim_zeros(gt_boxes)\n",
        "  gt_masks = gt_masks[..., :gt_boxes.shape[0]]\n",
        "  pred_boxes = trim_zeros(pred_boxes)\n",
        "  pred_scores = pred_scores[:pred_boxes.shape[0]]\n",
        "  # Sort predictions by score from high to low\n",
        "  indices = np.argsort(pred_scores)[::-1]\n",
        "  pred_boxes = pred_boxes[indices]\n",
        "  pred_class_ids = pred_class_ids[indices]\n",
        "  pred_scores = pred_scores[indices]\n",
        "  pred_masks = pred_masks[..., indices]\n",
        "\n",
        "  # Compute IoU overlaps [pred_masks, gt_masks]\n",
        "  overlaps = compute_overlaps_masks(pred_masks, gt_masks)\n",
        "\n",
        "  # Loop through predictions and find matching ground truth boxes\n",
        "  match_count = 0\n",
        "  pred_match = -1 * np.ones([pred_boxes.shape[0]])\n",
        "  gt_match = -1 * np.ones([gt_boxes.shape[0]])\n",
        "  for i in range(len(pred_boxes)):\n",
        "      # Find best matching ground truth box\n",
        "      # 1. Sort matches by score\n",
        "      sorted_ixs = np.argsort(overlaps[i])[::-1]\n",
        "      # 2. Remove low scores\n",
        "      low_score_idx = np.where(overlaps[i, sorted_ixs] < score_threshold)[0]\n",
        "      if low_score_idx.size > 0:\n",
        "          sorted_ixs = sorted_ixs[:low_score_idx[0]]\n",
        "      # 3. Find the match\n",
        "      for j in sorted_ixs:\n",
        "          # If ground truth box is already matched, go to next one\n",
        "          if gt_match[j] > -1:\n",
        "              continue\n",
        "          # If we reach IoU smaller than the threshold, end the loop\n",
        "          iou = overlaps[i, j]\n",
        "          if iou < iou_threshold:\n",
        "              break\n",
        "          # Do we have a match?\n",
        "          if pred_class_ids[i] == gt_class_ids[j]:\n",
        "              match_count += 1\n",
        "              gt_match[j] = i\n",
        "              pred_match[i] = j\n",
        "              break\n",
        "\n",
        "  return gt_match, pred_match, overlaps\n",
        "\n",
        "def trim_zeros(x):\n",
        "  \"\"\"It's common to have tensors larger than the available data and\n",
        "  pad with zeros. This function removes rows that are all zeros.\n",
        "  x: [rows, columns].\n",
        "  \"\"\"\n",
        "  assert len(x.shape) == 2\n",
        "  return x[~np.all(x == 0, axis=1)]\n",
        "\n",
        "\n",
        "def compute_overlaps_masks(masks1, masks2):\n",
        "    \"\"\"Computes IoU overlaps between two sets of masks.\n",
        "    masks1, masks2: [Height, Width, instances]\n",
        "    \"\"\"\n",
        "    \n",
        "    # If either set of masks is empty return empty result\n",
        "    if masks1.shape[-1] == 0 or masks2.shape[-1] == 0:\n",
        "        return np.zeros((masks1.shape[-1], masks2.shape[-1]))\n",
        "    # flatten masks and compute their areas\n",
        "    masks1 = np.reshape(masks1 > .5, (-1, masks1.shape[-1])).astype(np.float32)\n",
        "    masks2 = np.reshape(masks2 > .5, (-1, masks2.shape[-1])).astype(np.float32)\n",
        "    area1 = np.sum(masks1, axis=0)\n",
        "    area2 = np.sum(masks2, axis=0)\n",
        "\n",
        "    # intersections and union\n",
        "    intersections = np.dot(masks1.T, masks2)\n",
        "    union = area1[:, None] + area2[None, :] - intersections\n",
        "    overlaps = intersections / union\n",
        "\n",
        "    return overlaps\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "loading annotations into memory...\n",
            "Done (t=5.81s)\n",
            "creating index...\n",
            "index created!\n",
            "Image Count: 2975\n",
            "<class 'dict'>\n",
            "loading annotations into memory...\n",
            "Done (t=3.85s)\n",
            "creating index...\n",
            "index created!\n",
            "loading annotations into memory...\n",
            "Done (t=5.84s)\n",
            "creating index...\n",
            "index created!\n",
            "model loaded at epoch 12\n",
            "Epoch: [0]  [  0/300]  eta: 0:31:32  lr: 0.000001  loss: 1.1853 (1.1853)  loss_classifier: 0.2336 (0.2336)  loss_box_reg: 0.2634 (0.2634)  loss_mask: 0.2362 (0.2362)  loss_objectness: 0.0527 (0.0527)  loss_rpn_box_reg: 0.3994 (0.3994)  time: 6.3085  data: 5.4137  max mem: 1827\n",
            "Epoch: [0]  [ 10/300]  eta: 0:10:50  lr: 0.000008  loss: 0.8402 (0.7597)  loss_classifier: 0.1183 (0.1383)  loss_box_reg: 0.2634 (0.2525)  loss_mask: 0.2362 (0.2395)  loss_objectness: 0.0146 (0.0168)  loss_rpn_box_reg: 0.0470 (0.1126)  time: 2.2432  data: 1.8179  max mem: 2096\n",
            "Epoch: [0]  [ 20/300]  eta: 0:15:10  lr: 0.000014  loss: 0.8553 (0.8938)  loss_classifier: 0.1424 (0.1674)  loss_box_reg: 0.2952 (0.3057)  loss_mask: 0.2646 (0.2612)  loss_objectness: 0.0177 (0.0252)  loss_rpn_box_reg: 0.0483 (0.1343)  time: 3.0994  data: 2.7025  max mem: 2186\n",
            "Epoch: [0]  [ 30/300]  eta: 0:13:43  lr: 0.000021  loss: 0.8894 (0.8552)  loss_classifier: 0.1430 (0.1595)  loss_box_reg: 0.2953 (0.2915)  loss_mask: 0.2529 (0.2569)  loss_objectness: 0.0184 (0.0226)  loss_rpn_box_reg: 0.0944 (0.1247)  time: 3.4960  data: 3.1025  max mem: 2186\n",
            "Epoch: [0]  [ 40/300]  eta: 0:13:46  lr: 0.000028  loss: 0.8894 (0.8644)  loss_classifier: 0.1657 (0.1643)  loss_box_reg: 0.2915 (0.2929)  loss_mask: 0.2502 (0.2592)  loss_objectness: 0.0145 (0.0230)  loss_rpn_box_reg: 0.0887 (0.1251)  time: 3.0982  data: 2.7141  max mem: 2186\n",
            "Epoch: [0]  [ 50/300]  eta: 0:12:47  lr: 0.000034  loss: 0.8618 (0.8480)  loss_classifier: 0.1643 (0.1601)  loss_box_reg: 0.2943 (0.2857)  loss_mask: 0.2502 (0.2544)  loss_objectness: 0.0139 (0.0216)  loss_rpn_box_reg: 0.0844 (0.1262)  time: 3.1021  data: 2.7047  max mem: 2186\n",
            "Epoch: [0]  [ 60/300]  eta: 0:13:00  lr: 0.000041  loss: 0.9003 (0.8884)  loss_classifier: 0.1869 (0.1713)  loss_box_reg: 0.3201 (0.2971)  loss_mask: 0.2677 (0.2621)  loss_objectness: 0.0170 (0.0231)  loss_rpn_box_reg: 0.1032 (0.1349)  time: 3.4080  data: 2.9888  max mem: 2186\n",
            "Epoch: [0]  [ 70/300]  eta: 0:12:52  lr: 0.000048  loss: 1.0328 (0.8974)  loss_classifier: 0.2178 (0.1759)  loss_box_reg: 0.3219 (0.2957)  loss_mask: 0.2745 (0.2625)  loss_objectness: 0.0232 (0.0237)  loss_rpn_box_reg: 0.1731 (0.1396)  time: 4.0948  data: 3.6685  max mem: 2186\n",
            "Epoch: [0]  [ 80/300]  eta: 0:12:26  lr: 0.000054  loss: 1.0040 (0.9012)  loss_classifier: 0.1872 (0.1782)  loss_box_reg: 0.3083 (0.2992)  loss_mask: 0.2745 (0.2644)  loss_objectness: 0.0251 (0.0241)  loss_rpn_box_reg: 0.1203 (0.1352)  time: 3.8225  data: 3.4058  max mem: 2186\n",
            "Epoch: [0]  [ 90/300]  eta: 0:12:01  lr: 0.000061  loss: 0.9266 (0.8960)  loss_classifier: 0.1768 (0.1760)  loss_box_reg: 0.3358 (0.3004)  loss_mask: 0.2513 (0.2633)  loss_objectness: 0.0193 (0.0235)  loss_rpn_box_reg: 0.0493 (0.1328)  time: 3.6987  data: 3.2948  max mem: 2186\n",
            "Epoch: [0]  [100/300]  eta: 0:11:39  lr: 0.000068  loss: 0.8845 (0.8950)  loss_classifier: 0.1671 (0.1775)  loss_box_reg: 0.2846 (0.2979)  loss_mask: 0.2513 (0.2622)  loss_objectness: 0.0185 (0.0232)  loss_rpn_box_reg: 0.1300 (0.1341)  time: 3.9114  data: 3.5179  max mem: 2186\n",
            "Epoch: [0]  [110/300]  eta: 0:11:11  lr: 0.000074  loss: 0.8832 (0.8940)  loss_classifier: 0.1933 (0.1788)  loss_box_reg: 0.2816 (0.2950)  loss_mask: 0.2575 (0.2611)  loss_objectness: 0.0185 (0.0233)  loss_rpn_box_reg: 0.1378 (0.1358)  time: 4.0004  data: 3.5931  max mem: 2193\n",
            "Epoch: [0]  [120/300]  eta: 0:10:35  lr: 0.000081  loss: 0.8358 (0.8838)  loss_classifier: 0.1580 (0.1745)  loss_box_reg: 0.2228 (0.2896)  loss_mask: 0.2070 (0.2582)  loss_objectness: 0.0171 (0.0237)  loss_rpn_box_reg: 0.0750 (0.1378)  time: 3.6895  data: 3.2776  max mem: 2193\n",
            "Epoch: [0]  [130/300]  eta: 0:10:05  lr: 0.000088  loss: 0.6687 (0.8841)  loss_classifier: 0.1207 (0.1747)  loss_box_reg: 0.2049 (0.2875)  loss_mask: 0.2070 (0.2572)  loss_objectness: 0.0171 (0.0237)  loss_rpn_box_reg: 0.1050 (0.1410)  time: 3.7013  data: 3.2964  max mem: 2193\n",
            "Epoch: [0]  [140/300]  eta: 0:09:34  lr: 0.000094  loss: 0.9248 (0.8802)  loss_classifier: 0.1529 (0.1742)  loss_box_reg: 0.2660 (0.2843)  loss_mask: 0.2503 (0.2569)  loss_objectness: 0.0135 (0.0232)  loss_rpn_box_reg: 0.1540 (0.1417)  time: 3.9704  data: 3.5672  max mem: 2193\n",
            "Epoch: [0]  [150/300]  eta: 0:08:54  lr: 0.000101  loss: 0.8162 (0.8775)  loss_classifier: 0.1683 (0.1729)  loss_box_reg: 0.2660 (0.2826)  loss_mask: 0.2622 (0.2556)  loss_objectness: 0.0130 (0.0230)  loss_rpn_box_reg: 0.1039 (0.1434)  time: 3.5804  data: 3.1779  max mem: 2193\n",
            "Epoch: [0]  [160/300]  eta: 0:08:21  lr: 0.000108  loss: 0.7915 (0.8817)  loss_classifier: 0.1640 (0.1737)  loss_box_reg: 0.2839 (0.2832)  loss_mask: 0.2582 (0.2572)  loss_objectness: 0.0155 (0.0229)  loss_rpn_box_reg: 0.1039 (0.1448)  time: 3.5012  data: 3.0952  max mem: 2193\n",
            "Epoch: [0]  [170/300]  eta: 0:07:46  lr: 0.000114  loss: 0.8162 (0.8801)  loss_classifier: 0.1517 (0.1725)  loss_box_reg: 0.3059 (0.2818)  loss_mask: 0.2666 (0.2567)  loss_objectness: 0.0185 (0.0228)  loss_rpn_box_reg: 0.1054 (0.1463)  time: 3.8027  data: 3.4072  max mem: 2193\n",
            "Epoch: [0]  [180/300]  eta: 0:07:17  lr: 0.000120  loss: 0.8275 (0.8882)  loss_classifier: 0.1517 (0.1721)  loss_box_reg: 0.2887 (0.2825)  loss_mask: 0.2760 (0.2592)  loss_objectness: 0.0205 (0.0226)  loss_rpn_box_reg: 0.1293 (0.1518)  time: 4.2143  data: 3.8242  max mem: 2219\n",
            "Epoch: [0]  [190/300]  eta: 0:06:39  lr: 0.000127  loss: 0.9312 (0.8869)  loss_classifier: 0.1354 (0.1707)  loss_box_reg: 0.2749 (0.2808)  loss_mask: 0.2759 (0.2594)  loss_objectness: 0.0205 (0.0223)  loss_rpn_box_reg: 0.2150 (0.1537)  time: 3.9796  data: 3.5752  max mem: 2219\n",
            "Epoch: [0]  [200/300]  eta: 0:06:07  lr: 0.000134  loss: 0.8128 (0.8860)  loss_classifier: 0.1484 (0.1713)  loss_box_reg: 0.2675 (0.2786)  loss_mask: 0.2400 (0.2582)  loss_objectness: 0.0161 (0.0222)  loss_rpn_box_reg: 0.1986 (0.1557)  time: 3.9375  data: 3.5381  max mem: 2219\n",
            "Epoch: [0]  [210/300]  eta: 0:05:27  lr: 0.000141  loss: 0.6738 (0.8808)  loss_classifier: 0.1652 (0.1699)  loss_box_reg: 0.2549 (0.2766)  loss_mask: 0.2292 (0.2576)  loss_objectness: 0.0118 (0.0218)  loss_rpn_box_reg: 0.1605 (0.1549)  time: 3.6447  data: 3.2515  max mem: 2219\n",
            "Epoch: [0]  [220/300]  eta: 0:04:53  lr: 0.000147  loss: 0.8076 (0.8795)  loss_classifier: 0.1661 (0.1704)  loss_box_reg: 0.2590 (0.2765)  loss_mask: 0.2359 (0.2576)  loss_objectness: 0.0136 (0.0216)  loss_rpn_box_reg: 0.1122 (0.1535)  time: 3.5785  data: 3.1748  max mem: 2219\n",
            "Epoch: [0]  [230/300]  eta: 0:04:13  lr: 0.000154  loss: 0.7479 (0.8729)  loss_classifier: 0.1661 (0.1689)  loss_box_reg: 0.2377 (0.2737)  loss_mask: 0.2359 (0.2569)  loss_objectness: 0.0136 (0.0214)  loss_rpn_box_reg: 0.1011 (0.1520)  time: 3.5069  data: 3.1032  max mem: 2219\n",
            "Epoch: [0]  [240/300]  eta: 0:03:38  lr: 0.000161  loss: 0.7194 (0.8634)  loss_classifier: 0.1160 (0.1670)  loss_box_reg: 0.2076 (0.2704)  loss_mask: 0.2300 (0.2549)  loss_objectness: 0.0065 (0.0208)  loss_rpn_box_reg: 0.0902 (0.1502)  time: 3.2387  data: 2.8388  max mem: 2219\n",
            "Epoch: [0]  [250/300]  eta: 0:03:03  lr: 0.000167  loss: 0.7836 (0.8686)  loss_classifier: 0.1848 (0.1698)  loss_box_reg: 0.2536 (0.2720)  loss_mask: 0.2485 (0.2558)  loss_objectness: 0.0081 (0.0207)  loss_rpn_box_reg: 0.1046 (0.1503)  time: 4.2958  data: 3.8889  max mem: 2219\n",
            "Epoch: [0]  [260/300]  eta: 0:02:30  lr: 0.000174  loss: 0.9496 (0.8691)  loss_classifier: 0.1870 (0.1690)  loss_box_reg: 0.2718 (0.2709)  loss_mask: 0.2563 (0.2554)  loss_objectness: 0.0224 (0.0212)  loss_rpn_box_reg: 0.1450 (0.1525)  time: 5.2938  data: 4.8832  max mem: 2292\n",
            "Epoch: [0]  [270/300]  eta: 0:01:52  lr: 0.000181  loss: 0.8190 (0.8669)  loss_classifier: 0.1495 (0.1688)  loss_box_reg: 0.2385 (0.2699)  loss_mask: 0.2453 (0.2559)  loss_objectness: 0.0181 (0.0210)  loss_rpn_box_reg: 0.1265 (0.1512)  time: 4.7472  data: 4.3296  max mem: 2292\n",
            "Epoch: [0]  [280/300]  eta: 0:01:14  lr: 0.000187  loss: 0.7452 (0.8619)  loss_classifier: 0.1298 (0.1672)  loss_box_reg: 0.2326 (0.2688)  loss_mask: 0.2453 (0.2555)  loss_objectness: 0.0133 (0.0208)  loss_rpn_box_reg: 0.0532 (0.1496)  time: 3.0834  data: 2.6712  max mem: 2292\n",
            "Epoch: [0]  [290/300]  eta: 0:00:37  lr: 0.000194  loss: 0.7915 (0.8623)  loss_classifier: 0.1325 (0.1672)  loss_box_reg: 0.2240 (0.2687)  loss_mask: 0.2423 (0.2554)  loss_objectness: 0.0122 (0.0207)  loss_rpn_box_reg: 0.1377 (0.1503)  time: 3.4862  data: 3.0716  max mem: 2292\n",
            "Epoch: [0]  [299/300]  eta: 0:00:03  lr: 0.000200  loss: 0.8359 (0.8592)  loss_classifier: 0.1451 (0.1666)  loss_box_reg: 0.2632 (0.2679)  loss_mask: 0.2433 (0.2550)  loss_objectness: 0.0131 (0.0206)  loss_rpn_box_reg: 0.1477 (0.1491)  time: 3.7433  data: 3.3305  max mem: 2292\n",
            "Epoch: [0] Total time: 0:18:38 (3.7267 s / it)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qdJlOC3fD7d2",
        "outputId": "3033314b-955e-46de-cd7f-3f303a70d93e"
      },
      "source": [
        "\"\"\"---\n",
        "\n",
        "# GAN part\n",
        "### Now that we have our Mask-RCNN Model that is ready and trained on the dataset, we try to improve its prediction performances by adversarial approach.\n",
        "\n",
        "#### Creation of discriminator network\n",
        "\"\"\"\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms\n",
        "from torchvision.utils import make_grid\n",
        "import torchvision.utils as vutils\n",
        "\n",
        "from math import sqrt\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "###################################\n",
        "## -------- Configs ------------ ##\n",
        "###################################\n",
        "\n",
        "# Number of GPUs available. Use 0 for CPU mode.\n",
        "ngpu = 1\n",
        "\n",
        "# Number of channels in the training images. For color images this is 3\n",
        "nc = 1\n",
        "\n",
        "# Size of feature maps in generator\n",
        "ngf = 64\n",
        "\n",
        "# Size of feature maps in discriminator\n",
        "ndf = 64\n",
        "\n",
        "# Learning rate for optimizers\n",
        "lr = 0.0002\n",
        "\n",
        "# Beta1 hyperparam for Adam optimizers\n",
        "beta1 = 0.5\n",
        "\n",
        "# Number of training epochs for discriminators train\n",
        "num_epochs = 10\n",
        "\n",
        "# Number of training epochs for GAN training\n",
        "num_epochs_GAN = 2\n",
        "\n",
        "\"\"\"### Mask Discriminator network:\"\"\"\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, ngpu):\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.ngpu = ngpu\n",
        "        self.main = nn.Sequential(\n",
        "            \n",
        "            # input is (nc) x 128 x 128\n",
        "            nn.Conv2d(nc, ndf, 4, 2, 1, bias=False),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "\n",
        "            # input is (nc) x 64 x 64\n",
        "            nn.Conv2d(ndf, ndf*2, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ndf * 2),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            # state size. (ndf) x 32 x 32\n",
        "            nn.Conv2d(ndf*2, ndf * 2, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ndf * 2),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            # state size. (ndf*2) x 16 x 16\n",
        "            nn.Conv2d(ndf * 2, ndf * 4, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ndf * 4),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            # state size. (ndf*4) x 8 x 8\n",
        "            nn.Conv2d(ndf * 4, ndf * 8, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ndf * 8),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            # state size. (ndf*8) x 4 x 4\n",
        "\n",
        "            nn.Conv2d(ndf * 8, ndf * 16, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ndf * 16),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            # state size. (ndf*16) x 2 x 2\n",
        "\n",
        "            nn.Conv2d(ndf * 16, 1, 2, 1, 0, bias=False),\n",
        "            # nn.Conv2d(ndf * 16, 1, 2, 1, 0, bias=False),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, input):\n",
        "        return self.main(input)\n",
        "\n",
        "\"\"\"### Boxes discriminator network:\"\"\"\n",
        "\n",
        "class BoxDiscriminator(nn.Module):\n",
        "    def __init__(self, nc=256, ndf=64): # channel dim is 256 because it takes as input the feature map\n",
        "        super(BoxDiscriminator, self).__init__()\n",
        "        self.main = nn.Sequential(\n",
        "            # input is (channel_dim) x 32 x 32\n",
        "            nn.Conv2d(256, ndf, 4, 2, 1, bias=False),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            # state size. (ndf) x 16 x 16\n",
        "            nn.Conv2d(ndf * 1, ndf * 2, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ndf * 2),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            # state size. (ndf*2) x 8 x 8\n",
        "            nn.Conv2d(ndf * 2, ndf * 4, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ndf * 4),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            # state size. (ndf*4) x 4 x 4\n",
        "            nn.Conv2d(ndf * 4, ndf * 8, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ndf * 8),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            # state size. (ndf*8) x 2 x 2\n",
        "            nn.Conv2d(ndf * 8, 1, 2, 1, 0, bias=False),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "\n",
        "    def forward(self, input):\n",
        "      return self.main(input)\n",
        "\n",
        "\"\"\"### Weight init\n",
        "\n",
        "From the DCGAN paper, the authors specify that all model weights shall be randomly initialized from a Normal distribution with mean=0, stdev=0.02. The weights_init function takes an initialized model as input and reinitializes all convolutional, convolutional-transpose, and batch normalization layers to meet this criteria. This function is applied to the models immediately after initialization.\n",
        "\"\"\"\n",
        "\n",
        "# custom weights initialization called on netG and netD\n",
        "def weights_init(m):\n",
        "    classname = m.__class__.__name__\n",
        "    if classname.find('Conv') != -1:\n",
        "        nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
        "    elif classname.find('BatchNorm') != -1:\n",
        "        nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
        "        nn.init.constant_(m.bias.data, 0)\n",
        "\n",
        "# Create the Mask Discriminator\n",
        "netD = Discriminator(ngpu).to(device)\n",
        "\n",
        "# Create the Box Discriminator\n",
        "netD_box = BoxDiscriminator(ngpu).to(device)\n",
        "\n",
        "# Handle multi-gpu if desired\n",
        "if (device.type == 'cuda') and (ngpu > 1):\n",
        "    netD = nn.DataParallel(netD, list(range(ngpu)))\n",
        "    netD_box = nn.DataParallel(netD, list(range(ngpu)))\n",
        "\n",
        "# Apply the weights_init function to randomly initialize all weights\n",
        "#  to mean=0, stdev=0.2.\n",
        "netD.apply(weights_init)\n",
        "netD_box.apply(weights_init)\n",
        "\n",
        "# Print the model\n",
        "# print(netD)\n",
        "# print(netD_box)\n",
        "\n",
        "from torchsummary import summary\n",
        "\n",
        "summary(netD, (1, 128, 128))\n",
        "# summary(netD_box, (256, 32, 32))\n",
        "\n",
        "\"\"\"### Loss function and optimizer\"\"\"\n",
        "\n",
        "# Initialize BCELoss function\n",
        "criterion = nn.BCELoss()\n",
        "\n",
        "#Initialize loss function for the Mask generator training\n",
        "mae = nn.L1Loss() # MAE loss\n",
        "\n",
        "# Establish convention for real and fake labels during training\n",
        "real_label = 1.\n",
        "fake_label = 0.\n",
        "\n",
        "# Optimizer for the discriminators:\n",
        "optimizerD = optim.Adam(netD.parameters(), lr=lr, betas=(beta1, 0.999))\n",
        "optimizerD_box = optim.Adam(netD_box.parameters(), lr=lr, betas=(beta1, 0.999))\n",
        "\n",
        "# optimizer for the generator\n",
        "optimizer = torch.optim.SGD(params, lr=lr,\n",
        "                            momentum=0.9, weight_decay=0.00002)\n",
        "# and a learning rate scheduler which decreases the learning rate by\n",
        "# 10x every 3 epochs\n",
        "lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer,\n",
        "                                               step_size=3,\n",
        "                                               gamma=0.1)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 64, 64, 64]           1,024\n",
            "         LeakyReLU-2           [-1, 64, 64, 64]               0\n",
            "            Conv2d-3          [-1, 128, 32, 32]         131,072\n",
            "       BatchNorm2d-4          [-1, 128, 32, 32]             256\n",
            "         LeakyReLU-5          [-1, 128, 32, 32]               0\n",
            "            Conv2d-6          [-1, 128, 16, 16]         262,144\n",
            "       BatchNorm2d-7          [-1, 128, 16, 16]             256\n",
            "         LeakyReLU-8          [-1, 128, 16, 16]               0\n",
            "            Conv2d-9            [-1, 256, 8, 8]         524,288\n",
            "      BatchNorm2d-10            [-1, 256, 8, 8]             512\n",
            "        LeakyReLU-11            [-1, 256, 8, 8]               0\n",
            "           Conv2d-12            [-1, 512, 4, 4]       2,097,152\n",
            "      BatchNorm2d-13            [-1, 512, 4, 4]           1,024\n",
            "        LeakyReLU-14            [-1, 512, 4, 4]               0\n",
            "           Conv2d-15           [-1, 1024, 2, 2]       8,388,608\n",
            "      BatchNorm2d-16           [-1, 1024, 2, 2]           2,048\n",
            "        LeakyReLU-17           [-1, 1024, 2, 2]               0\n",
            "           Conv2d-18              [-1, 1, 1, 1]           4,096\n",
            "          Sigmoid-19              [-1, 1, 1, 1]               0\n",
            "================================================================\n",
            "Total params: 11,412,480\n",
            "Trainable params: 11,412,480\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.06\n",
            "Forward/backward pass size (MB): 8.41\n",
            "Params size (MB): 43.54\n",
            "Estimated Total Size (MB): 52.00\n",
            "----------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W5bzgU9tKo7P",
        "outputId": "42de18e5-6799-4448-8229-6c0a9520be20"
      },
      "source": [
        "### load the discriminator\n",
        "#load discriminator\n",
        "PATH_D = \"/content/drive/MyDrive/Thesis/Pythorch Mask-RCNN/saved_models_cityscapes/GAN_training_100%/discriminators/mask_discriminator_300imgs_epoch_\"\n",
        "\n",
        "epoch = 12  # last epoch for which the model was saved\n",
        "checkpoint = torch.load(PATH_D+str(epoch))\n",
        "netD.load_state_dict(checkpoint['model_state_dict'])\n",
        "optimizerD.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "\n",
        "epoch = checkpoint['epoch']\n",
        "netD.train()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Discriminator(\n",
              "  (main): Sequential(\n",
              "    (0): Conv2d(1, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "    (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
              "    (2): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "    (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (4): LeakyReLU(negative_slope=0.2, inplace=True)\n",
              "    (5): Conv2d(128, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "    (6): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (7): LeakyReLU(negative_slope=0.2, inplace=True)\n",
              "    (8): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "    (9): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (10): LeakyReLU(negative_slope=0.2, inplace=True)\n",
              "    (11): Conv2d(256, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "    (12): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (13): LeakyReLU(negative_slope=0.2, inplace=True)\n",
              "    (14): Conv2d(512, 1024, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "    (15): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (16): LeakyReLU(negative_slope=0.2, inplace=True)\n",
              "    (17): Conv2d(1024, 1, kernel_size=(2, 2), stride=(1, 1), bias=False)\n",
              "    (18): Sigmoid()\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tV_86nQFDwJW"
      },
      "source": [
        "## GAN training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RBUbeuNC7lLq",
        "outputId": "d0319cd1-e3ac-493b-a433-ccb6a30bfd95"
      },
      "source": [
        "\n",
        "import torch.nn.functional as nnf\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "tensor_converter = transforms.ToTensor()\n",
        "\n",
        "\n",
        "\n",
        "\"\"\"---\n",
        "\n",
        "## Adversarial training\n",
        "\n",
        "### Now it's time to put the Mask-RCNN generator in competition with the Masks discriminator and the boxes discriminatir networks\n",
        "\n",
        "## Adversarial training with GT - Predictions match\n",
        "\"\"\"\n",
        "\n",
        "SAVE_PATH = \"/content/drive/MyDrive/Thesis/Pythorch Mask-RCNN/saved_models_cityscapes/\"\n",
        "last_epoch = 9\n",
        "\n",
        "\n",
        "# Training Loop\n",
        "\n",
        "# Lists to keep track of progress\n",
        "img_list = []\n",
        "\n",
        "iters = 0\n",
        "masks = []\n",
        "b_size = 1\n",
        "\n",
        "LAMBDA = 100\n",
        "\n",
        "start_epoch = 13\n",
        "\n",
        "num_epochs = 20\n",
        "\n",
        "# errD_masks = torch.zeros((1), device=device, dtype=dtype)\n",
        "# errG_tot = torch.zeros((1), device=device, dtype=dtype)\n",
        "\n",
        "print(\"Starting Training Loop...\")\n",
        "# For each epoch\n",
        "for epoch in range(start_epoch, num_epochs + start_epoch):\n",
        "\n",
        "    D_mask_losses = []\n",
        "    Gen_losses = []\n",
        "    # For each batch in the dataloader\n",
        "    for k, data in enumerate(data_loader, 0):\n",
        "\n",
        "        if (len(data[1][0][\"boxes\"]) == 0):\n",
        "            continue\n",
        "\n",
        "        # get the image\n",
        "        tensor_image = data[0][0]\n",
        "        # get the corresponding gt boxes\n",
        "        gt_boxes = data[1][0][\"boxes\"].cpu().numpy()\n",
        "        # get the corresponding gt masks\n",
        "        gt_masks = data[1][0][\"masks\"]\n",
        "        tensor_gt_labels = data[1][0][\"labels\"]\n",
        "        ## -----------------------\n",
        "        # generate mask predictions using the Mask-RCNN model\n",
        "        model.eval()  # put the model in evaluation mode\n",
        "\n",
        "        prediction = model([tensor_image.to(device)])\n",
        "\n",
        "        ## IMPORTANT restore the model in training mode\n",
        "        model.train()\n",
        "        # -------\n",
        "        pred_masks = prediction[0][\"masks\"]  # tensor predicted masks\n",
        "        # save predictions and extract each corresponding boxes\n",
        "        pred_boxes = prediction[0][\"boxes\"].cpu().detach().numpy()\n",
        "        # save predicted scores and labels\n",
        "        pred_labels = prediction[0][\"labels\"].cpu().numpy()\n",
        "        pred_scores = prediction[0][\"scores\"].cpu().detach().numpy()\n",
        "\n",
        "        # ################ Compute Matches ######################\n",
        "        ##\n",
        "        # get the corresponding gt numpy masks\n",
        "        gt_numpy_masks = data[1][0][\"masks\"].mul(255).permute(1, 2, 0).cpu().numpy()\n",
        "        ## -----------------------\n",
        "        pred_numpy_masks = torch.squeeze(prediction[0][\"masks\"], dim=1).permute(1, 2, 0).cpu().detach().numpy()\n",
        "        ## --------------------------------\n",
        "        gt_match, pred_match, overlaps = compute_matches(gt_boxes, tensor_gt_labels, gt_numpy_masks,\n",
        "                                                         pred_boxes, pred_labels, pred_scores, pred_numpy_masks)\n",
        "        valid_gt_match = []  # initialize list before every iteration to avoid errors\n",
        "        valid_gt_elems = []\n",
        "        index = 0  # initialize i before every iteration to avoid errors\n",
        "        elem = None  # initialize i before every iteration to avoid errors\n",
        "        for index, elem in enumerate(gt_match):\n",
        "            if np.int(elem) != -1:\n",
        "                valid_gt_match.append(np.int(elem))\n",
        "                valid_gt_elems.append(index)\n",
        "\n",
        "        # ################ END - Compute Matches ######################\n",
        "\n",
        "        # inizialize gradients at each iteration\n",
        "        netD.zero_grad()\n",
        "\n",
        "        # # uncomment to block discriminator training in even epochs\n",
        "        # netD.train()\n",
        "        # if (k%2 == 0):\n",
        "        #   netD.train(False)\n",
        "\n",
        "        real_errors = []\n",
        "        fake_errors = []\n",
        "        gen_losses = []\n",
        "\n",
        "        errD_masks = 0\n",
        "        errG_tot = 0\n",
        "\n",
        "        real_batch = torch.empty(gt_masks.shape[0], 1, 128, 128)\n",
        "        fake_batch = torch.empty(pred_masks.shape[0], 1, 128, 128)\n",
        "\n",
        "        i = 0  # initialize i before every iteration to avoid errors\n",
        "        for i in range(gt_masks.shape[0]):\n",
        "            real_mask = gt_masks[i, :, :]  # get the i-th mask\n",
        "            # add channel\n",
        "            real_mask.unsqueeze_(0)\n",
        "            normalized_real_mask = (real_mask - 0.5).div(0.5)  # normalize the mask in -1,1\n",
        "            # add batch dimension\n",
        "            # normalized_real_mask.unsqueeze_(0)\n",
        "\n",
        "            real_box = gt_boxes[i, :]\n",
        "            top = int(real_box[1])\n",
        "            left = int(real_box[0])\n",
        "            heigth = int(real_box[3] - real_box[1])\n",
        "            width = int(real_box[2] - real_box[0])\n",
        "\n",
        "            ## REAL DATA\n",
        "            # crop real mask with real boxes\n",
        "            cropped_mask = torchvision.transforms.functional.crop(normalized_real_mask, top, left, heigth, width)\n",
        "            # resize the cropped mask to 128x128\n",
        "            tensor_mask = transforms.functional.resize(cropped_mask, [128, 128])\n",
        "\n",
        "            real_batch[i] = tensor_mask\n",
        "\n",
        "        # train with reals\n",
        "        if (np.random.uniform() > 0.95):  # introduce a low probability of noisy labels)\n",
        "            label = torch.FloatTensor(gt_masks.shape[0], ).uniform_(0.0, 0.3)\n",
        "            # label = torch.full((gt_masks.shape[0],), fake_label, dtype=torch.float, device=device)\n",
        "        else:\n",
        "            label = torch.FloatTensor(gt_masks.shape[0], ).uniform_(0.7, 1.2)\n",
        "            # label = torch.full((gt_masks.shape[0],), real_label, dtype=torch.float, device=device)\n",
        "\n",
        "        if (GPU == True):\n",
        "            label, real_batch = label.cuda(), real_batch.cuda()\n",
        "        output = netD(real_batch).view(-1)\n",
        "        # Calculate loss on all-real batch\n",
        "\n",
        "        errD_real_mask = criterion(output, label)\n",
        "        # print(\"error real masks \",errD_real_mask)\n",
        "        # print(\"error real requires grad \",errD_real_mask.requires_grad)\n",
        "\n",
        "        errD_real_mask.backward()\n",
        "\n",
        "        D_x_mask_real = output.mean().item()\n",
        "\n",
        "        ##  ----- TRAIN WITH FAKES -----------\n",
        "\n",
        "        j = 0\n",
        "        for j in range(pred_masks.shape[0]):\n",
        "            fake_mask = pred_masks[j, :, :, :]\n",
        "            normalized_fake_mask = (fake_mask - 0.5).div(0.5)  # normalize the mask in -1,1\n",
        "            # print(\"normalized fake mask shape \", normalized_fake_mask.shape )\n",
        "\n",
        "            fake_box = pred_boxes[j, :]\n",
        "            top = int(fake_box[1])\n",
        "            left = int(fake_box[0])\n",
        "            heigth = int(fake_box[3] - fake_box[1])\n",
        "            width = int(fake_box[2] - fake_box[0])\n",
        "\n",
        "            # crop using the predicted boxes\n",
        "            cropped_fake_mask = torchvision.transforms.functional.crop(normalized_fake_mask, top, left, heigth, width)\n",
        "            # print(\"cropped fake mask shape \", cropped_fake_mask.shape )\n",
        "            # resize the cropped mask to 128x128\n",
        "            tensor_fake_mask = transforms.functional.resize(cropped_fake_mask, [128, 128])\n",
        "            # print(\"tensor fake mask shape \", tensor_fake_mask.shape)\n",
        "            fake_batch[j] = tensor_fake_mask\n",
        "\n",
        "        real_matched_batch = torch.empty(len(valid_gt_match), 1, 128, 128)\n",
        "        fake_matched_batch = torch.empty(len(valid_gt_match), 1, 128, 128)\n",
        "        count = 0\n",
        "\n",
        "        h = 0\n",
        "        for h in range(pred_masks.shape[0]):\n",
        "\n",
        "            matching = False\n",
        "            ### Chech if there is matching with GT ###\n",
        "            if (h in valid_gt_match):  # check if there is matching\n",
        "                matching = True\n",
        "                # we have a prediction - gt correspondence\n",
        "                # get index elem of h in valid gt elems\n",
        "                corresponding_index = valid_gt_match.index(h)\n",
        "                # use the index to find valid gt index in gt masks\n",
        "                valid_gt_index = valid_gt_elems[corresponding_index]\n",
        "                # get the mask\n",
        "                real_mask = real_batch[valid_gt_index]  # get the i-th real mask\n",
        "                fake_mask = fake_batch[h]\n",
        "\n",
        "                real_matched_batch[count] = real_mask\n",
        "                fake_matched_batch[count] = fake_mask\n",
        "\n",
        "                count += 1\n",
        "\n",
        "        # train with fakes\n",
        "        if (np.random.uniform() > 0.95):  # introduce a low probability of noisy labels)\n",
        "            # label = torch.full((pred_masks.shape[0],), real_label, dtype=torch.float, device=device)\n",
        "            label = torch.FloatTensor(pred_masks.shape[0], ).uniform_(0.7, 1.2)\n",
        "        else:\n",
        "            label = torch.FloatTensor(pred_masks.shape[0], ).uniform_(0.0, 0.3)\n",
        "            # label = torch.full((pred_masks.shape[0],), fake_label, dtype=torch.float, device=device)\n",
        "\n",
        "        if (GPU == True):\n",
        "            label, fake_batch = label.cuda(), fake_batch.cuda()\n",
        "        output = netD(fake_batch.detach()).view(-1)\n",
        "        # Calculate loss on all-fake batch\n",
        "\n",
        "        errD_fake_mask = criterion(output, label)\n",
        "        # print(\"error fake masks \",errD_fake_mask)\n",
        "        # print(\"error fake requires grad \",errD_fake_mask.requires_grad)\n",
        "        errD_fake_mask.backward()\n",
        "\n",
        "        D_x_mask_fake = output.mean().item()\n",
        "\n",
        "        errD_masks = float(errD_real_mask + errD_fake_mask)\n",
        "\n",
        "        # Update D\n",
        "        optimizerD.step()\n",
        "\n",
        "        # free some GPU space\n",
        "        # del label, errD_fake_mask, errD_real_mask, tensor_image, gt_masks, real_batch\n",
        "        # torch.cuda.empty_cache()\n",
        "\n",
        "        # --------------------\n",
        "        ############################\n",
        "        # (2) Update G network: maximize log(D(G(z)))\n",
        "        ###########################\n",
        "        model.zero_grad()\n",
        "\n",
        "\n",
        "        # set label to true label\n",
        "        label = torch.full((pred_masks.shape[0],), real_label, dtype=torch.float, device=device)\n",
        "        if (GPU == True):\n",
        "            real_matched_batch, fake_matched_batch, label = real_matched_batch.cuda(), fake_matched_batch.cuda(), label.cuda()\n",
        "\n",
        "        # Since we just updated D, perform another forward pass of all-fake batch through D\n",
        "        # compute output for Mask\n",
        "        outputM = netD(fake_batch).view(-1)\n",
        "\n",
        "        # Calculate G's loss based on this output\n",
        "        if (matching == True):\n",
        "            errG_mask = criterion(outputM, label) + LAMBDA * mae(real_matched_batch, fake_matched_batch)\n",
        "        else:\n",
        "            errG_mask = criterion(outputM, label)\n",
        "\n",
        "        # Calculate gradients for G\n",
        "        errG_mask.backward()\n",
        "        # plot_grad_flow(model.named_parameters()) # plots the gradient flow\n",
        "        optimizer.step()\n",
        "        lr_scheduler.step()\n",
        "\n",
        "        D_G_mask = outputM.mean().item()\n",
        "\n",
        "        errG_tot = float(errG_mask)\n",
        "\n",
        "        # Output training stats\n",
        "        if k % 5 == 0:\n",
        "            print('[%d/%d][%d/%d]\\tLoss_D_mask: %.4f\\tLoss_G: %.4f\\tD(x_real): %.4f\\tD(x_fake): %.4f\\t'\n",
        "                  % (epoch, num_epochs, k, len(data_loader),\n",
        "                     errD_masks, errG_tot, D_x_mask_real, D_x_mask_fake))\n",
        "\n",
        "        D_mask_losses.append(errD_masks)\n",
        "        Gen_losses.append(errG_tot)\n",
        "\n",
        "\n",
        "    if(epoch % 4 == 0):\n",
        "        # save models\n",
        "        torch.save({\n",
        "            'epoch': epoch,\n",
        "            'model_state_dict': model.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\n",
        "            # 'loss': loss,\n",
        "        }, SAVE_PATH+\"GAN_training_100%/generator/generator_300imgs_epoch_\" + str(epoch))\n",
        "\n",
        "        torch.save({\n",
        "            'epoch': epoch,\n",
        "            'model_state_dict': netD.state_dict(),\n",
        "            'optimizer_state_dict': optimizerD.state_dict(),\n",
        "            # 'loss': loss,\n",
        "        }, SAVE_PATH+\"GAN_training_100%/discriminators/mask_discriminator_300imgs_epoch_\" + str(epoch))\n",
        "\n",
        "        print(\"models saved correctly\")\n",
        "\n",
        "        # save loss lists into file\n",
        "\n",
        "    # D box losses\n",
        "    f=open(SAVE_PATH+'GAN_training_100%/losses/D_mask_300_losses_epoch'+str(epoch)+'.txt','w')\n",
        "    for ele in D_mask_losses:\n",
        "        f.write(str(ele)+'\\n')\n",
        "    f.close()\n",
        "\n",
        "    # generator losses\n",
        "    f=open(SAVE_PATH+'GAN_training_100%/losses/generator_300_losses_epoch'+str(epoch)+'.txt','w')\n",
        "    for ele in Gen_losses:\n",
        "        f.write(str(ele)+'\\n')\n",
        "    f.close()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Starting Training Loop...\n",
            "[13/20][0/300]\tLoss_D_mask: 1.0873\tLoss_G: 1.7119\tD(x_real): 0.9514\tD(x_fake): 0.2050\t\n",
            "[13/20][5/300]\tLoss_D_mask: 1.0398\tLoss_G: 2.1445\tD(x_real): 0.9481\tD(x_fake): 0.1239\t\n",
            "[13/20][10/300]\tLoss_D_mask: 0.5097\tLoss_G: 2.1199\tD(x_real): 0.8610\tD(x_fake): 0.1028\t\n",
            "[13/20][15/300]\tLoss_D_mask: 0.6724\tLoss_G: 1.8993\tD(x_real): 0.9250\tD(x_fake): 0.1458\t\n",
            "[13/20][20/300]\tLoss_D_mask: 0.6939\tLoss_G: 1.9888\tD(x_real): 0.9187\tD(x_fake): 0.1380\t\n",
            "[13/20][25/300]\tLoss_D_mask: 0.8182\tLoss_G: 1.9623\tD(x_real): 0.9446\tD(x_fake): 0.1471\t\n",
            "[13/20][30/300]\tLoss_D_mask: 0.6950\tLoss_G: 1.2687\tD(x_real): 0.9493\tD(x_fake): 0.2594\t\n",
            "[13/20][35/300]\tLoss_D_mask: 0.6221\tLoss_G: 1.1226\tD(x_real): 0.9671\tD(x_fake): 0.3191\t\n",
            "[13/20][40/300]\tLoss_D_mask: 0.5995\tLoss_G: 1.7554\tD(x_real): 0.9462\tD(x_fake): 0.1898\t\n",
            "[13/20][45/300]\tLoss_D_mask: 0.8060\tLoss_G: 1.7169\tD(x_real): 0.9644\tD(x_fake): 0.1898\t\n",
            "[13/20][50/300]\tLoss_D_mask: 0.6146\tLoss_G: 1.3925\tD(x_real): 0.8758\tD(x_fake): 0.2140\t\n",
            "[13/20][55/300]\tLoss_D_mask: 0.6365\tLoss_G: 1.4260\tD(x_real): 0.9481\tD(x_fake): 0.2626\t\n",
            "[13/20][60/300]\tLoss_D_mask: 0.6030\tLoss_G: 1.8726\tD(x_real): 0.9347\tD(x_fake): 0.1591\t\n",
            "[13/20][65/300]\tLoss_D_mask: 1.8119\tLoss_G: 1.2334\tD(x_real): 0.9014\tD(x_fake): 0.1828\t\n",
            "[13/20][70/300]\tLoss_D_mask: 0.7242\tLoss_G: 1.4552\tD(x_real): 0.8792\tD(x_fake): 0.2535\t\n",
            "[13/20][75/300]\tLoss_D_mask: 0.5126\tLoss_G: 1.6213\tD(x_real): 0.9208\tD(x_fake): 0.2032\t\n",
            "[13/20][80/300]\tLoss_D_mask: 0.6435\tLoss_G: 1.8266\tD(x_real): 0.9122\tD(x_fake): 0.1612\t\n",
            "[13/20][85/300]\tLoss_D_mask: 0.5713\tLoss_G: 2.3365\tD(x_real): 0.8340\tD(x_fake): 0.0816\t\n",
            "[13/20][90/300]\tLoss_D_mask: 0.5521\tLoss_G: 1.8102\tD(x_real): 0.9150\tD(x_fake): 0.1601\t\n",
            "[13/20][95/300]\tLoss_D_mask: 0.4851\tLoss_G: 1.7073\tD(x_real): 0.9369\tD(x_fake): 0.1822\t\n",
            "[13/20][100/300]\tLoss_D_mask: 0.5395\tLoss_G: 1.8615\tD(x_real): 0.9404\tD(x_fake): 0.1638\t\n",
            "[13/20][110/300]\tLoss_D_mask: 0.8325\tLoss_G: 1.5382\tD(x_real): 0.9658\tD(x_fake): 0.2481\t\n",
            "[13/20][115/300]\tLoss_D_mask: 0.7389\tLoss_G: 1.8827\tD(x_real): 0.9410\tD(x_fake): 0.1655\t\n",
            "[13/20][120/300]\tLoss_D_mask: 0.7540\tLoss_G: 2.1236\tD(x_real): 0.9004\tD(x_fake): 0.1615\t\n",
            "[13/20][125/300]\tLoss_D_mask: 0.7629\tLoss_G: 1.3514\tD(x_real): 0.8634\tD(x_fake): 0.2305\t\n",
            "[13/20][130/300]\tLoss_D_mask: 0.7658\tLoss_G: 1.3997\tD(x_real): 0.9244\tD(x_fake): 0.2622\t\n",
            "[13/20][135/300]\tLoss_D_mask: 3.6647\tLoss_G: 19.3780\tD(x_real): 0.8596\tD(x_fake): 0.8960\t\n",
            "[13/20][140/300]\tLoss_D_mask: 0.7519\tLoss_G: 1.3813\tD(x_real): 0.8865\tD(x_fake): 0.2635\t\n",
            "[13/20][145/300]\tLoss_D_mask: 0.9161\tLoss_G: 1.1700\tD(x_real): 0.9148\tD(x_fake): 0.3610\t\n",
            "[13/20][150/300]\tLoss_D_mask: 2.9430\tLoss_G: 1.8496\tD(x_real): 0.6434\tD(x_fake): 0.1444\t\n",
            "[13/20][155/300]\tLoss_D_mask: 0.6916\tLoss_G: 1.4023\tD(x_real): 0.8286\tD(x_fake): 0.2445\t\n",
            "[13/20][160/300]\tLoss_D_mask: 2.6259\tLoss_G: 1.6934\tD(x_real): 0.9113\tD(x_fake): 0.2567\t\n",
            "[13/20][165/300]\tLoss_D_mask: 0.5672\tLoss_G: 1.5030\tD(x_real): 0.8766\tD(x_fake): 0.2183\t\n",
            "[13/20][170/300]\tLoss_D_mask: 2.5327\tLoss_G: 1.9051\tD(x_real): 0.9084\tD(x_fake): 0.2278\t\n",
            "[13/20][175/300]\tLoss_D_mask: 0.6848\tLoss_G: 1.8107\tD(x_real): 0.8654\tD(x_fake): 0.1478\t\n",
            "[13/20][180/300]\tLoss_D_mask: 0.5249\tLoss_G: 1.6788\tD(x_real): 0.8933\tD(x_fake): 0.2074\t\n",
            "[13/20][185/300]\tLoss_D_mask: 2.4935\tLoss_G: 1.5164\tD(x_real): 0.6391\tD(x_fake): 0.1303\t\n",
            "[13/20][190/300]\tLoss_D_mask: 1.0530\tLoss_G: 0.6592\tD(x_real): 0.9503\tD(x_fake): 0.4087\t\n",
            "[13/20][195/300]\tLoss_D_mask: 0.7558\tLoss_G: 1.3365\tD(x_real): 0.8991\tD(x_fake): 0.3130\t\n",
            "[13/20][200/300]\tLoss_D_mask: 2.5987\tLoss_G: 1.8724\tD(x_real): 0.9083\tD(x_fake): 0.2036\t\n",
            "[13/20][205/300]\tLoss_D_mask: 0.5084\tLoss_G: 1.7028\tD(x_real): 0.8716\tD(x_fake): 0.1718\t\n",
            "[13/20][210/300]\tLoss_D_mask: 0.4063\tLoss_G: 1.8529\tD(x_real): 0.9156\tD(x_fake): 0.1565\t\n",
            "[13/20][215/300]\tLoss_D_mask: 0.8566\tLoss_G: 1.8535\tD(x_real): 0.9309\tD(x_fake): 0.1702\t\n",
            "[13/20][220/300]\tLoss_D_mask: 0.6817\tLoss_G: 1.8986\tD(x_real): 0.9248\tD(x_fake): 0.1512\t\n",
            "[13/20][225/300]\tLoss_D_mask: 0.5175\tLoss_G: 1.8063\tD(x_real): 0.9314\tD(x_fake): 0.1620\t\n",
            "[13/20][230/300]\tLoss_D_mask: 0.7590\tLoss_G: 1.9201\tD(x_real): 0.9464\tD(x_fake): 0.1534\t\n",
            "[13/20][235/300]\tLoss_D_mask: 3.0235\tLoss_G: 2.2778\tD(x_real): 0.9485\tD(x_fake): 0.1446\t\n",
            "[13/20][240/300]\tLoss_D_mask: 2.5527\tLoss_G: 2.0250\tD(x_real): 0.9140\tD(x_fake): 0.1763\t\n",
            "[13/20][245/300]\tLoss_D_mask: 0.6786\tLoss_G: 1.9344\tD(x_real): 0.8480\tD(x_fake): 0.1315\t\n",
            "[13/20][250/300]\tLoss_D_mask: 0.5796\tLoss_G: 1.8978\tD(x_real): 0.8801\tD(x_fake): 0.1468\t\n",
            "[13/20][255/300]\tLoss_D_mask: 1.2367\tLoss_G: 2.3709\tD(x_real): 0.4854\tD(x_fake): 0.1019\t\n",
            "[13/20][260/300]\tLoss_D_mask: 0.6312\tLoss_G: 1.7107\tD(x_real): 0.8703\tD(x_fake): 0.1819\t\n",
            "[13/20][265/300]\tLoss_D_mask: 0.7430\tLoss_G: 1.6135\tD(x_real): 0.9202\tD(x_fake): 0.2079\t\n",
            "[13/20][270/300]\tLoss_D_mask: 0.7210\tLoss_G: 2.0259\tD(x_real): 0.8615\tD(x_fake): 0.1217\t\n",
            "[13/20][275/300]\tLoss_D_mask: 0.7433\tLoss_G: 1.5283\tD(x_real): 0.9309\tD(x_fake): 0.2245\t\n",
            "[13/20][280/300]\tLoss_D_mask: 0.8093\tLoss_G: 0.3382\tD(x_real): 0.9719\tD(x_fake): 0.6536\t\n",
            "[13/20][285/300]\tLoss_D_mask: 0.8078\tLoss_G: 1.1569\tD(x_real): 0.8939\tD(x_fake): 0.2986\t\n",
            "[13/20][290/300]\tLoss_D_mask: 0.5991\tLoss_G: 1.4024\tD(x_real): 0.9137\tD(x_fake): 0.2563\t\n",
            "[13/20][295/300]\tLoss_D_mask: 0.5642\tLoss_G: 1.4042\tD(x_real): 0.9212\tD(x_fake): 0.2574\t\n",
            "[14/20][0/300]\tLoss_D_mask: 0.8799\tLoss_G: 1.6206\tD(x_real): 0.9317\tD(x_fake): 0.2334\t\n",
            "[14/20][5/300]\tLoss_D_mask: 0.6232\tLoss_G: 1.7981\tD(x_real): 0.8877\tD(x_fake): 0.1642\t\n",
            "[14/20][10/300]\tLoss_D_mask: 0.6103\tLoss_G: 1.7828\tD(x_real): 0.8838\tD(x_fake): 0.1665\t\n",
            "[14/20][15/300]\tLoss_D_mask: 0.6331\tLoss_G: 1.9308\tD(x_real): 0.8525\tD(x_fake): 0.1541\t\n",
            "[14/20][25/300]\tLoss_D_mask: 0.7460\tLoss_G: 1.8054\tD(x_real): 0.7753\tD(x_fake): 0.1564\t\n",
            "[14/20][30/300]\tLoss_D_mask: 0.5262\tLoss_G: 1.6482\tD(x_real): 0.8772\tD(x_fake): 0.1914\t\n",
            "[14/20][35/300]\tLoss_D_mask: 0.6342\tLoss_G: 1.8093\tD(x_real): 0.9034\tD(x_fake): 0.1681\t\n",
            "[14/20][40/300]\tLoss_D_mask: 0.7843\tLoss_G: 2.1838\tD(x_real): 0.8044\tD(x_fake): 0.1180\t\n",
            "[14/20][45/300]\tLoss_D_mask: 0.5988\tLoss_G: 2.0126\tD(x_real): 0.8209\tD(x_fake): 0.1221\t\n",
            "[14/20][50/300]\tLoss_D_mask: 0.6405\tLoss_G: 1.2106\tD(x_real): 0.9552\tD(x_fake): 0.3102\t\n",
            "[14/20][55/300]\tLoss_D_mask: 0.6934\tLoss_G: 1.9585\tD(x_real): 0.8049\tD(x_fake): 0.1546\t\n",
            "[14/20][60/300]\tLoss_D_mask: 0.5693\tLoss_G: 1.8406\tD(x_real): 0.9276\tD(x_fake): 0.1674\t\n",
            "[14/20][65/300]\tLoss_D_mask: 2.2719\tLoss_G: 1.7017\tD(x_real): 0.8881\tD(x_fake): 0.1230\t\n",
            "[14/20][70/300]\tLoss_D_mask: 0.7211\tLoss_G: 1.4604\tD(x_real): 0.7552\tD(x_fake): 0.2119\t\n",
            "[14/20][75/300]\tLoss_D_mask: 0.7299\tLoss_G: 1.2371\tD(x_real): 0.9342\tD(x_fake): 0.3204\t\n",
            "[14/20][80/300]\tLoss_D_mask: 0.4143\tLoss_G: 1.6363\tD(x_real): 0.9107\tD(x_fake): 0.2094\t\n",
            "[14/20][85/300]\tLoss_D_mask: 0.9030\tLoss_G: 2.0993\tD(x_real): 0.7120\tD(x_fake): 0.1266\t\n",
            "[14/20][90/300]\tLoss_D_mask: 0.8221\tLoss_G: 1.7520\tD(x_real): 0.6913\tD(x_fake): 0.1617\t\n",
            "[14/20][95/300]\tLoss_D_mask: 0.6937\tLoss_G: 2.1022\tD(x_real): 0.8468\tD(x_fake): 0.1388\t\n",
            "[14/20][100/300]\tLoss_D_mask: 0.7977\tLoss_G: 1.8636\tD(x_real): 0.8976\tD(x_fake): 0.1620\t\n",
            "[14/20][105/300]\tLoss_D_mask: 0.6317\tLoss_G: 1.7974\tD(x_real): 0.9070\tD(x_fake): 0.1650\t\n",
            "[14/20][110/300]\tLoss_D_mask: 0.7055\tLoss_G: 1.7718\tD(x_real): 0.9235\tD(x_fake): 0.1729\t\n",
            "[14/20][115/300]\tLoss_D_mask: 0.7173\tLoss_G: 1.8636\tD(x_real): 0.8717\tD(x_fake): 0.1539\t\n",
            "[14/20][120/300]\tLoss_D_mask: 0.6669\tLoss_G: 1.7023\tD(x_real): 0.8925\tD(x_fake): 0.1805\t\n",
            "[14/20][125/300]\tLoss_D_mask: 2.1361\tLoss_G: 18.4849\tD(x_real): 0.8569\tD(x_fake): 0.8663\t\n",
            "[14/20][130/300]\tLoss_D_mask: 0.7227\tLoss_G: 1.9873\tD(x_real): 0.8597\tD(x_fake): 0.1270\t\n",
            "[14/20][135/300]\tLoss_D_mask: 0.6944\tLoss_G: 1.5610\tD(x_real): 0.9281\tD(x_fake): 0.2132\t\n",
            "[14/20][140/300]\tLoss_D_mask: 0.6691\tLoss_G: 2.0798\tD(x_real): 0.8115\tD(x_fake): 0.1175\t\n",
            "[14/20][145/300]\tLoss_D_mask: 0.7430\tLoss_G: 1.5225\tD(x_real): 0.9337\tD(x_fake): 0.2341\t\n",
            "[14/20][150/300]\tLoss_D_mask: 0.6239\tLoss_G: 1.5713\tD(x_real): 0.9414\tD(x_fake): 0.2171\t\n",
            "[14/20][155/300]\tLoss_D_mask: 0.6991\tLoss_G: 1.4353\tD(x_real): 0.9530\tD(x_fake): 0.2684\t\n",
            "[14/20][160/300]\tLoss_D_mask: 0.6331\tLoss_G: 2.2877\tD(x_real): 0.8933\tD(x_fake): 0.1273\t\n",
            "[14/20][165/300]\tLoss_D_mask: 0.8822\tLoss_G: 1.8048\tD(x_real): 0.9354\tD(x_fake): 0.1650\t\n",
            "[14/20][170/300]\tLoss_D_mask: 0.6636\tLoss_G: 1.9327\tD(x_real): 0.9366\tD(x_fake): 0.1458\t\n",
            "[14/20][175/300]\tLoss_D_mask: 2.5778\tLoss_G: 2.0951\tD(x_real): 0.9261\tD(x_fake): 0.1668\t\n",
            "[14/20][180/300]\tLoss_D_mask: 0.6341\tLoss_G: 1.8006\tD(x_real): 0.8937\tD(x_fake): 0.1586\t\n",
            "[14/20][185/300]\tLoss_D_mask: 0.7334\tLoss_G: 1.9065\tD(x_real): 0.9111\tD(x_fake): 0.1452\t\n",
            "[14/20][190/300]\tLoss_D_mask: 0.5214\tLoss_G: 1.7484\tD(x_real): 0.9286\tD(x_fake): 0.1804\t\n",
            "[14/20][195/300]\tLoss_D_mask: 2.8762\tLoss_G: 2.0136\tD(x_real): 0.9435\tD(x_fake): 0.1838\t\n",
            "[14/20][200/300]\tLoss_D_mask: 2.1902\tLoss_G: 1.7263\tD(x_real): 0.8649\tD(x_fake): 0.1063\t\n",
            "[14/20][205/300]\tLoss_D_mask: 1.7071\tLoss_G: 1.2353\tD(x_real): 0.9368\tD(x_fake): 0.2184\t\n",
            "[14/20][210/300]\tLoss_D_mask: 0.8600\tLoss_G: 1.4175\tD(x_real): 0.9487\tD(x_fake): 0.2811\t\n",
            "[14/20][215/300]\tLoss_D_mask: 0.5648\tLoss_G: 1.7547\tD(x_real): 0.9233\tD(x_fake): 0.1786\t\n",
            "[14/20][220/300]\tLoss_D_mask: 0.4829\tLoss_G: 1.4879\tD(x_real): 0.8846\tD(x_fake): 0.2159\t\n",
            "[14/20][225/300]\tLoss_D_mask: 0.5436\tLoss_G: 1.6134\tD(x_real): 0.9129\tD(x_fake): 0.2023\t\n",
            "[14/20][230/300]\tLoss_D_mask: 0.7547\tLoss_G: 2.0145\tD(x_real): 0.8286\tD(x_fake): 0.1593\t\n",
            "[14/20][235/300]\tLoss_D_mask: 0.6548\tLoss_G: 1.9065\tD(x_real): 0.8881\tD(x_fake): 0.1463\t\n",
            "[14/20][240/300]\tLoss_D_mask: 0.5903\tLoss_G: 1.7999\tD(x_real): 0.9321\tD(x_fake): 0.1692\t\n",
            "[14/20][245/300]\tLoss_D_mask: 0.4831\tLoss_G: 1.9426\tD(x_real): 0.8955\tD(x_fake): 0.1419\t\n",
            "[14/20][250/300]\tLoss_D_mask: 0.6100\tLoss_G: 1.8801\tD(x_real): 0.9334\tD(x_fake): 0.1594\t\n",
            "[14/20][255/300]\tLoss_D_mask: 0.4664\tLoss_G: 1.8851\tD(x_real): 0.9327\tD(x_fake): 0.1539\t\n",
            "[14/20][260/300]\tLoss_D_mask: 2.6949\tLoss_G: 1.8404\tD(x_real): 0.9339\tD(x_fake): 0.2282\t\n",
            "[14/20][265/300]\tLoss_D_mask: 0.7470\tLoss_G: 1.8060\tD(x_real): 0.7891\tD(x_fake): 0.1509\t\n",
            "[14/20][270/300]\tLoss_D_mask: 0.7014\tLoss_G: 1.7821\tD(x_real): 0.9140\tD(x_fake): 0.1673\t\n",
            "[14/20][275/300]\tLoss_D_mask: 0.7267\tLoss_G: 2.1024\tD(x_real): 0.8834\tD(x_fake): 0.1494\t\n",
            "[14/20][280/300]\tLoss_D_mask: 0.7281\tLoss_G: 37.3874\tD(x_real): 0.8863\tD(x_fake): 0.1423\t\n",
            "[14/20][285/300]\tLoss_D_mask: 0.6771\tLoss_G: 1.6119\tD(x_real): 0.9331\tD(x_fake): 0.2125\t\n",
            "[14/20][290/300]\tLoss_D_mask: 0.8492\tLoss_G: 1.2894\tD(x_real): 0.9467\tD(x_fake): 0.2472\t\n",
            "[14/20][295/300]\tLoss_D_mask: 0.6429\tLoss_G: 1.5446\tD(x_real): 0.9399\tD(x_fake): 0.2329\t\n",
            "[15/20][0/300]\tLoss_D_mask: 0.6251\tLoss_G: 1.7262\tD(x_real): 0.9367\tD(x_fake): 0.1838\t\n",
            "[15/20][5/300]\tLoss_D_mask: 0.7825\tLoss_G: 2.0482\tD(x_real): 0.7251\tD(x_fake): 0.1284\t\n",
            "[15/20][10/300]\tLoss_D_mask: 2.6483\tLoss_G: 1.6886\tD(x_real): 0.9263\tD(x_fake): 0.2420\t\n",
            "[15/20][15/300]\tLoss_D_mask: 0.7834\tLoss_G: 1.7103\tD(x_real): 0.8870\tD(x_fake): 0.1810\t\n",
            "[15/20][20/300]\tLoss_D_mask: 0.7583\tLoss_G: 1.2307\tD(x_real): 0.9317\tD(x_fake): 0.2570\t\n",
            "[15/20][25/300]\tLoss_D_mask: 0.6202\tLoss_G: 1.4254\tD(x_real): 0.9428\tD(x_fake): 0.2684\t\n",
            "[15/20][30/300]\tLoss_D_mask: 0.5504\tLoss_G: 2.1101\tD(x_real): 0.8465\tD(x_fake): 0.1333\t\n",
            "[15/20][35/300]\tLoss_D_mask: 0.5637\tLoss_G: 1.4419\tD(x_real): 0.8387\tD(x_fake): 0.2376\t\n",
            "[15/20][40/300]\tLoss_D_mask: 0.7019\tLoss_G: 1.6756\tD(x_real): 0.9295\tD(x_fake): 0.1963\t\n",
            "[15/20][45/300]\tLoss_D_mask: 0.6903\tLoss_G: 1.8008\tD(x_real): 0.9260\tD(x_fake): 0.1649\t\n",
            "[15/20][50/300]\tLoss_D_mask: 0.5890\tLoss_G: 2.1118\tD(x_real): 0.8546\tD(x_fake): 0.1145\t\n",
            "[15/20][55/300]\tLoss_D_mask: 0.5674\tLoss_G: 1.8234\tD(x_real): 0.9075\tD(x_fake): 0.1564\t\n",
            "[15/20][60/300]\tLoss_D_mask: 0.7931\tLoss_G: 1.3903\tD(x_real): 0.9379\tD(x_fake): 0.2754\t\n",
            "[15/20][65/300]\tLoss_D_mask: 0.7696\tLoss_G: 1.0728\tD(x_real): 0.9635\tD(x_fake): 0.3874\t\n",
            "[15/20][70/300]\tLoss_D_mask: 0.5230\tLoss_G: 1.7623\tD(x_real): 0.9346\tD(x_fake): 0.1827\t\n",
            "[15/20][75/300]\tLoss_D_mask: 0.7147\tLoss_G: 1.8820\tD(x_real): 0.8600\tD(x_fake): 0.1454\t\n",
            "[15/20][80/300]\tLoss_D_mask: 0.7517\tLoss_G: 1.6817\tD(x_real): 0.9025\tD(x_fake): 0.1869\t\n",
            "[15/20][85/300]\tLoss_D_mask: 0.6733\tLoss_G: 1.3690\tD(x_real): 0.9308\tD(x_fake): 0.3017\t\n",
            "[15/20][90/300]\tLoss_D_mask: 0.6762\tLoss_G: 1.5590\tD(x_real): 0.9499\tD(x_fake): 0.2363\t\n",
            "[15/20][95/300]\tLoss_D_mask: 0.7421\tLoss_G: 1.7374\tD(x_real): 0.9173\tD(x_fake): 0.1800\t\n",
            "[15/20][100/300]\tLoss_D_mask: 0.7207\tLoss_G: 1.7826\tD(x_real): 0.9330\tD(x_fake): 0.1669\t\n",
            "[15/20][105/300]\tLoss_D_mask: 0.5531\tLoss_G: 1.4914\tD(x_real): 0.9429\tD(x_fake): 0.2292\t\n",
            "[15/20][110/300]\tLoss_D_mask: 0.6508\tLoss_G: 28.2925\tD(x_real): 0.6469\tD(x_fake): 0.0637\t\n",
            "[15/20][115/300]\tLoss_D_mask: 0.7760\tLoss_G: 1.3018\tD(x_real): 0.9152\tD(x_fake): 0.2520\t\n",
            "[15/20][120/300]\tLoss_D_mask: 0.7133\tLoss_G: 1.8537\tD(x_real): 0.8879\tD(x_fake): 0.2044\t\n",
            "[15/20][125/300]\tLoss_D_mask: 0.7873\tLoss_G: 1.5141\tD(x_real): 0.8819\tD(x_fake): 0.2201\t\n",
            "[15/20][130/300]\tLoss_D_mask: 0.8027\tLoss_G: 1.6819\tD(x_real): 0.9285\tD(x_fake): 0.1936\t\n",
            "[15/20][135/300]\tLoss_D_mask: 2.4773\tLoss_G: 1.9718\tD(x_real): 0.9165\tD(x_fake): 0.1802\t\n",
            "[15/20][140/300]\tLoss_D_mask: 0.6621\tLoss_G: 1.8203\tD(x_real): 0.7795\tD(x_fake): 0.1568\t\n",
            "[15/20][145/300]\tLoss_D_mask: 0.8210\tLoss_G: 1.4440\tD(x_real): 0.8938\tD(x_fake): 0.2359\t\n",
            "[15/20][150/300]\tLoss_D_mask: 0.6332\tLoss_G: 1.6607\tD(x_real): 0.8850\tD(x_fake): 0.1922\t\n",
            "[15/20][155/300]\tLoss_D_mask: 1.5076\tLoss_G: 0.9220\tD(x_real): 0.9393\tD(x_fake): 0.2716\t\n",
            "[15/20][160/300]\tLoss_D_mask: 0.9784\tLoss_G: 1.0699\tD(x_real): 0.9385\tD(x_fake): 0.5341\t\n",
            "[15/20][165/300]\tLoss_D_mask: 0.5410\tLoss_G: 1.6414\tD(x_real): 0.9301\tD(x_fake): 0.2090\t\n",
            "[15/20][170/300]\tLoss_D_mask: 0.5960\tLoss_G: 1.9882\tD(x_real): 0.8704\tD(x_fake): 0.1533\t\n",
            "[15/20][175/300]\tLoss_D_mask: 0.9036\tLoss_G: 1.8433\tD(x_real): 0.6503\tD(x_fake): 0.1384\t\n",
            "[15/20][180/300]\tLoss_D_mask: 0.7063\tLoss_G: 1.4028\tD(x_real): 0.9573\tD(x_fake): 0.2595\t\n",
            "[15/20][185/300]\tLoss_D_mask: 1.7442\tLoss_G: 1.3160\tD(x_real): 0.9391\tD(x_fake): 0.1924\t\n",
            "[15/20][190/300]\tLoss_D_mask: 2.4070\tLoss_G: 1.9703\tD(x_real): 0.8877\tD(x_fake): 0.2291\t\n",
            "[15/20][195/300]\tLoss_D_mask: 0.6862\tLoss_G: 1.2940\tD(x_real): 0.8774\tD(x_fake): 0.2922\t\n",
            "[15/20][200/300]\tLoss_D_mask: 0.6788\tLoss_G: 1.5387\tD(x_real): 0.8675\tD(x_fake): 0.2141\t\n",
            "[15/20][205/300]\tLoss_D_mask: 0.6221\tLoss_G: 1.9133\tD(x_real): 0.8734\tD(x_fake): 0.1782\t\n",
            "[15/20][210/300]\tLoss_D_mask: 0.6522\tLoss_G: 1.7350\tD(x_real): 0.8872\tD(x_fake): 0.1689\t\n",
            "[15/20][215/300]\tLoss_D_mask: 0.6810\tLoss_G: 1.6971\tD(x_real): 0.9018\tD(x_fake): 0.1890\t\n",
            "[15/20][220/300]\tLoss_D_mask: 0.8567\tLoss_G: 1.5671\tD(x_real): 0.9248\tD(x_fake): 0.2336\t\n",
            "[15/20][225/300]\tLoss_D_mask: 0.7747\tLoss_G: 1.6716\tD(x_real): 0.9215\tD(x_fake): 0.1908\t\n",
            "[15/20][230/300]\tLoss_D_mask: 0.8192\tLoss_G: 1.7741\tD(x_real): 0.9478\tD(x_fake): 0.1806\t\n",
            "[15/20][235/300]\tLoss_D_mask: 0.5655\tLoss_G: 2.0305\tD(x_real): 0.9148\tD(x_fake): 0.1292\t\n",
            "[15/20][240/300]\tLoss_D_mask: 0.7172\tLoss_G: 1.8971\tD(x_real): 0.9052\tD(x_fake): 0.1491\t\n",
            "[15/20][245/300]\tLoss_D_mask: 0.7922\tLoss_G: 2.3229\tD(x_real): 0.8647\tD(x_fake): 0.1000\t\n",
            "[15/20][250/300]\tLoss_D_mask: 0.7609\tLoss_G: 2.1400\tD(x_real): 0.8054\tD(x_fake): 0.1158\t\n",
            "[15/20][255/300]\tLoss_D_mask: 0.6343\tLoss_G: 1.8914\tD(x_real): 0.8713\tD(x_fake): 0.1448\t\n",
            "[15/20][260/300]\tLoss_D_mask: 0.6129\tLoss_G: 1.7780\tD(x_real): 0.9068\tD(x_fake): 0.1683\t\n",
            "[15/20][265/300]\tLoss_D_mask: 0.5088\tLoss_G: 1.7601\tD(x_real): 0.9305\tD(x_fake): 0.1754\t\n",
            "[15/20][270/300]\tLoss_D_mask: 0.6749\tLoss_G: 1.6092\tD(x_real): 0.8331\tD(x_fake): 0.1982\t\n",
            "[15/20][275/300]\tLoss_D_mask: 0.6599\tLoss_G: 2.1838\tD(x_real): 0.8921\tD(x_fake): 0.1272\t\n",
            "[15/20][280/300]\tLoss_D_mask: 0.5799\tLoss_G: 1.9234\tD(x_real): 0.8806\tD(x_fake): 0.1366\t\n",
            "[15/20][285/300]\tLoss_D_mask: 0.4650\tLoss_G: 1.7398\tD(x_real): 0.9295\tD(x_fake): 0.1755\t\n",
            "[15/20][290/300]\tLoss_D_mask: 0.9970\tLoss_G: 1.3721\tD(x_real): 0.9601\tD(x_fake): 0.2639\t\n",
            "[15/20][295/300]\tLoss_D_mask: 1.6484\tLoss_G: 1.1660\tD(x_real): 0.9418\tD(x_fake): 0.2230\t\n",
            "[16/20][0/300]\tLoss_D_mask: 0.8443\tLoss_G: 1.5986\tD(x_real): 0.7814\tD(x_fake): 0.2028\t\n",
            "[16/20][5/300]\tLoss_D_mask: 0.5212\tLoss_G: 1.6883\tD(x_real): 0.8980\tD(x_fake): 0.1884\t\n",
            "[16/20][10/300]\tLoss_D_mask: 0.7836\tLoss_G: 2.0256\tD(x_real): 0.8145\tD(x_fake): 0.1301\t\n",
            "[16/20][15/300]\tLoss_D_mask: 0.5665\tLoss_G: 1.6155\tD(x_real): 0.9443\tD(x_fake): 0.2109\t\n",
            "[16/20][20/300]\tLoss_D_mask: 0.7688\tLoss_G: 1.2114\tD(x_real): 0.9477\tD(x_fake): 0.2688\t\n",
            "[16/20][25/300]\tLoss_D_mask: 0.7507\tLoss_G: 1.6409\tD(x_real): 0.9409\tD(x_fake): 0.2153\t\n",
            "[16/20][30/300]\tLoss_D_mask: 1.5507\tLoss_G: 18.7985\tD(x_real): 0.8283\tD(x_fake): 0.8177\t\n",
            "[16/20][35/300]\tLoss_D_mask: 0.7407\tLoss_G: 1.9584\tD(x_real): 0.8899\tD(x_fake): 0.1352\t\n",
            "[16/20][40/300]\tLoss_D_mask: 0.9367\tLoss_G: 1.9636\tD(x_real): 0.8192\tD(x_fake): 0.1378\t\n",
            "[16/20][45/300]\tLoss_D_mask: 0.6237\tLoss_G: 1.9785\tD(x_real): 0.9150\tD(x_fake): 0.1470\t\n",
            "[16/20][50/300]\tLoss_D_mask: 0.6631\tLoss_G: 2.1285\tD(x_real): 0.7908\tD(x_fake): 0.1198\t\n",
            "[16/20][55/300]\tLoss_D_mask: 1.0363\tLoss_G: 0.7556\tD(x_real): 0.9690\tD(x_fake): 0.4922\t\n",
            "[16/20][60/300]\tLoss_D_mask: 2.7495\tLoss_G: 1.9038\tD(x_real): 0.9317\tD(x_fake): 0.2280\t\n",
            "[16/20][65/300]\tLoss_D_mask: 0.3893\tLoss_G: 1.8366\tD(x_real): 0.9050\tD(x_fake): 0.1608\t\n",
            "[16/20][70/300]\tLoss_D_mask: 0.5633\tLoss_G: 1.7321\tD(x_real): 0.9276\tD(x_fake): 0.1818\t\n",
            "[16/20][75/300]\tLoss_D_mask: 0.6628\tLoss_G: 1.5705\tD(x_real): 0.9262\tD(x_fake): 0.1997\t\n",
            "[16/20][80/300]\tLoss_D_mask: 0.6000\tLoss_G: 2.0069\tD(x_real): 0.8908\tD(x_fake): 0.1310\t\n",
            "[16/20][85/300]\tLoss_D_mask: 0.4452\tLoss_G: 1.8370\tD(x_real): 0.9157\tD(x_fake): 0.1547\t\n",
            "[16/20][90/300]\tLoss_D_mask: 0.4779\tLoss_G: 1.9721\tD(x_real): 0.9360\tD(x_fake): 0.1355\t\n",
            "[16/20][95/300]\tLoss_D_mask: 0.7283\tLoss_G: 1.9508\tD(x_real): 0.8999\tD(x_fake): 0.1451\t\n",
            "[16/20][100/300]\tLoss_D_mask: 0.5982\tLoss_G: 2.0232\tD(x_real): 0.9337\tD(x_fake): 0.1327\t\n",
            "[16/20][105/300]\tLoss_D_mask: 0.8707\tLoss_G: 1.7533\tD(x_real): 0.9505\tD(x_fake): 0.1851\t\n",
            "[16/20][110/300]\tLoss_D_mask: 2.0698\tLoss_G: 1.3794\tD(x_real): 0.9702\tD(x_fake): 0.1569\t\n",
            "[16/20][115/300]\tLoss_D_mask: 0.5789\tLoss_G: 1.4590\tD(x_real): 0.9624\tD(x_fake): 0.2498\t\n",
            "[16/20][120/300]\tLoss_D_mask: 0.6730\tLoss_G: 1.2871\tD(x_real): 0.9598\tD(x_fake): 0.2865\t\n",
            "[16/20][125/300]\tLoss_D_mask: 2.2468\tLoss_G: 1.9424\tD(x_real): 0.8885\tD(x_fake): 0.2012\t\n",
            "[16/20][130/300]\tLoss_D_mask: 0.7254\tLoss_G: 1.5319\tD(x_real): 0.9390\tD(x_fake): 0.2316\t\n",
            "[16/20][135/300]\tLoss_D_mask: 0.7434\tLoss_G: 1.4812\tD(x_real): 0.9229\tD(x_fake): 0.2416\t\n",
            "[16/20][140/300]\tLoss_D_mask: 0.6842\tLoss_G: 2.0068\tD(x_real): 0.8141\tD(x_fake): 0.1353\t\n",
            "[16/20][145/300]\tLoss_D_mask: 0.8257\tLoss_G: 1.6934\tD(x_real): 0.9511\tD(x_fake): 0.1859\t\n",
            "[16/20][150/300]\tLoss_D_mask: 0.7784\tLoss_G: 1.5342\tD(x_real): 0.9556\tD(x_fake): 0.2316\t\n",
            "[16/20][155/300]\tLoss_D_mask: 0.7211\tLoss_G: 1.8321\tD(x_real): 0.9165\tD(x_fake): 0.1604\t\n",
            "[16/20][160/300]\tLoss_D_mask: 1.1203\tLoss_G: 2.2706\tD(x_real): 0.5106\tD(x_fake): 0.1051\t\n",
            "[16/20][165/300]\tLoss_D_mask: 0.5303\tLoss_G: 1.7375\tD(x_real): 0.9215\tD(x_fake): 0.1765\t\n",
            "[16/20][170/300]\tLoss_D_mask: 0.7531\tLoss_G: 1.9925\tD(x_real): 0.8439\tD(x_fake): 0.1315\t\n",
            "[16/20][175/300]\tLoss_D_mask: 0.6421\tLoss_G: 1.7530\tD(x_real): 0.8726\tD(x_fake): 0.1736\t\n",
            "[16/20][180/300]\tLoss_D_mask: 0.5599\tLoss_G: 1.5474\tD(x_real): 0.9401\tD(x_fake): 0.2173\t\n",
            "[16/20][185/300]\tLoss_D_mask: 0.5395\tLoss_G: 1.7017\tD(x_real): 0.9306\tD(x_fake): 0.1870\t\n",
            "[16/20][190/300]\tLoss_D_mask: 0.7127\tLoss_G: 1.4779\tD(x_real): 0.9144\tD(x_fake): 0.2322\t\n",
            "[16/20][195/300]\tLoss_D_mask: 0.6702\tLoss_G: 1.3752\tD(x_real): 0.8595\tD(x_fake): 0.2578\t\n",
            "[16/20][200/300]\tLoss_D_mask: 0.2525\tLoss_G: 1.3252\tD(x_real): 0.9247\tD(x_fake): 0.2686\t\n",
            "[16/20][205/300]\tLoss_D_mask: 0.6312\tLoss_G: 1.4085\tD(x_real): 0.8853\tD(x_fake): 0.2453\t\n",
            "[16/20][210/300]\tLoss_D_mask: 0.9883\tLoss_G: 1.3821\tD(x_real): 0.6334\tD(x_fake): 0.2401\t\n",
            "[16/20][215/300]\tLoss_D_mask: 0.6976\tLoss_G: 1.5051\tD(x_real): 0.8996\tD(x_fake): 0.2294\t\n",
            "[16/20][220/300]\tLoss_D_mask: 0.6918\tLoss_G: 2.0567\tD(x_real): 0.7992\tD(x_fake): 0.1327\t\n",
            "[16/20][225/300]\tLoss_D_mask: 1.4532\tLoss_G: 0.9651\tD(x_real): 0.9132\tD(x_fake): 0.2658\t\n",
            "[16/20][230/300]\tLoss_D_mask: 2.8005\tLoss_G: 1.5268\tD(x_real): 0.9328\tD(x_fake): 0.2984\t\n",
            "[16/20][235/300]\tLoss_D_mask: 0.5847\tLoss_G: 1.3274\tD(x_real): 0.8824\tD(x_fake): 0.2635\t\n",
            "[16/20][240/300]\tLoss_D_mask: 0.6127\tLoss_G: 1.4142\tD(x_real): 0.9020\tD(x_fake): 0.2610\t\n",
            "[16/20][245/300]\tLoss_D_mask: 0.9639\tLoss_G: 1.5871\tD(x_real): 0.9347\tD(x_fake): 0.2112\t\n",
            "[16/20][250/300]\tLoss_D_mask: 0.5301\tLoss_G: 1.3557\tD(x_real): 0.9505\tD(x_fake): 0.2623\t\n",
            "[16/20][255/300]\tLoss_D_mask: 0.8477\tLoss_G: 1.1593\tD(x_real): 0.9540\tD(x_fake): 0.3476\t\n",
            "[16/20][260/300]\tLoss_D_mask: 0.7258\tLoss_G: 1.5951\tD(x_real): 0.9287\tD(x_fake): 0.2184\t\n",
            "[16/20][265/300]\tLoss_D_mask: 0.4749\tLoss_G: 1.8002\tD(x_real): 0.8387\tD(x_fake): 0.1462\t\n",
            "[16/20][270/300]\tLoss_D_mask: 0.5590\tLoss_G: 1.7544\tD(x_real): 0.8906\tD(x_fake): 0.1684\t\n",
            "[16/20][275/300]\tLoss_D_mask: 0.7782\tLoss_G: 1.3123\tD(x_real): 0.9346\tD(x_fake): 0.2554\t\n",
            "[16/20][280/300]\tLoss_D_mask: 0.7223\tLoss_G: 1.4019\tD(x_real): 0.9312\tD(x_fake): 0.2942\t\n",
            "[16/20][285/300]\tLoss_D_mask: 0.6779\tLoss_G: 1.4114\tD(x_real): 0.9053\tD(x_fake): 0.2563\t\n",
            "[16/20][290/300]\tLoss_D_mask: 0.5569\tLoss_G: 1.8170\tD(x_real): 0.9109\tD(x_fake): 0.1626\t\n",
            "[16/20][295/300]\tLoss_D_mask: 0.3953\tLoss_G: 1.1052\tD(x_real): 0.9593\tD(x_fake): 0.3492\t\n",
            "models saved correctly\n",
            "[17/20][0/300]\tLoss_D_mask: 0.8145\tLoss_G: 1.6961\tD(x_real): 0.8858\tD(x_fake): 0.1958\t\n",
            "[17/20][5/300]\tLoss_D_mask: 0.5338\tLoss_G: 1.7930\tD(x_real): 0.9537\tD(x_fake): 0.1676\t\n",
            "[17/20][10/300]\tLoss_D_mask: 0.8555\tLoss_G: 1.7333\tD(x_real): 0.9488\tD(x_fake): 0.2003\t\n",
            "[17/20][15/300]\tLoss_D_mask: 0.5159\tLoss_G: 1.7815\tD(x_real): 0.9576\tD(x_fake): 0.1706\t\n",
            "[17/20][20/300]\tLoss_D_mask: 0.6677\tLoss_G: 2.3073\tD(x_real): 0.8800\tD(x_fake): 0.0994\t\n",
            "[17/20][25/300]\tLoss_D_mask: 2.7712\tLoss_G: 1.7558\tD(x_real): 0.9320\tD(x_fake): 0.2449\t\n",
            "[17/20][30/300]\tLoss_D_mask: 0.7303\tLoss_G: 1.8342\tD(x_real): 0.8749\tD(x_fake): 0.1596\t\n",
            "[17/20][35/300]\tLoss_D_mask: 0.7814\tLoss_G: 1.3005\tD(x_real): 0.8957\tD(x_fake): 0.2926\t\n",
            "[17/20][40/300]\tLoss_D_mask: 1.3723\tLoss_G: 0.7432\tD(x_real): 0.9494\tD(x_fake): 0.3268\t\n",
            "[17/20][45/300]\tLoss_D_mask: 0.6516\tLoss_G: 1.5417\tD(x_real): 0.8260\tD(x_fake): 0.2300\t\n",
            "[17/20][50/300]\tLoss_D_mask: 0.7638\tLoss_G: 1.8036\tD(x_real): 0.7126\tD(x_fake): 0.1512\t\n",
            "[17/20][55/300]\tLoss_D_mask: 1.3776\tLoss_G: 0.8699\tD(x_real): 0.8958\tD(x_fake): 0.2898\t\n",
            "[17/20][60/300]\tLoss_D_mask: 0.7000\tLoss_G: 1.2342\tD(x_real): 0.9358\tD(x_fake): 0.3250\t\n",
            "[17/20][65/300]\tLoss_D_mask: 0.6747\tLoss_G: 1.2287\tD(x_real): 0.8930\tD(x_fake): 0.2887\t\n",
            "[17/20][70/300]\tLoss_D_mask: 0.8126\tLoss_G: 1.6899\tD(x_real): 0.7547\tD(x_fake): 0.1791\t\n",
            "[17/20][75/300]\tLoss_D_mask: 2.0886\tLoss_G: 1.4901\tD(x_real): 0.8655\tD(x_fake): 0.1672\t\n",
            "[17/20][80/300]\tLoss_D_mask: 0.7218\tLoss_G: 1.7861\tD(x_real): 0.7661\tD(x_fake): 0.1620\t\n",
            "[17/20][85/300]\tLoss_D_mask: 0.7606\tLoss_G: 1.5770\tD(x_real): 0.8228\tD(x_fake): 0.2082\t\n",
            "[17/20][90/300]\tLoss_D_mask: 0.6492\tLoss_G: 1.6181\tD(x_real): 0.8127\tD(x_fake): 0.2026\t\n",
            "[17/20][95/300]\tLoss_D_mask: 0.7603\tLoss_G: 1.8359\tD(x_real): 0.7932\tD(x_fake): 0.1464\t\n",
            "[17/20][100/300]\tLoss_D_mask: 0.6865\tLoss_G: 1.6984\tD(x_real): 0.8594\tD(x_fake): 0.1826\t\n",
            "[17/20][105/300]\tLoss_D_mask: 1.7133\tLoss_G: 1.2282\tD(x_real): 0.9061\tD(x_fake): 0.2162\t\n",
            "[17/20][110/300]\tLoss_D_mask: 0.6846\tLoss_G: 1.4617\tD(x_real): 0.9446\tD(x_fake): 0.2466\t\n",
            "[17/20][115/300]\tLoss_D_mask: 0.9523\tLoss_G: 1.5121\tD(x_real): 0.9410\tD(x_fake): 0.2423\t\n",
            "[17/20][120/300]\tLoss_D_mask: 0.6047\tLoss_G: 1.8422\tD(x_real): 0.9163\tD(x_fake): 0.1892\t\n",
            "[17/20][125/300]\tLoss_D_mask: 0.5010\tLoss_G: 1.2958\tD(x_real): 0.9211\tD(x_fake): 0.2519\t\n",
            "[17/20][130/300]\tLoss_D_mask: 0.0805\tLoss_G: 1.2071\tD(x_real): 0.9594\tD(x_fake): 0.2779\t\n",
            "[17/20][135/300]\tLoss_D_mask: 0.7001\tLoss_G: 1.6967\tD(x_real): 0.8660\tD(x_fake): 0.1948\t\n",
            "[17/20][140/300]\tLoss_D_mask: 0.5737\tLoss_G: 1.7274\tD(x_real): 0.9073\tD(x_fake): 0.1757\t\n",
            "[17/20][145/300]\tLoss_D_mask: 0.5018\tLoss_G: 2.0377\tD(x_real): 0.8502\tD(x_fake): 0.1379\t\n",
            "[17/20][150/300]\tLoss_D_mask: 0.5352\tLoss_G: 1.9267\tD(x_real): 0.9102\tD(x_fake): 0.1515\t\n",
            "[17/20][155/300]\tLoss_D_mask: 0.6664\tLoss_G: 1.1033\tD(x_real): 0.8877\tD(x_fake): 0.2914\t\n",
            "[17/20][160/300]\tLoss_D_mask: 1.9971\tLoss_G: 1.8146\tD(x_real): 0.8264\tD(x_fake): 0.2342\t\n",
            "[17/20][165/300]\tLoss_D_mask: 0.8682\tLoss_G: 1.8112\tD(x_real): 0.7458\tD(x_fake): 0.1489\t\n",
            "[17/20][170/300]\tLoss_D_mask: 0.6823\tLoss_G: 1.1529\tD(x_real): 0.9205\tD(x_fake): 0.2903\t\n",
            "[17/20][175/300]\tLoss_D_mask: 0.6914\tLoss_G: 1.5205\tD(x_real): 0.8791\tD(x_fake): 0.2396\t\n",
            "[17/20][180/300]\tLoss_D_mask: 0.7363\tLoss_G: 1.5398\tD(x_real): 0.9274\tD(x_fake): 0.2245\t\n",
            "[17/20][185/300]\tLoss_D_mask: 0.7225\tLoss_G: 1.8718\tD(x_real): 0.8331\tD(x_fake): 0.1543\t\n",
            "[17/20][190/300]\tLoss_D_mask: 0.7646\tLoss_G: 1.6919\tD(x_real): 0.9202\tD(x_fake): 0.1878\t\n",
            "[17/20][195/300]\tLoss_D_mask: 0.6855\tLoss_G: 1.7197\tD(x_real): 0.9148\tD(x_fake): 0.1799\t\n",
            "[17/20][200/300]\tLoss_D_mask: 0.6725\tLoss_G: 1.2941\tD(x_real): 0.9330\tD(x_fake): 0.2793\t\n",
            "[17/20][205/300]\tLoss_D_mask: 0.6153\tLoss_G: 1.5037\tD(x_real): 0.9520\tD(x_fake): 0.2411\t\n",
            "[17/20][210/300]\tLoss_D_mask: 0.7817\tLoss_G: 1.7540\tD(x_real): 0.9407\tD(x_fake): 0.1842\t\n",
            "[17/20][215/300]\tLoss_D_mask: 0.5659\tLoss_G: 1.6809\tD(x_real): 0.9098\tD(x_fake): 0.1849\t\n",
            "[17/20][220/300]\tLoss_D_mask: 0.8466\tLoss_G: 2.1306\tD(x_real): 0.8782\tD(x_fake): 0.1116\t\n",
            "[17/20][225/300]\tLoss_D_mask: 0.5294\tLoss_G: 1.7770\tD(x_real): 0.9202\tD(x_fake): 0.1672\t\n",
            "[17/20][230/300]\tLoss_D_mask: 0.6148\tLoss_G: 1.7272\tD(x_real): 0.9373\tD(x_fake): 0.1811\t\n",
            "[17/20][235/300]\tLoss_D_mask: 0.8017\tLoss_G: 1.8928\tD(x_real): 0.8573\tD(x_fake): 0.1466\t\n",
            "[17/20][240/300]\tLoss_D_mask: 0.6975\tLoss_G: 1.8197\tD(x_real): 0.9121\tD(x_fake): 0.1664\t\n",
            "[17/20][245/300]\tLoss_D_mask: 0.6703\tLoss_G: 1.8454\tD(x_real): 0.9267\tD(x_fake): 0.1600\t\n",
            "[17/20][250/300]\tLoss_D_mask: 0.6380\tLoss_G: 1.6845\tD(x_real): 0.9213\tD(x_fake): 0.2084\t\n",
            "[17/20][255/300]\tLoss_D_mask: 0.7379\tLoss_G: 2.0217\tD(x_real): 0.8567\tD(x_fake): 0.1443\t\n",
            "[17/20][260/300]\tLoss_D_mask: 0.6947\tLoss_G: 1.8790\tD(x_real): 0.8564\tD(x_fake): 0.1478\t\n",
            "[17/20][265/300]\tLoss_D_mask: 0.5672\tLoss_G: 1.6698\tD(x_real): 0.9323\tD(x_fake): 0.2006\t\n",
            "[17/20][270/300]\tLoss_D_mask: 0.6886\tLoss_G: 1.7829\tD(x_real): 0.9212\tD(x_fake): 0.1752\t\n",
            "[17/20][275/300]\tLoss_D_mask: 0.6078\tLoss_G: 1.8579\tD(x_real): 0.9209\tD(x_fake): 0.1559\t\n",
            "[17/20][280/300]\tLoss_D_mask: 0.2798\tLoss_G: 1.4253\tD(x_real): 0.9144\tD(x_fake): 0.2765\t\n",
            "[17/20][285/300]\tLoss_D_mask: 0.6932\tLoss_G: 1.9782\tD(x_real): 0.9503\tD(x_fake): 0.1429\t\n",
            "[17/20][290/300]\tLoss_D_mask: 0.7477\tLoss_G: 2.5551\tD(x_real): 0.8741\tD(x_fake): 0.0962\t\n",
            "[17/20][295/300]\tLoss_D_mask: 0.5850\tLoss_G: 2.0466\tD(x_real): 0.9274\tD(x_fake): 0.1229\t\n",
            "[18/20][0/300]\tLoss_D_mask: 0.7681\tLoss_G: 2.1894\tD(x_real): 0.8131\tD(x_fake): 0.1139\t\n",
            "[18/20][5/300]\tLoss_D_mask: 0.8210\tLoss_G: 2.3093\tD(x_real): 0.6645\tD(x_fake): 0.0808\t\n",
            "[18/20][10/300]\tLoss_D_mask: 0.6304\tLoss_G: 1.2064\tD(x_real): 0.8071\tD(x_fake): 0.2368\t\n",
            "[18/20][15/300]\tLoss_D_mask: 0.3892\tLoss_G: 1.1200\tD(x_real): 0.9326\tD(x_fake): 0.3945\t\n",
            "[18/20][20/300]\tLoss_D_mask: 0.7169\tLoss_G: 1.5416\tD(x_real): 0.8672\tD(x_fake): 0.2277\t\n",
            "[18/20][25/300]\tLoss_D_mask: 0.6802\tLoss_G: 1.8774\tD(x_real): 0.8989\tD(x_fake): 0.1541\t\n",
            "[18/20][30/300]\tLoss_D_mask: 0.9752\tLoss_G: 1.9924\tD(x_real): 0.8762\tD(x_fake): 0.1372\t\n",
            "[18/20][35/300]\tLoss_D_mask: 0.6275\tLoss_G: 1.5562\tD(x_real): 0.9103\tD(x_fake): 0.2109\t\n",
            "[18/20][40/300]\tLoss_D_mask: 0.5436\tLoss_G: 1.5162\tD(x_real): 0.9455\tD(x_fake): 0.3357\t\n",
            "[18/20][45/300]\tLoss_D_mask: 0.6377\tLoss_G: 1.8553\tD(x_real): 0.9344\tD(x_fake): 0.1550\t\n",
            "[18/20][50/300]\tLoss_D_mask: 0.7156\tLoss_G: 1.3874\tD(x_real): 0.8934\tD(x_fake): 0.2457\t\n",
            "[18/20][55/300]\tLoss_D_mask: 0.6127\tLoss_G: 1.6114\tD(x_real): 0.9310\tD(x_fake): 0.2143\t\n",
            "[18/20][60/300]\tLoss_D_mask: 0.2864\tLoss_G: 1.6926\tD(x_real): 0.9290\tD(x_fake): 0.1782\t\n",
            "[18/20][65/300]\tLoss_D_mask: 0.8023\tLoss_G: 1.6286\tD(x_real): 0.9565\tD(x_fake): 0.2237\t\n",
            "[18/20][70/300]\tLoss_D_mask: 0.5132\tLoss_G: 1.9011\tD(x_real): 0.9265\tD(x_fake): 0.1475\t\n",
            "[18/20][75/300]\tLoss_D_mask: 2.1209\tLoss_G: 1.5717\tD(x_real): 0.8941\tD(x_fake): 0.1299\t\n",
            "[18/20][80/300]\tLoss_D_mask: 0.7253\tLoss_G: 1.5093\tD(x_real): 0.9555\tD(x_fake): 0.2388\t\n",
            "[18/20][85/300]\tLoss_D_mask: 0.5866\tLoss_G: 1.9044\tD(x_real): 0.8185\tD(x_fake): 0.1292\t\n",
            "[18/20][90/300]\tLoss_D_mask: 0.5670\tLoss_G: 1.6624\tD(x_real): 0.9374\tD(x_fake): 0.1906\t\n",
            "[18/20][95/300]\tLoss_D_mask: 0.6424\tLoss_G: 1.6410\tD(x_real): 0.8520\tD(x_fake): 0.1946\t\n",
            "[18/20][100/300]\tLoss_D_mask: 0.7357\tLoss_G: 1.3417\tD(x_real): 0.9598\tD(x_fake): 0.2933\t\n",
            "[18/20][105/300]\tLoss_D_mask: 0.6398\tLoss_G: 1.6568\tD(x_real): 0.9428\tD(x_fake): 0.2014\t\n",
            "[18/20][110/300]\tLoss_D_mask: 3.2723\tLoss_G: 2.0313\tD(x_real): 0.9574\tD(x_fake): 0.1766\t\n",
            "[18/20][115/300]\tLoss_D_mask: 0.7790\tLoss_G: 2.0125\tD(x_real): 0.8892\tD(x_fake): 0.1261\t\n",
            "[18/20][120/300]\tLoss_D_mask: 0.4960\tLoss_G: 1.6994\tD(x_real): 0.9029\tD(x_fake): 0.1702\t\n",
            "[18/20][125/300]\tLoss_D_mask: 0.4789\tLoss_G: 1.8802\tD(x_real): 0.9466\tD(x_fake): 0.1470\t\n",
            "[18/20][130/300]\tLoss_D_mask: 0.5727\tLoss_G: 1.7724\tD(x_real): 0.9630\tD(x_fake): 0.1831\t\n",
            "[18/20][135/300]\tLoss_D_mask: 0.4339\tLoss_G: 1.8021\tD(x_real): 0.9583\tD(x_fake): 0.1716\t\n",
            "[18/20][140/300]\tLoss_D_mask: 0.7050\tLoss_G: 2.0686\tD(x_real): 0.8727\tD(x_fake): 0.1223\t\n",
            "[18/20][145/300]\tLoss_D_mask: 0.6962\tLoss_G: 1.4212\tD(x_real): 0.9364\tD(x_fake): 0.2578\t\n",
            "[18/20][150/300]\tLoss_D_mask: 1.2092\tLoss_G: 17.2549\tD(x_real): 0.9138\tD(x_fake): 0.7875\t\n",
            "[18/20][155/300]\tLoss_D_mask: 2.6686\tLoss_G: 1.7574\tD(x_real): 0.9154\tD(x_fake): 0.2792\t\n",
            "[18/20][160/300]\tLoss_D_mask: 0.7307\tLoss_G: 1.7783\tD(x_real): 0.8693\tD(x_fake): 0.1678\t\n",
            "[18/20][165/300]\tLoss_D_mask: 0.4468\tLoss_G: 1.2412\tD(x_real): 0.9456\tD(x_fake): 0.2564\t\n",
            "[18/20][170/300]\tLoss_D_mask: 0.6710\tLoss_G: 1.6283\tD(x_real): 0.9277\tD(x_fake): 0.2081\t\n",
            "[18/20][175/300]\tLoss_D_mask: 2.5551\tLoss_G: 2.0740\tD(x_real): 0.9158\tD(x_fake): 0.1816\t\n",
            "[18/20][180/300]\tLoss_D_mask: 0.5650\tLoss_G: 1.5079\tD(x_real): 0.8917\tD(x_fake): 0.2244\t\n",
            "[18/20][185/300]\tLoss_D_mask: 0.7084\tLoss_G: 1.6412\tD(x_real): 0.8342\tD(x_fake): 0.1972\t\n",
            "[18/20][190/300]\tLoss_D_mask: 0.7187\tLoss_G: 2.0863\tD(x_real): 0.8009\tD(x_fake): 0.1186\t\n",
            "[18/20][195/300]\tLoss_D_mask: 0.8676\tLoss_G: 1.8332\tD(x_real): 0.9143\tD(x_fake): 0.1655\t\n",
            "[18/20][200/300]\tLoss_D_mask: 0.7946\tLoss_G: 1.9377\tD(x_real): 0.9074\tD(x_fake): 0.1445\t\n",
            "[18/20][205/300]\tLoss_D_mask: 0.8760\tLoss_G: 1.4702\tD(x_real): 0.9472\tD(x_fake): 0.2719\t\n",
            "[18/20][210/300]\tLoss_D_mask: 0.6528\tLoss_G: 1.8423\tD(x_real): 0.9381\tD(x_fake): 0.1629\t\n",
            "[18/20][215/300]\tLoss_D_mask: 0.6601\tLoss_G: 1.8955\tD(x_real): 0.9028\tD(x_fake): 0.1473\t\n",
            "[18/20][220/300]\tLoss_D_mask: 0.8278\tLoss_G: 1.3472\tD(x_real): 0.9626\tD(x_fake): 0.2806\t\n",
            "[18/20][225/300]\tLoss_D_mask: 2.0241\tLoss_G: 1.3283\tD(x_real): 0.9397\tD(x_fake): 0.1849\t\n",
            "[18/20][230/300]\tLoss_D_mask: 0.5518\tLoss_G: 1.4690\tD(x_real): 0.9196\tD(x_fake): 0.2421\t\n",
            "[18/20][235/300]\tLoss_D_mask: 0.5952\tLoss_G: 2.1111\tD(x_real): 0.9069\tD(x_fake): 0.1431\t\n",
            "[18/20][240/300]\tLoss_D_mask: 0.6045\tLoss_G: 1.9122\tD(x_real): 0.8890\tD(x_fake): 0.1439\t\n",
            "[18/20][245/300]\tLoss_D_mask: 0.4633\tLoss_G: 1.9925\tD(x_real): 0.8885\tD(x_fake): 0.1306\t\n",
            "[18/20][250/300]\tLoss_D_mask: 0.5438\tLoss_G: 1.8361\tD(x_real): 0.9254\tD(x_fake): 0.1584\t\n",
            "[18/20][255/300]\tLoss_D_mask: 0.7273\tLoss_G: 1.8579\tD(x_real): 0.8848\tD(x_fake): 0.1580\t\n",
            "[18/20][260/300]\tLoss_D_mask: 0.6301\tLoss_G: 2.2143\tD(x_real): 0.9076\tD(x_fake): 0.1235\t\n",
            "[18/20][265/300]\tLoss_D_mask: 0.8494\tLoss_G: 1.8821\tD(x_real): 0.6870\tD(x_fake): 0.1196\t\n",
            "[18/20][270/300]\tLoss_D_mask: 0.7288\tLoss_G: 2.1301\tD(x_real): 0.8625\tD(x_fake): 0.1297\t\n",
            "[18/20][275/300]\tLoss_D_mask: 0.7842\tLoss_G: 1.5655\tD(x_real): 0.8916\tD(x_fake): 0.2175\t\n",
            "[18/20][280/300]\tLoss_D_mask: 0.5861\tLoss_G: 1.6990\tD(x_real): 0.9168\tD(x_fake): 0.1868\t\n",
            "[18/20][285/300]\tLoss_D_mask: 0.6476\tLoss_G: 1.6784\tD(x_real): 0.9377\tD(x_fake): 0.1901\t\n",
            "[18/20][290/300]\tLoss_D_mask: 0.6035\tLoss_G: 2.0125\tD(x_real): 0.9251\tD(x_fake): 0.1337\t\n",
            "[18/20][295/300]\tLoss_D_mask: 0.6680\tLoss_G: 2.2461\tD(x_real): 0.8443\tD(x_fake): 0.1062\t\n",
            "[19/20][0/300]\tLoss_D_mask: 0.7960\tLoss_G: 1.7052\tD(x_real): 0.9169\tD(x_fake): 0.1940\t\n",
            "[19/20][5/300]\tLoss_D_mask: 0.5198\tLoss_G: 2.0408\tD(x_real): 0.8786\tD(x_fake): 0.1244\t\n",
            "[19/20][10/300]\tLoss_D_mask: 0.6962\tLoss_G: 1.3901\tD(x_real): 0.9081\tD(x_fake): 0.2487\t\n",
            "[19/20][15/300]\tLoss_D_mask: 0.8749\tLoss_G: 1.5797\tD(x_real): 0.9111\tD(x_fake): 0.2225\t\n",
            "[19/20][20/300]\tLoss_D_mask: 0.5821\tLoss_G: 1.7535\tD(x_real): 0.9018\tD(x_fake): 0.1728\t\n",
            "[19/20][25/300]\tLoss_D_mask: 0.5712\tLoss_G: 1.6973\tD(x_real): 0.9371\tD(x_fake): 0.1866\t\n",
            "[19/20][30/300]\tLoss_D_mask: 0.5153\tLoss_G: 1.6108\tD(x_real): 0.9320\tD(x_fake): 0.2017\t\n",
            "[19/20][35/300]\tLoss_D_mask: 0.7612\tLoss_G: 1.7732\tD(x_real): 0.9413\tD(x_fake): 0.1728\t\n",
            "[19/20][40/300]\tLoss_D_mask: 0.7680\tLoss_G: 1.4936\tD(x_real): 0.9517\tD(x_fake): 0.2685\t\n",
            "[19/20][45/300]\tLoss_D_mask: 0.5610\tLoss_G: 1.7030\tD(x_real): 0.9418\tD(x_fake): 0.1759\t\n",
            "[19/20][50/300]\tLoss_D_mask: 0.4399\tLoss_G: 1.6262\tD(x_real): 0.9592\tD(x_fake): 0.1969\t\n",
            "[19/20][55/300]\tLoss_D_mask: 0.7641\tLoss_G: 1.7379\tD(x_real): 0.9608\tD(x_fake): 0.1817\t\n",
            "[19/20][60/300]\tLoss_D_mask: 0.6321\tLoss_G: 2.0503\tD(x_real): 0.9535\tD(x_fake): 0.1278\t\n",
            "[19/20][65/300]\tLoss_D_mask: 0.7394\tLoss_G: 1.4182\tD(x_real): 0.9677\tD(x_fake): 0.2122\t\n",
            "[19/20][70/300]\tLoss_D_mask: 0.4193\tLoss_G: 1.4817\tD(x_real): 0.9537\tD(x_fake): 0.2395\t\n",
            "[19/20][75/300]\tLoss_D_mask: 2.8835\tLoss_G: 1.9325\tD(x_real): 0.9460\tD(x_fake): 0.2080\t\n",
            "[19/20][80/300]\tLoss_D_mask: 0.6782\tLoss_G: 1.8695\tD(x_real): 0.8983\tD(x_fake): 0.1459\t\n",
            "[19/20][85/300]\tLoss_D_mask: 0.6664\tLoss_G: 1.9286\tD(x_real): 0.9157\tD(x_fake): 0.1454\t\n",
            "[19/20][90/300]\tLoss_D_mask: 2.5102\tLoss_G: 44.1965\tD(x_real): 0.9078\tD(x_fake): 0.1578\t\n",
            "[19/20][95/300]\tLoss_D_mask: 0.7026\tLoss_G: 1.9247\tD(x_real): 0.8092\tD(x_fake): 0.1332\t\n",
            "[19/20][100/300]\tLoss_D_mask: 0.6098\tLoss_G: 2.0892\tD(x_real): 0.8636\tD(x_fake): 0.1377\t\n",
            "[19/20][105/300]\tLoss_D_mask: 0.6874\tLoss_G: 2.0994\tD(x_real): 0.8546\tD(x_fake): 0.1214\t\n",
            "[19/20][110/300]\tLoss_D_mask: 0.3866\tLoss_G: 1.6561\tD(x_real): 0.9234\tD(x_fake): 0.1888\t\n",
            "[19/20][115/300]\tLoss_D_mask: 2.7448\tLoss_G: 2.2929\tD(x_real): 0.9409\tD(x_fake): 0.1328\t\n",
            "[19/20][120/300]\tLoss_D_mask: 0.6371\tLoss_G: 1.7165\tD(x_real): 0.8849\tD(x_fake): 0.1739\t\n",
            "[19/20][125/300]\tLoss_D_mask: 0.5869\tLoss_G: 1.9810\tD(x_real): 0.9101\tD(x_fake): 0.1384\t\n",
            "[19/20][130/300]\tLoss_D_mask: 0.6230\tLoss_G: 1.8321\tD(x_real): 0.9291\tD(x_fake): 0.1623\t\n",
            "[19/20][135/300]\tLoss_D_mask: 0.7001\tLoss_G: 1.6607\tD(x_real): 0.9191\tD(x_fake): 0.1811\t\n",
            "[19/20][140/300]\tLoss_D_mask: 1.3693\tLoss_G: 0.9652\tD(x_real): 0.9320\tD(x_fake): 0.2983\t\n",
            "[19/20][145/300]\tLoss_D_mask: 0.7748\tLoss_G: 1.3605\tD(x_real): 0.9245\tD(x_fake): 0.2926\t\n",
            "[19/20][150/300]\tLoss_D_mask: 0.9252\tLoss_G: 1.5885\tD(x_real): 0.8836\tD(x_fake): 0.2060\t\n",
            "[19/20][155/300]\tLoss_D_mask: 0.7203\tLoss_G: 1.6159\tD(x_real): 0.8184\tD(x_fake): 0.2010\t\n",
            "[19/20][160/300]\tLoss_D_mask: 0.6778\tLoss_G: 1.5655\tD(x_real): 0.8785\tD(x_fake): 0.2146\t\n",
            "[19/20][165/300]\tLoss_D_mask: 0.7100\tLoss_G: 1.8667\tD(x_real): 0.8502\tD(x_fake): 0.1423\t\n",
            "[19/20][170/300]\tLoss_D_mask: 0.7103\tLoss_G: 1.5941\tD(x_real): 0.9457\tD(x_fake): 0.2260\t\n",
            "[19/20][175/300]\tLoss_D_mask: 1.7919\tLoss_G: 1.3751\tD(x_real): 0.9449\tD(x_fake): 0.1790\t\n",
            "[19/20][180/300]\tLoss_D_mask: 0.7225\tLoss_G: 1.8336\tD(x_real): 0.8949\tD(x_fake): 0.1601\t\n",
            "[19/20][185/300]\tLoss_D_mask: 0.8975\tLoss_G: 1.8793\tD(x_real): 0.8378\tD(x_fake): 0.1540\t\n",
            "[19/20][190/300]\tLoss_D_mask: 0.8094\tLoss_G: 2.1525\tD(x_real): 0.6601\tD(x_fake): 0.1016\t\n",
            "[19/20][195/300]\tLoss_D_mask: 0.7076\tLoss_G: 1.5038\tD(x_real): 0.9262\tD(x_fake): 0.2437\t\n",
            "[19/20][200/300]\tLoss_D_mask: 2.4390\tLoss_G: 2.1522\tD(x_real): 0.9071\tD(x_fake): 0.1652\t\n",
            "[19/20][205/300]\tLoss_D_mask: 0.8331\tLoss_G: 2.0113\tD(x_real): 0.8039\tD(x_fake): 0.1159\t\n",
            "[19/20][210/300]\tLoss_D_mask: 0.7108\tLoss_G: 2.1314\tD(x_real): 0.7660\tD(x_fake): 0.1130\t\n",
            "[19/20][215/300]\tLoss_D_mask: 0.5768\tLoss_G: 1.6622\tD(x_real): 0.8955\tD(x_fake): 0.1865\t\n",
            "[19/20][220/300]\tLoss_D_mask: 0.6697\tLoss_G: 1.7150\tD(x_real): 0.9105\tD(x_fake): 0.1764\t\n",
            "[19/20][225/300]\tLoss_D_mask: 0.5274\tLoss_G: 1.9638\tD(x_real): 0.9133\tD(x_fake): 0.1386\t\n",
            "[19/20][230/300]\tLoss_D_mask: 0.5930\tLoss_G: 1.8340\tD(x_real): 0.9119\tD(x_fake): 0.1681\t\n",
            "[19/20][235/300]\tLoss_D_mask: 0.6263\tLoss_G: 1.8358\tD(x_real): 0.9373\tD(x_fake): 0.1608\t\n",
            "[19/20][240/300]\tLoss_D_mask: 0.6279\tLoss_G: 1.8149\tD(x_real): 0.9341\tD(x_fake): 0.1635\t\n",
            "[19/20][245/300]\tLoss_D_mask: 0.2490\tLoss_G: 1.8685\tD(x_real): 0.9374\tD(x_fake): 0.1639\t\n",
            "[19/20][250/300]\tLoss_D_mask: 0.5858\tLoss_G: 1.7907\tD(x_real): 0.9391\tD(x_fake): 0.1639\t\n",
            "[19/20][255/300]\tLoss_D_mask: 0.8875\tLoss_G: 1.6616\tD(x_real): 0.9616\tD(x_fake): 0.1998\t\n",
            "[19/20][260/300]\tLoss_D_mask: 0.9922\tLoss_G: 2.0583\tD(x_real): 0.9498\tD(x_fake): 0.1329\t\n",
            "[19/20][265/300]\tLoss_D_mask: 0.6279\tLoss_G: 2.2960\tD(x_real): 0.8696\tD(x_fake): 0.1161\t\n",
            "[19/20][270/300]\tLoss_D_mask: 0.6917\tLoss_G: 1.3687\tD(x_real): 0.9323\tD(x_fake): 0.2188\t\n",
            "[19/20][275/300]\tLoss_D_mask: 0.7746\tLoss_G: 1.5967\tD(x_real): 0.9230\tD(x_fake): 0.2220\t\n",
            "[19/20][280/300]\tLoss_D_mask: 0.7276\tLoss_G: 1.3137\tD(x_real): 0.9532\tD(x_fake): 0.2959\t\n",
            "[19/20][285/300]\tLoss_D_mask: 0.6114\tLoss_G: 2.1462\tD(x_real): 0.8275\tD(x_fake): 0.1283\t\n",
            "[19/20][290/300]\tLoss_D_mask: 0.4870\tLoss_G: 1.4542\tD(x_real): 0.8526\tD(x_fake): 0.2219\t\n",
            "[19/20][295/300]\tLoss_D_mask: 0.7085\tLoss_G: 1.6102\tD(x_real): 0.9155\tD(x_fake): 0.2010\t\n",
            "[20/20][0/300]\tLoss_D_mask: 2.3509\tLoss_G: 1.4766\tD(x_real): 0.8088\tD(x_fake): 0.1420\t\n",
            "[20/20][5/300]\tLoss_D_mask: 1.8330\tLoss_G: 1.3114\tD(x_real): 0.8947\tD(x_fake): 0.1854\t\n",
            "[20/20][10/300]\tLoss_D_mask: 0.7137\tLoss_G: 43.4636\tD(x_real): 0.9380\tD(x_fake): 0.2786\t\n",
            "[20/20][15/300]\tLoss_D_mask: 0.5653\tLoss_G: 1.5264\tD(x_real): 0.9151\tD(x_fake): 0.2285\t\n",
            "[20/20][20/300]\tLoss_D_mask: 0.6228\tLoss_G: 1.2715\tD(x_real): 0.9435\tD(x_fake): 0.3011\t\n",
            "[20/20][25/300]\tLoss_D_mask: 0.5761\tLoss_G: 1.6242\tD(x_real): 0.9323\tD(x_fake): 0.2036\t\n",
            "[20/20][30/300]\tLoss_D_mask: 0.5957\tLoss_G: 1.7652\tD(x_real): 0.8913\tD(x_fake): 0.1649\t\n",
            "[20/20][35/300]\tLoss_D_mask: 0.6688\tLoss_G: 1.4358\tD(x_real): 0.9407\tD(x_fake): 0.2536\t\n",
            "[20/20][40/300]\tLoss_D_mask: 0.6717\tLoss_G: 1.7016\tD(x_real): 0.9295\tD(x_fake): 0.1962\t\n",
            "[20/20][45/300]\tLoss_D_mask: 0.6479\tLoss_G: 1.7883\tD(x_real): 0.9373\tD(x_fake): 0.1719\t\n",
            "[20/20][50/300]\tLoss_D_mask: 0.7028\tLoss_G: 1.7712\tD(x_real): 0.9299\tD(x_fake): 0.1739\t\n",
            "[20/20][55/300]\tLoss_D_mask: 0.5632\tLoss_G: 1.3906\tD(x_real): 0.9527\tD(x_fake): 0.2580\t\n",
            "[20/20][60/300]\tLoss_D_mask: 0.5529\tLoss_G: 1.7044\tD(x_real): 0.9493\tD(x_fake): 0.1936\t\n",
            "[20/20][65/300]\tLoss_D_mask: 0.6029\tLoss_G: 2.2650\tD(x_real): 0.9085\tD(x_fake): 0.1169\t\n",
            "[20/20][70/300]\tLoss_D_mask: 0.6117\tLoss_G: 1.9399\tD(x_real): 0.9338\tD(x_fake): 0.1361\t\n",
            "[20/20][75/300]\tLoss_D_mask: 0.6422\tLoss_G: 1.7217\tD(x_real): 0.8983\tD(x_fake): 0.1771\t\n",
            "[20/20][80/300]\tLoss_D_mask: 0.6160\tLoss_G: 1.4499\tD(x_real): 0.9355\tD(x_fake): 0.2487\t\n",
            "[20/20][85/300]\tLoss_D_mask: 0.7657\tLoss_G: 2.3166\tD(x_real): 0.7632\tD(x_fake): 0.1384\t\n",
            "[20/20][90/300]\tLoss_D_mask: 1.1042\tLoss_G: 2.4615\tD(x_real): 0.5396\tD(x_fake): 0.0851\t\n",
            "[20/20][95/300]\tLoss_D_mask: 0.7865\tLoss_G: 1.6934\tD(x_real): 0.8775\tD(x_fake): 0.1840\t\n",
            "[20/20][100/300]\tLoss_D_mask: 1.5497\tLoss_G: 1.0858\tD(x_real): 0.9414\tD(x_fake): 0.7081\t\n",
            "[20/20][105/300]\tLoss_D_mask: 0.5542\tLoss_G: 1.5605\tD(x_real): 0.8808\tD(x_fake): 0.2171\t\n",
            "[20/20][110/300]\tLoss_D_mask: 0.5787\tLoss_G: 1.2855\tD(x_real): 0.9344\tD(x_fake): 0.2957\t\n",
            "[20/20][115/300]\tLoss_D_mask: 2.9126\tLoss_G: 1.7377\tD(x_real): 0.9370\tD(x_fake): 0.2278\t\n",
            "[20/20][120/300]\tLoss_D_mask: 0.7100\tLoss_G: 1.9608\tD(x_real): 0.8570\tD(x_fake): 0.1372\t\n",
            "[20/20][125/300]\tLoss_D_mask: 0.8896\tLoss_G: 0.9266\tD(x_real): 0.9517\tD(x_fake): 0.4244\t\n",
            "[20/20][130/300]\tLoss_D_mask: 0.7571\tLoss_G: 1.6952\tD(x_real): 0.8417\tD(x_fake): 0.2007\t\n",
            "[20/20][135/300]\tLoss_D_mask: 0.8401\tLoss_G: 1.7753\tD(x_real): 0.8919\tD(x_fake): 0.1760\t\n",
            "[20/20][140/300]\tLoss_D_mask: 0.6387\tLoss_G: 1.7324\tD(x_real): 0.9097\tD(x_fake): 0.1791\t\n",
            "[20/20][145/300]\tLoss_D_mask: 0.7011\tLoss_G: 1.7634\tD(x_real): 0.9315\tD(x_fake): 0.1755\t\n",
            "[20/20][150/300]\tLoss_D_mask: 0.5297\tLoss_G: 1.6256\tD(x_real): 0.9489\tD(x_fake): 0.2010\t\n",
            "[20/20][155/300]\tLoss_D_mask: 0.5420\tLoss_G: 1.3095\tD(x_real): 0.9467\tD(x_fake): 0.2967\t\n",
            "[20/20][160/300]\tLoss_D_mask: 0.7795\tLoss_G: 2.0882\tD(x_real): 0.8446\tD(x_fake): 0.1407\t\n",
            "[20/20][165/300]\tLoss_D_mask: 0.7932\tLoss_G: 1.8143\tD(x_real): 0.8147\tD(x_fake): 0.1562\t\n",
            "[20/20][170/300]\tLoss_D_mask: 0.7716\tLoss_G: 0.9072\tD(x_real): 0.9624\tD(x_fake): 0.4376\t\n",
            "[20/20][175/300]\tLoss_D_mask: 0.6804\tLoss_G: 1.6242\tD(x_real): 0.8770\tD(x_fake): 0.2313\t\n",
            "[20/20][180/300]\tLoss_D_mask: 1.5932\tLoss_G: 1.3547\tD(x_real): 0.8906\tD(x_fake): 0.1909\t\n",
            "[20/20][185/300]\tLoss_D_mask: 0.8703\tLoss_G: 1.3451\tD(x_real): 0.9446\tD(x_fake): 0.2916\t\n",
            "[20/20][190/300]\tLoss_D_mask: 0.6070\tLoss_G: 1.7887\tD(x_real): 0.9140\tD(x_fake): 0.1766\t\n",
            "[20/20][195/300]\tLoss_D_mask: 2.3827\tLoss_G: 1.5779\tD(x_real): 0.8180\tD(x_fake): 0.1476\t\n",
            "[20/20][200/300]\tLoss_D_mask: 0.5548\tLoss_G: 1.5615\tD(x_real): 0.9103\tD(x_fake): 0.2165\t\n",
            "[20/20][205/300]\tLoss_D_mask: 0.5261\tLoss_G: 1.5962\tD(x_real): 0.9097\tD(x_fake): 0.2059\t\n",
            "[20/20][210/300]\tLoss_D_mask: 0.7163\tLoss_G: 1.7747\tD(x_real): 0.9198\tD(x_fake): 0.1774\t\n",
            "[20/20][215/300]\tLoss_D_mask: 2.5484\tLoss_G: 2.1071\tD(x_real): 0.9170\tD(x_fake): 0.1561\t\n",
            "[20/20][220/300]\tLoss_D_mask: 0.5294\tLoss_G: 1.8395\tD(x_real): 0.8783\tD(x_fake): 0.1490\t\n",
            "[20/20][225/300]\tLoss_D_mask: 0.5730\tLoss_G: 1.5157\tD(x_real): 0.9379\tD(x_fake): 0.2353\t\n",
            "[20/20][230/300]\tLoss_D_mask: 0.6123\tLoss_G: 1.6082\tD(x_real): 0.9374\tD(x_fake): 0.2102\t\n",
            "[20/20][235/300]\tLoss_D_mask: 0.6296\tLoss_G: 1.6771\tD(x_real): 0.9332\tD(x_fake): 0.1915\t\n",
            "[20/20][240/300]\tLoss_D_mask: 2.8980\tLoss_G: 2.0705\tD(x_real): 0.9450\tD(x_fake): 0.1620\t\n",
            "[20/20][245/300]\tLoss_D_mask: 0.8572\tLoss_G: 1.9964\tD(x_real): 0.8726\tD(x_fake): 0.1293\t\n",
            "[20/20][250/300]\tLoss_D_mask: 0.6958\tLoss_G: 1.6457\tD(x_real): 0.8951\tD(x_fake): 0.1929\t\n",
            "[20/20][255/300]\tLoss_D_mask: 0.7101\tLoss_G: 2.2466\tD(x_real): 0.8226\tD(x_fake): 0.1169\t\n",
            "[20/20][260/300]\tLoss_D_mask: 0.6966\tLoss_G: 1.7653\tD(x_real): 0.8655\tD(x_fake): 0.1648\t\n",
            "[20/20][265/300]\tLoss_D_mask: 0.1810\tLoss_G: 1.6860\tD(x_real): 0.9394\tD(x_fake): 0.1850\t\n",
            "[20/20][270/300]\tLoss_D_mask: 1.4080\tLoss_G: 0.9801\tD(x_real): 0.9589\tD(x_fake): 0.2698\t\n",
            "[20/20][275/300]\tLoss_D_mask: 0.5245\tLoss_G: 1.4743\tD(x_real): 0.9463\tD(x_fake): 0.2496\t\n",
            "[20/20][280/300]\tLoss_D_mask: 0.7650\tLoss_G: 1.7515\tD(x_real): 0.9503\tD(x_fake): 0.1823\t\n",
            "[20/20][285/300]\tLoss_D_mask: 0.5792\tLoss_G: 1.7282\tD(x_real): 0.9538\tD(x_fake): 0.1766\t\n",
            "[20/20][290/300]\tLoss_D_mask: 0.7467\tLoss_G: 1.5078\tD(x_real): 0.7488\tD(x_fake): 0.2040\t\n",
            "[20/20][295/300]\tLoss_D_mask: 0.8123\tLoss_G: 1.4357\tD(x_real): 0.9288\tD(x_fake): 0.2704\t\n",
            "models saved correctly\n",
            "[21/20][0/300]\tLoss_D_mask: 1.8042\tLoss_G: 1.2456\tD(x_real): 0.9265\tD(x_fake): 0.1927\t\n",
            "[21/20][5/300]\tLoss_D_mask: 0.5644\tLoss_G: 1.4805\tD(x_real): 0.9311\tD(x_fake): 0.2432\t\n",
            "[21/20][10/300]\tLoss_D_mask: 1.0506\tLoss_G: 1.2190\tD(x_real): 0.5523\tD(x_fake): 0.2198\t\n",
            "[21/20][15/300]\tLoss_D_mask: 2.6220\tLoss_G: 2.0269\tD(x_real): 0.9121\tD(x_fake): 0.2046\t\n",
            "[21/20][20/300]\tLoss_D_mask: 0.6578\tLoss_G: 1.6743\tD(x_real): 0.8438\tD(x_fake): 0.1723\t\n",
            "[21/20][25/300]\tLoss_D_mask: 0.7802\tLoss_G: 1.8028\tD(x_real): 0.9103\tD(x_fake): 0.1841\t\n",
            "[21/20][30/300]\tLoss_D_mask: 0.6540\tLoss_G: 1.5528\tD(x_real): 0.9334\tD(x_fake): 0.2243\t\n",
            "[21/20][35/300]\tLoss_D_mask: 0.5162\tLoss_G: 1.7894\tD(x_real): 0.9385\tD(x_fake): 0.1694\t\n",
            "[21/20][40/300]\tLoss_D_mask: 0.7365\tLoss_G: 1.7352\tD(x_real): 0.9373\tD(x_fake): 0.1797\t\n",
            "[21/20][45/300]\tLoss_D_mask: 0.5192\tLoss_G: 1.7879\tD(x_real): 0.9432\tD(x_fake): 0.1672\t\n",
            "[21/20][50/300]\tLoss_D_mask: 0.6277\tLoss_G: 1.7575\tD(x_real): 0.9519\tD(x_fake): 0.1787\t\n",
            "[21/20][55/300]\tLoss_D_mask: 0.8278\tLoss_G: 2.1152\tD(x_real): 0.7868\tD(x_fake): 0.1516\t\n",
            "[21/20][60/300]\tLoss_D_mask: 0.7252\tLoss_G: 1.9764\tD(x_real): 0.9157\tD(x_fake): 0.1353\t\n",
            "[21/20][65/300]\tLoss_D_mask: 0.5792\tLoss_G: 1.9486\tD(x_real): 0.9073\tD(x_fake): 0.1387\t\n",
            "[21/20][70/300]\tLoss_D_mask: 0.7200\tLoss_G: 2.2123\tD(x_real): 0.8764\tD(x_fake): 0.1179\t\n",
            "[21/20][75/300]\tLoss_D_mask: 0.6097\tLoss_G: 1.8511\tD(x_real): 0.8993\tD(x_fake): 0.1550\t\n",
            "[21/20][80/300]\tLoss_D_mask: 0.7741\tLoss_G: 1.7261\tD(x_real): 0.9289\tD(x_fake): 0.1852\t\n",
            "[21/20][85/300]\tLoss_D_mask: 0.7379\tLoss_G: 1.7992\tD(x_real): 0.9494\tD(x_fake): 0.1710\t\n",
            "[21/20][90/300]\tLoss_D_mask: 3.2366\tLoss_G: 1.5878\tD(x_real): 0.9614\tD(x_fake): 0.2785\t\n",
            "[21/20][95/300]\tLoss_D_mask: 0.5515\tLoss_G: 1.3551\tD(x_real): 0.9317\tD(x_fake): 0.2574\t\n",
            "[21/20][100/300]\tLoss_D_mask: 0.7472\tLoss_G: 1.8073\tD(x_real): 0.8519\tD(x_fake): 0.1628\t\n",
            "[21/20][105/300]\tLoss_D_mask: 0.7081\tLoss_G: 1.4429\tD(x_real): 0.8422\tD(x_fake): 0.2030\t\n",
            "[21/20][110/300]\tLoss_D_mask: 0.5739\tLoss_G: 1.1434\tD(x_real): 0.9278\tD(x_fake): 0.3311\t\n",
            "[21/20][115/300]\tLoss_D_mask: 0.5516\tLoss_G: 1.5744\tD(x_real): 0.8352\tD(x_fake): 0.2053\t\n",
            "[21/20][120/300]\tLoss_D_mask: 0.5961\tLoss_G: 1.6749\tD(x_real): 0.8956\tD(x_fake): 0.1879\t\n",
            "[21/20][125/300]\tLoss_D_mask: 2.8559\tLoss_G: 1.4261\tD(x_real): 0.9416\tD(x_fake): 0.2662\t\n",
            "[21/20][130/300]\tLoss_D_mask: 0.7229\tLoss_G: 1.4729\tD(x_real): 0.8556\tD(x_fake): 0.2343\t\n",
            "[21/20][135/300]\tLoss_D_mask: 2.2430\tLoss_G: 2.1396\tD(x_real): 0.8995\tD(x_fake): 0.1834\t\n",
            "[21/20][140/300]\tLoss_D_mask: 0.6195\tLoss_G: 1.7650\tD(x_real): 0.8543\tD(x_fake): 0.1622\t\n",
            "[21/20][145/300]\tLoss_D_mask: 0.5876\tLoss_G: 1.5882\tD(x_real): 0.8913\tD(x_fake): 0.2016\t\n",
            "[21/20][155/300]\tLoss_D_mask: 0.7009\tLoss_G: 1.6927\tD(x_real): 0.9107\tD(x_fake): 0.1857\t\n",
            "[21/20][160/300]\tLoss_D_mask: 0.6529\tLoss_G: 1.7337\tD(x_real): 0.9352\tD(x_fake): 0.1822\t\n",
            "[21/20][165/300]\tLoss_D_mask: 0.6920\tLoss_G: 1.6015\tD(x_real): 0.9496\tD(x_fake): 0.2182\t\n",
            "[21/20][170/300]\tLoss_D_mask: 2.5373\tLoss_G: 2.0696\tD(x_real): 0.9011\tD(x_fake): 0.1765\t\n",
            "[21/20][175/300]\tLoss_D_mask: 0.6965\tLoss_G: 2.0042\tD(x_real): 0.9214\tD(x_fake): 0.1319\t\n",
            "[21/20][180/300]\tLoss_D_mask: 0.5357\tLoss_G: 1.3350\tD(x_real): 0.9070\tD(x_fake): 0.2226\t\n",
            "[21/20][185/300]\tLoss_D_mask: 0.5801\tLoss_G: 1.3901\tD(x_real): 0.9543\tD(x_fake): 0.2646\t\n",
            "[21/20][190/300]\tLoss_D_mask: 3.4695\tLoss_G: 1.6974\tD(x_real): 0.9598\tD(x_fake): 0.3783\t\n",
            "[21/20][195/300]\tLoss_D_mask: 0.8634\tLoss_G: 1.4400\tD(x_real): 0.7556\tD(x_fake): 0.2217\t\n",
            "[21/20][200/300]\tLoss_D_mask: 0.7585\tLoss_G: 1.5631\tD(x_real): 0.9035\tD(x_fake): 0.2172\t\n",
            "[21/20][205/300]\tLoss_D_mask: 0.6986\tLoss_G: 1.7345\tD(x_real): 0.9152\tD(x_fake): 0.1872\t\n",
            "[21/20][210/300]\tLoss_D_mask: 2.5619\tLoss_G: 1.8678\tD(x_real): 0.9057\tD(x_fake): 0.2329\t\n",
            "[21/20][215/300]\tLoss_D_mask: 0.7131\tLoss_G: 2.0243\tD(x_real): 0.8185\tD(x_fake): 0.1277\t\n",
            "[21/20][220/300]\tLoss_D_mask: 0.7658\tLoss_G: 1.3028\tD(x_real): 0.8984\tD(x_fake): 0.2831\t\n",
            "[21/20][225/300]\tLoss_D_mask: 0.7416\tLoss_G: 2.0659\tD(x_real): 0.7570\tD(x_fake): 0.1377\t\n",
            "[21/20][230/300]\tLoss_D_mask: 0.7248\tLoss_G: 1.8580\tD(x_real): 0.8739\tD(x_fake): 0.1519\t\n",
            "[21/20][235/300]\tLoss_D_mask: 0.6413\tLoss_G: 1.6774\tD(x_real): 0.9230\tD(x_fake): 0.1991\t\n",
            "[21/20][240/300]\tLoss_D_mask: 1.8097\tLoss_G: 1.4226\tD(x_real): 0.9200\tD(x_fake): 0.1676\t\n",
            "[21/20][245/300]\tLoss_D_mask: 0.6701\tLoss_G: 1.7631\tD(x_real): 0.8800\tD(x_fake): 0.1819\t\n",
            "[21/20][250/300]\tLoss_D_mask: 0.5797\tLoss_G: 1.6612\tD(x_real): 0.9069\tD(x_fake): 0.2046\t\n",
            "[21/20][255/300]\tLoss_D_mask: 0.8572\tLoss_G: 2.0680\tD(x_real): 0.8110\tD(x_fake): 0.1230\t\n",
            "[21/20][260/300]\tLoss_D_mask: 0.7343\tLoss_G: 1.6617\tD(x_real): 0.8367\tD(x_fake): 0.2041\t\n",
            "[21/20][265/300]\tLoss_D_mask: 0.7079\tLoss_G: 1.4112\tD(x_real): 0.8952\tD(x_fake): 0.2657\t\n",
            "[21/20][270/300]\tLoss_D_mask: 0.6892\tLoss_G: 1.5245\tD(x_real): 0.8826\tD(x_fake): 0.2336\t\n",
            "[21/20][275/300]\tLoss_D_mask: 0.6709\tLoss_G: 1.6918\tD(x_real): 0.8261\tD(x_fake): 0.1847\t\n",
            "[21/20][280/300]\tLoss_D_mask: 0.8700\tLoss_G: 1.8708\tD(x_real): 0.7071\tD(x_fake): 0.1551\t\n",
            "[21/20][285/300]\tLoss_D_mask: 2.3735\tLoss_G: 1.9555\tD(x_real): 0.8930\tD(x_fake): 0.1816\t\n",
            "[21/20][290/300]\tLoss_D_mask: 0.5906\tLoss_G: 1.8707\tD(x_real): 0.8046\tD(x_fake): 0.1368\t\n",
            "[21/20][295/300]\tLoss_D_mask: 0.7678\tLoss_G: 1.7175\tD(x_real): 0.9167\tD(x_fake): 0.1841\t\n",
            "[22/20][0/300]\tLoss_D_mask: 0.7777\tLoss_G: 1.7154\tD(x_real): 0.9165\tD(x_fake): 0.1801\t\n",
            "[22/20][5/300]\tLoss_D_mask: 2.3728\tLoss_G: 2.0788\tD(x_real): 0.8981\tD(x_fake): 0.1706\t\n",
            "[22/20][10/300]\tLoss_D_mask: 0.6685\tLoss_G: 1.9236\tD(x_real): 0.8891\tD(x_fake): 0.1538\t\n",
            "[22/20][15/300]\tLoss_D_mask: 0.6282\tLoss_G: 1.9562\tD(x_real): 0.8977\tD(x_fake): 0.1424\t\n",
            "[22/20][20/300]\tLoss_D_mask: 0.5045\tLoss_G: 1.8126\tD(x_real): 0.9090\tD(x_fake): 0.1834\t\n",
            "[22/20][25/300]\tLoss_D_mask: 0.6756\tLoss_G: 1.2084\tD(x_real): 0.9642\tD(x_fake): 0.3071\t\n",
            "[22/20][30/300]\tLoss_D_mask: 0.4936\tLoss_G: 1.7059\tD(x_real): 0.9528\tD(x_fake): 0.1940\t\n",
            "[22/20][35/300]\tLoss_D_mask: 1.7995\tLoss_G: 1.3248\tD(x_real): 0.9382\tD(x_fake): 0.1849\t\n",
            "[22/20][40/300]\tLoss_D_mask: 0.7197\tLoss_G: 1.4178\tD(x_real): 0.9610\tD(x_fake): 0.2683\t\n",
            "[22/20][45/300]\tLoss_D_mask: 0.7065\tLoss_G: 1.3530\tD(x_real): 0.9548\tD(x_fake): 0.2476\t\n",
            "[22/20][50/300]\tLoss_D_mask: 0.5279\tLoss_G: 1.6924\tD(x_real): 0.9584\tD(x_fake): 0.1917\t\n",
            "[22/20][55/300]\tLoss_D_mask: 0.6007\tLoss_G: 1.8747\tD(x_real): 0.9522\tD(x_fake): 0.1569\t\n",
            "[22/20][60/300]\tLoss_D_mask: 0.6019\tLoss_G: 1.8263\tD(x_real): 0.9431\tD(x_fake): 0.1642\t\n",
            "[22/20][65/300]\tLoss_D_mask: 0.6660\tLoss_G: 1.9450\tD(x_real): 0.9464\tD(x_fake): 0.1482\t\n",
            "[22/20][70/300]\tLoss_D_mask: 0.9384\tLoss_G: 1.2685\tD(x_real): 0.9585\tD(x_fake): 0.2720\t\n",
            "[22/20][75/300]\tLoss_D_mask: 0.7759\tLoss_G: 1.6653\tD(x_real): 0.9503\tD(x_fake): 0.2076\t\n",
            "[22/20][80/300]\tLoss_D_mask: 0.7512\tLoss_G: 1.7199\tD(x_real): 0.9397\tD(x_fake): 0.1824\t\n",
            "[22/20][85/300]\tLoss_D_mask: 0.6362\tLoss_G: 1.7412\tD(x_real): 0.9271\tD(x_fake): 0.1791\t\n",
            "[22/20][90/300]\tLoss_D_mask: 0.6408\tLoss_G: 2.0128\tD(x_real): 0.9264\tD(x_fake): 0.1343\t\n",
            "[22/20][95/300]\tLoss_D_mask: 0.6221\tLoss_G: 1.4693\tD(x_real): 0.9345\tD(x_fake): 0.2305\t\n",
            "[22/20][100/300]\tLoss_D_mask: 0.5486\tLoss_G: 1.5725\tD(x_real): 0.9450\tD(x_fake): 0.2220\t\n",
            "[22/20][105/300]\tLoss_D_mask: 0.7305\tLoss_G: 1.5727\tD(x_real): 0.9455\tD(x_fake): 0.2212\t\n",
            "[22/20][110/300]\tLoss_D_mask: 0.6862\tLoss_G: 1.9003\tD(x_real): 0.9427\tD(x_fake): 0.1531\t\n",
            "[22/20][115/300]\tLoss_D_mask: 0.6679\tLoss_G: 1.4182\tD(x_real): 0.9558\tD(x_fake): 0.2594\t\n",
            "[22/20][120/300]\tLoss_D_mask: 2.9629\tLoss_G: 1.8238\tD(x_real): 0.9499\tD(x_fake): 0.2145\t\n",
            "[22/20][125/300]\tLoss_D_mask: 2.2709\tLoss_G: 1.8693\tD(x_real): 0.8439\tD(x_fake): 0.1165\t\n",
            "[22/20][130/300]\tLoss_D_mask: 0.6768\tLoss_G: 1.5126\tD(x_real): 0.8934\tD(x_fake): 0.2268\t\n",
            "[22/20][135/300]\tLoss_D_mask: 0.5884\tLoss_G: 1.5217\tD(x_real): 0.9159\tD(x_fake): 0.2246\t\n",
            "[22/20][140/300]\tLoss_D_mask: 2.4723\tLoss_G: 1.8447\tD(x_real): 0.9036\tD(x_fake): 0.2178\t\n",
            "[22/20][145/300]\tLoss_D_mask: 0.7438\tLoss_G: 1.8740\tD(x_real): 0.8484\tD(x_fake): 0.1478\t\n",
            "[22/20][150/300]\tLoss_D_mask: 0.7917\tLoss_G: 16.2443\tD(x_real): 0.8512\tD(x_fake): 0.5367\t\n",
            "[22/20][155/300]\tLoss_D_mask: 0.6995\tLoss_G: 1.6679\tD(x_real): 0.9441\tD(x_fake): 0.1950\t\n",
            "[22/20][160/300]\tLoss_D_mask: 0.6356\tLoss_G: 1.7656\tD(x_real): 0.9251\tD(x_fake): 0.1792\t\n",
            "[22/20][165/300]\tLoss_D_mask: 1.1637\tLoss_G: 1.1963\tD(x_real): 0.9322\tD(x_fake): 0.4953\t\n",
            "[22/20][170/300]\tLoss_D_mask: 1.6414\tLoss_G: 1.3559\tD(x_real): 0.9318\tD(x_fake): 0.1992\t\n",
            "[22/20][175/300]\tLoss_D_mask: 1.9167\tLoss_G: 1.5555\tD(x_real): 0.9067\tD(x_fake): 0.1900\t\n",
            "[22/20][180/300]\tLoss_D_mask: 2.0863\tLoss_G: 2.0764\tD(x_real): 0.8607\tD(x_fake): 0.1953\t\n",
            "[22/20][185/300]\tLoss_D_mask: 0.7538\tLoss_G: 1.5925\tD(x_real): 0.8199\tD(x_fake): 0.1961\t\n",
            "[22/20][190/300]\tLoss_D_mask: 0.6197\tLoss_G: 1.6699\tD(x_real): 0.8960\tD(x_fake): 0.1878\t\n",
            "[22/20][195/300]\tLoss_D_mask: 0.5325\tLoss_G: 1.6871\tD(x_real): 0.9131\tD(x_fake): 0.1924\t\n",
            "[22/20][200/300]\tLoss_D_mask: 3.9616\tLoss_G: 1.6398\tD(x_real): 0.9238\tD(x_fake): 0.1672\t\n",
            "[22/20][205/300]\tLoss_D_mask: 0.7076\tLoss_G: 1.2710\tD(x_real): 0.9193\tD(x_fake): 0.2867\t\n",
            "[22/20][210/300]\tLoss_D_mask: 0.5591\tLoss_G: 1.4248\tD(x_real): 0.9211\tD(x_fake): 0.2588\t\n",
            "[22/20][215/300]\tLoss_D_mask: 0.7403\tLoss_G: 1.7330\tD(x_real): 0.8575\tD(x_fake): 0.1789\t\n",
            "[22/20][220/300]\tLoss_D_mask: 0.5777\tLoss_G: 1.9778\tD(x_real): 0.8235\tD(x_fake): 0.1323\t\n",
            "[22/20][225/300]\tLoss_D_mask: 1.0196\tLoss_G: 2.4346\tD(x_real): 0.9227\tD(x_fake): 0.1194\t\n",
            "[22/20][230/300]\tLoss_D_mask: 0.6374\tLoss_G: 1.6125\tD(x_real): 0.8972\tD(x_fake): 0.1812\t\n",
            "[22/20][235/300]\tLoss_D_mask: 1.2637\tLoss_G: 0.8529\tD(x_real): 0.9387\tD(x_fake): 0.3310\t\n",
            "[22/20][240/300]\tLoss_D_mask: 0.7773\tLoss_G: 1.3392\tD(x_real): 0.9344\tD(x_fake): 0.3124\t\n",
            "[22/20][245/300]\tLoss_D_mask: 0.8369\tLoss_G: 1.4632\tD(x_real): 0.9289\tD(x_fake): 0.2475\t\n",
            "[22/20][250/300]\tLoss_D_mask: 0.7666\tLoss_G: 1.8865\tD(x_real): 0.8188\tD(x_fake): 0.1506\t\n",
            "[22/20][255/300]\tLoss_D_mask: 0.7058\tLoss_G: 1.5860\tD(x_real): 0.8723\tD(x_fake): 0.1994\t\n",
            "[22/20][260/300]\tLoss_D_mask: 0.6310\tLoss_G: 1.6500\tD(x_real): 0.9084\tD(x_fake): 0.1940\t\n",
            "[22/20][265/300]\tLoss_D_mask: 0.2527\tLoss_G: 1.4141\tD(x_real): 0.9321\tD(x_fake): 0.2252\t\n",
            "[22/20][270/300]\tLoss_D_mask: 0.6234\tLoss_G: 1.2609\tD(x_real): 0.9520\tD(x_fake): 0.3195\t\n",
            "[22/20][275/300]\tLoss_D_mask: 0.5085\tLoss_G: 1.7847\tD(x_real): 0.9090\tD(x_fake): 0.2043\t\n",
            "[22/20][280/300]\tLoss_D_mask: 0.5210\tLoss_G: 1.8445\tD(x_real): 0.8964\tD(x_fake): 0.1531\t\n",
            "[22/20][285/300]\tLoss_D_mask: 0.5115\tLoss_G: 1.7405\tD(x_real): 0.9092\tD(x_fake): 0.1762\t\n",
            "[22/20][290/300]\tLoss_D_mask: 0.6015\tLoss_G: 1.7364\tD(x_real): 0.9237\tD(x_fake): 0.1759\t\n",
            "[22/20][295/300]\tLoss_D_mask: 0.3566\tLoss_G: 1.8432\tD(x_real): 0.9323\tD(x_fake): 0.1547\t\n",
            "[23/20][0/300]\tLoss_D_mask: 0.4981\tLoss_G: 1.7412\tD(x_real): 0.9403\tD(x_fake): 0.1790\t\n",
            "[23/20][5/300]\tLoss_D_mask: 0.5720\tLoss_G: 2.0863\tD(x_real): 0.9047\tD(x_fake): 0.1420\t\n",
            "[23/20][10/300]\tLoss_D_mask: 0.4978\tLoss_G: 1.4695\tD(x_real): 0.9347\tD(x_fake): 0.2363\t\n",
            "[23/20][15/300]\tLoss_D_mask: 0.7074\tLoss_G: 1.3037\tD(x_real): 0.9374\tD(x_fake): 0.2660\t\n",
            "[23/20][20/300]\tLoss_D_mask: 0.6377\tLoss_G: 1.6393\tD(x_real): 0.9426\tD(x_fake): 0.2086\t\n",
            "[23/20][25/300]\tLoss_D_mask: 0.7232\tLoss_G: 1.9114\tD(x_real): 0.9280\tD(x_fake): 0.1556\t\n",
            "[23/20][30/300]\tLoss_D_mask: 0.4411\tLoss_G: 1.8980\tD(x_real): 0.9298\tD(x_fake): 0.1484\t\n",
            "[23/20][35/300]\tLoss_D_mask: 0.4189\tLoss_G: 1.7478\tD(x_real): 0.9500\tD(x_fake): 0.1712\t\n",
            "[23/20][40/300]\tLoss_D_mask: 0.4721\tLoss_G: 1.7781\tD(x_real): 0.9530\tD(x_fake): 0.1683\t\n",
            "[23/20][45/300]\tLoss_D_mask: 0.7465\tLoss_G: 1.8714\tD(x_real): 0.9506\tD(x_fake): 0.1572\t\n",
            "[23/20][50/300]\tLoss_D_mask: 0.5151\tLoss_G: 1.9224\tD(x_real): 0.8944\tD(x_fake): 0.1416\t\n",
            "[23/20][55/300]\tLoss_D_mask: 0.5511\tLoss_G: 1.8946\tD(x_real): 0.9217\tD(x_fake): 0.1443\t\n",
            "[23/20][60/300]\tLoss_D_mask: 0.6336\tLoss_G: 1.6226\tD(x_real): 0.9346\tD(x_fake): 0.2120\t\n",
            "[23/20][65/300]\tLoss_D_mask: 0.6470\tLoss_G: 1.7264\tD(x_real): 0.9360\tD(x_fake): 0.1886\t\n",
            "[23/20][70/300]\tLoss_D_mask: 0.7677\tLoss_G: 1.7506\tD(x_real): 0.9394\tD(x_fake): 0.1778\t\n",
            "[23/20][75/300]\tLoss_D_mask: 0.7269\tLoss_G: 1.9945\tD(x_real): 0.9330\tD(x_fake): 0.1435\t\n",
            "[23/20][80/300]\tLoss_D_mask: 2.6110\tLoss_G: 2.4600\tD(x_real): 0.1526\tD(x_fake): 0.0515\t\n",
            "[23/20][85/300]\tLoss_D_mask: 1.5624\tLoss_G: 1.1255\tD(x_real): 0.8775\tD(x_fake): 0.2304\t\n",
            "[23/20][90/300]\tLoss_D_mask: 0.7806\tLoss_G: 1.1486\tD(x_real): 0.9370\tD(x_fake): 0.3805\t\n",
            "[23/20][95/300]\tLoss_D_mask: 0.7156\tLoss_G: 1.5554\tD(x_real): 0.9218\tD(x_fake): 0.2254\t\n",
            "[23/20][100/300]\tLoss_D_mask: 1.7120\tLoss_G: 1.2819\tD(x_real): 0.9112\tD(x_fake): 0.2119\t\n",
            "[23/20][105/300]\tLoss_D_mask: 0.5625\tLoss_G: 1.4494\tD(x_real): 0.9446\tD(x_fake): 0.2496\t\n",
            "[23/20][110/300]\tLoss_D_mask: 0.5269\tLoss_G: 1.7414\tD(x_real): 0.9148\tD(x_fake): 0.1839\t\n",
            "[23/20][115/300]\tLoss_D_mask: 0.6039\tLoss_G: 1.6345\tD(x_real): 0.9279\tD(x_fake): 0.1978\t\n",
            "[23/20][120/300]\tLoss_D_mask: 0.4221\tLoss_G: 1.6894\tD(x_real): 0.9318\tD(x_fake): 0.1924\t\n",
            "[23/20][125/300]\tLoss_D_mask: 0.6595\tLoss_G: 1.9639\tD(x_real): 0.8546\tD(x_fake): 0.1446\t\n",
            "[23/20][130/300]\tLoss_D_mask: 0.6111\tLoss_G: 1.7930\tD(x_real): 0.9260\tD(x_fake): 0.1669\t\n",
            "[23/20][135/300]\tLoss_D_mask: 0.6768\tLoss_G: 1.7435\tD(x_real): 0.9324\tD(x_fake): 0.1890\t\n",
            "[23/20][140/300]\tLoss_D_mask: 0.8239\tLoss_G: 1.9266\tD(x_real): 0.9386\tD(x_fake): 0.1505\t\n",
            "[23/20][145/300]\tLoss_D_mask: 0.8236\tLoss_G: 1.7901\tD(x_real): 0.9342\tD(x_fake): 0.1714\t\n",
            "[23/20][150/300]\tLoss_D_mask: 0.6052\tLoss_G: 2.4953\tD(x_real): 0.8602\tD(x_fake): 0.0790\t\n",
            "[23/20][155/300]\tLoss_D_mask: 0.9896\tLoss_G: 16.2457\tD(x_real): 0.9334\tD(x_fake): 0.8952\t\n",
            "[23/20][160/300]\tLoss_D_mask: 0.5308\tLoss_G: 1.6406\tD(x_real): 0.9188\tD(x_fake): 0.1969\t\n",
            "[23/20][165/300]\tLoss_D_mask: 0.8537\tLoss_G: 1.9672\tD(x_real): 0.7077\tD(x_fake): 0.1293\t\n",
            "[23/20][170/300]\tLoss_D_mask: 0.7278\tLoss_G: 1.8694\tD(x_real): 0.8820\tD(x_fake): 0.1559\t\n",
            "[23/20][175/300]\tLoss_D_mask: 0.5722\tLoss_G: 1.9573\tD(x_real): 0.8771\tD(x_fake): 0.1345\t\n",
            "[23/20][180/300]\tLoss_D_mask: 0.7499\tLoss_G: 1.7726\tD(x_real): 0.8815\tD(x_fake): 0.1702\t\n",
            "[23/20][185/300]\tLoss_D_mask: 0.6323\tLoss_G: 1.9729\tD(x_real): 0.8856\tD(x_fake): 0.1584\t\n",
            "[23/20][190/300]\tLoss_D_mask: 0.6000\tLoss_G: 1.0475\tD(x_real): 0.8818\tD(x_fake): 0.3025\t\n",
            "[23/20][195/300]\tLoss_D_mask: 0.7196\tLoss_G: 1.6938\tD(x_real): 0.8104\tD(x_fake): 0.2222\t\n",
            "[23/20][200/300]\tLoss_D_mask: 0.5802\tLoss_G: 1.7063\tD(x_real): 0.8700\tD(x_fake): 0.1848\t\n",
            "[23/20][205/300]\tLoss_D_mask: 0.6193\tLoss_G: 1.7229\tD(x_real): 0.8820\tD(x_fake): 0.1801\t\n",
            "[23/20][210/300]\tLoss_D_mask: 0.5865\tLoss_G: 1.1884\tD(x_real): 0.9478\tD(x_fake): 0.3140\t\n",
            "[23/20][215/300]\tLoss_D_mask: 0.8745\tLoss_G: 1.3506\tD(x_real): 0.9465\tD(x_fake): 0.2830\t\n",
            "[23/20][220/300]\tLoss_D_mask: 0.6768\tLoss_G: 1.5360\tD(x_real): 0.9305\tD(x_fake): 0.2235\t\n",
            "[23/20][225/300]\tLoss_D_mask: 0.6680\tLoss_G: 1.9716\tD(x_real): 0.8263\tD(x_fake): 0.1484\t\n",
            "[23/20][230/300]\tLoss_D_mask: 0.5764\tLoss_G: 1.5982\tD(x_real): 0.9111\tD(x_fake): 0.1979\t\n",
            "[23/20][235/300]\tLoss_D_mask: 0.7068\tLoss_G: 1.9125\tD(x_real): 0.9102\tD(x_fake): 0.1466\t\n",
            "[23/20][240/300]\tLoss_D_mask: 0.7153\tLoss_G: 1.6849\tD(x_real): 0.9423\tD(x_fake): 0.1971\t\n",
            "[23/20][245/300]\tLoss_D_mask: 0.6857\tLoss_G: 1.4520\tD(x_real): 0.9577\tD(x_fake): 0.2565\t\n",
            "[23/20][250/300]\tLoss_D_mask: 0.6006\tLoss_G: 1.7432\tD(x_real): 0.9370\tD(x_fake): 0.1857\t\n",
            "[23/20][255/300]\tLoss_D_mask: 0.9005\tLoss_G: 1.4318\tD(x_real): 0.8916\tD(x_fake): 0.2437\t\n",
            "[23/20][260/300]\tLoss_D_mask: 0.6682\tLoss_G: 1.7073\tD(x_real): 0.8964\tD(x_fake): 0.1870\t\n",
            "[23/20][265/300]\tLoss_D_mask: 2.1717\tLoss_G: 43.7577\tD(x_real): 0.8675\tD(x_fake): 0.2332\t\n",
            "[23/20][270/300]\tLoss_D_mask: 0.7756\tLoss_G: 1.5813\tD(x_real): 0.7538\tD(x_fake): 0.1899\t\n",
            "[23/20][280/300]\tLoss_D_mask: 0.6797\tLoss_G: 1.7160\tD(x_real): 0.8111\tD(x_fake): 0.1980\t\n",
            "[23/20][285/300]\tLoss_D_mask: 0.5822\tLoss_G: 1.5668\tD(x_real): 0.8576\tD(x_fake): 0.2062\t\n",
            "[23/20][290/300]\tLoss_D_mask: 0.6660\tLoss_G: 1.5133\tD(x_real): 0.9018\tD(x_fake): 0.2269\t\n",
            "[23/20][295/300]\tLoss_D_mask: 0.8294\tLoss_G: 1.6213\tD(x_real): 0.9351\tD(x_fake): 0.2073\t\n",
            "[24/20][0/300]\tLoss_D_mask: 0.7797\tLoss_G: 1.9929\tD(x_real): 0.8574\tD(x_fake): 0.1408\t\n",
            "[24/20][5/300]\tLoss_D_mask: 0.4311\tLoss_G: 1.3687\tD(x_real): 0.9159\tD(x_fake): 0.2561\t\n",
            "[24/20][10/300]\tLoss_D_mask: 0.7586\tLoss_G: 1.6618\tD(x_real): 0.9173\tD(x_fake): 0.1937\t\n",
            "[24/20][15/300]\tLoss_D_mask: 2.9103\tLoss_G: 1.7630\tD(x_real): 0.9417\tD(x_fake): 0.2420\t\n",
            "[24/20][20/300]\tLoss_D_mask: 2.4241\tLoss_G: 1.7869\tD(x_real): 0.9043\tD(x_fake): 0.2041\t\n",
            "[24/20][25/300]\tLoss_D_mask: 0.6120\tLoss_G: 1.4746\tD(x_real): 0.8612\tD(x_fake): 0.2088\t\n",
            "[24/20][30/300]\tLoss_D_mask: 0.6383\tLoss_G: 1.4235\tD(x_real): 0.9209\tD(x_fake): 0.2547\t\n",
            "[24/20][35/300]\tLoss_D_mask: 0.4118\tLoss_G: 1.7192\tD(x_real): 0.9238\tD(x_fake): 0.1803\t\n",
            "[24/20][40/300]\tLoss_D_mask: 0.4311\tLoss_G: 1.6893\tD(x_real): 0.9327\tD(x_fake): 0.1820\t\n",
            "[24/20][45/300]\tLoss_D_mask: 0.5998\tLoss_G: 1.8717\tD(x_real): 0.9332\tD(x_fake): 0.1591\t\n",
            "[24/20][50/300]\tLoss_D_mask: 3.0804\tLoss_G: 1.9730\tD(x_real): 0.9560\tD(x_fake): 0.1848\t\n",
            "[24/20][55/300]\tLoss_D_mask: 0.6132\tLoss_G: 1.5709\tD(x_real): 0.9133\tD(x_fake): 0.2038\t\n",
            "[24/20][60/300]\tLoss_D_mask: 0.7141\tLoss_G: 1.8698\tD(x_real): 0.8896\tD(x_fake): 0.1786\t\n",
            "[24/20][65/300]\tLoss_D_mask: 2.3487\tLoss_G: 2.1035\tD(x_real): 0.8901\tD(x_fake): 0.1497\t\n",
            "[24/20][70/300]\tLoss_D_mask: 0.7463\tLoss_G: 1.9601\tD(x_real): 0.8277\tD(x_fake): 0.1347\t\n",
            "[24/20][75/300]\tLoss_D_mask: 0.5988\tLoss_G: 1.8264\tD(x_real): 0.9120\tD(x_fake): 0.1583\t\n",
            "[24/20][80/300]\tLoss_D_mask: 0.8163\tLoss_G: 1.6305\tD(x_real): 0.9313\tD(x_fake): 0.2036\t\n",
            "[24/20][85/300]\tLoss_D_mask: 2.1256\tLoss_G: 1.4692\tD(x_real): 0.9409\tD(x_fake): 0.1736\t\n",
            "[24/20][90/300]\tLoss_D_mask: 0.7505\tLoss_G: 1.4042\tD(x_real): 0.9407\tD(x_fake): 0.2873\t\n",
            "[24/20][95/300]\tLoss_D_mask: 0.6232\tLoss_G: 1.3339\tD(x_real): 0.9127\tD(x_fake): 0.2839\t\n",
            "[24/20][100/300]\tLoss_D_mask: 0.5217\tLoss_G: 1.6965\tD(x_real): 0.8599\tD(x_fake): 0.1707\t\n",
            "[24/20][105/300]\tLoss_D_mask: 0.7733\tLoss_G: 1.8528\tD(x_real): 0.9321\tD(x_fake): 0.1607\t\n",
            "[24/20][110/300]\tLoss_D_mask: 0.6973\tLoss_G: 1.8255\tD(x_real): 0.9153\tD(x_fake): 0.1611\t\n",
            "[24/20][115/300]\tLoss_D_mask: 0.7122\tLoss_G: 1.6220\tD(x_real): 0.9492\tD(x_fake): 0.2149\t\n",
            "[24/20][120/300]\tLoss_D_mask: 0.5886\tLoss_G: 1.7816\tD(x_real): 0.9310\tD(x_fake): 0.1728\t\n",
            "[24/20][125/300]\tLoss_D_mask: 0.5178\tLoss_G: 1.9107\tD(x_real): 0.9221\tD(x_fake): 0.1456\t\n",
            "[24/20][130/300]\tLoss_D_mask: 2.0928\tLoss_G: 2.1004\tD(x_real): 0.8460\tD(x_fake): 0.1483\t\n",
            "[24/20][135/300]\tLoss_D_mask: 0.6649\tLoss_G: 1.6625\tD(x_real): 0.8508\tD(x_fake): 0.1793\t\n",
            "[24/20][140/300]\tLoss_D_mask: 1.4877\tLoss_G: 1.7983\tD(x_real): 0.9654\tD(x_fake): 0.1602\t\n",
            "[24/20][145/300]\tLoss_D_mask: 0.7800\tLoss_G: 1.7323\tD(x_real): 0.9284\tD(x_fake): 0.2044\t\n",
            "[24/20][150/300]\tLoss_D_mask: 0.6931\tLoss_G: 2.0599\tD(x_real): 0.8441\tD(x_fake): 0.1387\t\n",
            "[24/20][155/300]\tLoss_D_mask: 0.7470\tLoss_G: 1.7433\tD(x_real): 0.8922\tD(x_fake): 0.1699\t\n",
            "[24/20][160/300]\tLoss_D_mask: 0.6518\tLoss_G: 1.8480\tD(x_real): 0.9435\tD(x_fake): 0.1609\t\n",
            "[24/20][165/300]\tLoss_D_mask: 0.7168\tLoss_G: 1.6417\tD(x_real): 0.9417\tD(x_fake): 0.1942\t\n",
            "[24/20][170/300]\tLoss_D_mask: 0.4186\tLoss_G: 1.4328\tD(x_real): 0.9500\tD(x_fake): 0.2229\t\n",
            "[24/20][175/300]\tLoss_D_mask: 0.6713\tLoss_G: 1.5066\tD(x_real): 0.9485\tD(x_fake): 0.2585\t\n",
            "[24/20][180/300]\tLoss_D_mask: 0.7488\tLoss_G: 1.9448\tD(x_real): 0.7839\tD(x_fake): 0.1371\t\n",
            "[24/20][185/300]\tLoss_D_mask: 1.8549\tLoss_G: 1.3650\tD(x_real): 0.8783\tD(x_fake): 0.1859\t\n",
            "[24/20][190/300]\tLoss_D_mask: 0.8897\tLoss_G: 0.8177\tD(x_real): 0.9631\tD(x_fake): 0.4932\t\n",
            "[24/20][195/300]\tLoss_D_mask: 0.6020\tLoss_G: 1.4681\tD(x_real): 0.9121\tD(x_fake): 0.2470\t\n",
            "[24/20][200/300]\tLoss_D_mask: 0.7511\tLoss_G: 1.6610\tD(x_real): 0.9094\tD(x_fake): 0.1954\t\n",
            "[24/20][205/300]\tLoss_D_mask: 0.4447\tLoss_G: 1.6582\tD(x_real): 0.9190\tD(x_fake): 0.1882\t\n",
            "[24/20][210/300]\tLoss_D_mask: 0.6745\tLoss_G: 2.0222\tD(x_real): 0.9234\tD(x_fake): 0.1345\t\n",
            "[24/20][215/300]\tLoss_D_mask: 0.7685\tLoss_G: 2.1077\tD(x_real): 0.8557\tD(x_fake): 0.1367\t\n",
            "[24/20][220/300]\tLoss_D_mask: 0.6819\tLoss_G: 1.5000\tD(x_real): 0.9142\tD(x_fake): 0.2316\t\n",
            "[24/20][225/300]\tLoss_D_mask: 0.6959\tLoss_G: 1.6987\tD(x_real): 0.9216\tD(x_fake): 0.1909\t\n",
            "[24/20][235/300]\tLoss_D_mask: 1.2745\tLoss_G: 1.3461\tD(x_real): 0.9656\tD(x_fake): 0.3268\t\n",
            "[24/20][240/300]\tLoss_D_mask: 0.5955\tLoss_G: 1.5105\tD(x_real): 0.9164\tD(x_fake): 0.2299\t\n",
            "[24/20][245/300]\tLoss_D_mask: 0.6209\tLoss_G: 1.8014\tD(x_real): 0.9357\tD(x_fake): 0.1710\t\n",
            "[24/20][250/300]\tLoss_D_mask: 0.5076\tLoss_G: 1.7457\tD(x_real): 0.9345\tD(x_fake): 0.1744\t\n",
            "[24/20][255/300]\tLoss_D_mask: 0.7432\tLoss_G: 1.3999\tD(x_real): 0.9631\tD(x_fake): 0.2648\t\n",
            "[24/20][260/300]\tLoss_D_mask: 0.5227\tLoss_G: 1.7719\tD(x_real): 0.9146\tD(x_fake): 0.1775\t\n",
            "[24/20][265/300]\tLoss_D_mask: 0.6497\tLoss_G: 1.8751\tD(x_real): 0.9280\tD(x_fake): 0.1542\t\n",
            "[24/20][270/300]\tLoss_D_mask: 0.5738\tLoss_G: 1.6920\tD(x_real): 0.9332\tD(x_fake): 0.1827\t\n",
            "[24/20][275/300]\tLoss_D_mask: 0.7241\tLoss_G: 1.7120\tD(x_real): 0.9313\tD(x_fake): 0.1877\t\n",
            "[24/20][280/300]\tLoss_D_mask: 0.6814\tLoss_G: 1.7830\tD(x_real): 0.9272\tD(x_fake): 0.1684\t\n",
            "[24/20][285/300]\tLoss_D_mask: 0.6022\tLoss_G: 1.6919\tD(x_real): 0.9422\tD(x_fake): 0.1936\t\n",
            "[24/20][290/300]\tLoss_D_mask: 0.6015\tLoss_G: 1.9948\tD(x_real): 0.9288\tD(x_fake): 0.1320\t\n",
            "[24/20][295/300]\tLoss_D_mask: 0.6438\tLoss_G: 2.3122\tD(x_real): 0.8594\tD(x_fake): 0.0996\t\n",
            "models saved correctly\n",
            "[25/20][0/300]\tLoss_D_mask: 0.8592\tLoss_G: 2.0469\tD(x_real): 0.8985\tD(x_fake): 0.1281\t\n",
            "[25/20][5/300]\tLoss_D_mask: 0.6241\tLoss_G: 1.7156\tD(x_real): 0.9333\tD(x_fake): 0.1804\t\n",
            "[25/20][10/300]\tLoss_D_mask: 0.7504\tLoss_G: 2.1881\tD(x_real): 0.8957\tD(x_fake): 0.1297\t\n",
            "[25/20][15/300]\tLoss_D_mask: 0.5776\tLoss_G: 1.8239\tD(x_real): 0.8994\tD(x_fake): 0.1599\t\n",
            "[25/20][20/300]\tLoss_D_mask: 0.5754\tLoss_G: 1.9338\tD(x_real): 0.9180\tD(x_fake): 0.1401\t\n",
            "[25/20][25/300]\tLoss_D_mask: 2.7135\tLoss_G: 1.9311\tD(x_real): 0.9313\tD(x_fake): 0.1854\t\n",
            "[25/20][30/300]\tLoss_D_mask: 0.7729\tLoss_G: 1.8338\tD(x_real): 0.9070\tD(x_fake): 0.1518\t\n",
            "[25/20][35/300]\tLoss_D_mask: 0.4338\tLoss_G: 1.7569\tD(x_real): 0.9227\tD(x_fake): 0.1707\t\n",
            "[25/20][40/300]\tLoss_D_mask: 0.2647\tLoss_G: 20.9430\tD(x_real): 0.9237\tD(x_fake): 0.1803\t\n",
            "[25/20][45/300]\tLoss_D_mask: 0.6533\tLoss_G: 1.8703\tD(x_real): 0.9305\tD(x_fake): 0.1571\t\n",
            "[25/20][50/300]\tLoss_D_mask: 0.6123\tLoss_G: 2.0247\tD(x_real): 0.9314\tD(x_fake): 0.1325\t\n",
            "[25/20][55/300]\tLoss_D_mask: 0.6711\tLoss_G: 1.7381\tD(x_real): 0.9512\tD(x_fake): 0.1852\t\n",
            "[25/20][60/300]\tLoss_D_mask: 0.6599\tLoss_G: 2.1378\tD(x_real): 0.8281\tD(x_fake): 0.1281\t\n",
            "[25/20][65/300]\tLoss_D_mask: 0.4878\tLoss_G: 1.9069\tD(x_real): 0.9033\tD(x_fake): 0.1395\t\n",
            "[25/20][70/300]\tLoss_D_mask: 0.5275\tLoss_G: 1.9163\tD(x_real): 0.9253\tD(x_fake): 0.1505\t\n",
            "[25/20][75/300]\tLoss_D_mask: 2.0224\tLoss_G: 1.5659\tD(x_real): 0.9201\tD(x_fake): 0.1522\t\n",
            "[25/20][80/300]\tLoss_D_mask: 0.7780\tLoss_G: 1.7939\tD(x_real): 0.9361\tD(x_fake): 0.1716\t\n",
            "[25/20][85/300]\tLoss_D_mask: 0.6987\tLoss_G: 1.2925\tD(x_real): 0.9562\tD(x_fake): 0.2943\t\n",
            "[25/20][90/300]\tLoss_D_mask: 0.7440\tLoss_G: 1.5767\tD(x_real): 0.9342\tD(x_fake): 0.2188\t\n",
            "[25/20][95/300]\tLoss_D_mask: 0.7286\tLoss_G: 1.7900\tD(x_real): 0.9091\tD(x_fake): 0.1741\t\n",
            "[25/20][100/300]\tLoss_D_mask: 0.6855\tLoss_G: 1.8664\tD(x_real): 0.9158\tD(x_fake): 0.1509\t\n",
            "[25/20][105/300]\tLoss_D_mask: 0.7360\tLoss_G: 2.0906\tD(x_real): 0.8660\tD(x_fake): 0.1262\t\n",
            "[25/20][110/300]\tLoss_D_mask: 0.8077\tLoss_G: 1.9890\tD(x_real): 0.7651\tD(x_fake): 0.1278\t\n",
            "[25/20][115/300]\tLoss_D_mask: 2.3127\tLoss_G: 1.7630\tD(x_real): 0.7831\tD(x_fake): 0.1296\t\n",
            "[25/20][120/300]\tLoss_D_mask: 0.7278\tLoss_G: 1.4293\tD(x_real): 0.8857\tD(x_fake): 0.2492\t\n",
            "[25/20][125/300]\tLoss_D_mask: 0.7808\tLoss_G: 1.7603\tD(x_real): 0.9046\tD(x_fake): 0.1789\t\n",
            "[25/20][130/300]\tLoss_D_mask: 0.4814\tLoss_G: 1.6430\tD(x_real): 0.9039\tD(x_fake): 0.1948\t\n",
            "[25/20][135/300]\tLoss_D_mask: 0.6889\tLoss_G: 1.7850\tD(x_real): 0.9060\tD(x_fake): 0.1675\t\n",
            "[25/20][140/300]\tLoss_D_mask: 0.6745\tLoss_G: 37.3739\tD(x_real): 0.8466\tD(x_fake): 0.1400\t\n",
            "[25/20][145/300]\tLoss_D_mask: 0.6818\tLoss_G: 1.6946\tD(x_real): 0.9269\tD(x_fake): 0.1893\t\n",
            "[25/20][150/300]\tLoss_D_mask: 0.6070\tLoss_G: 1.6564\tD(x_real): 0.9034\tD(x_fake): 0.1893\t\n",
            "[25/20][155/300]\tLoss_D_mask: 0.5381\tLoss_G: 1.8967\tD(x_real): 0.9122\tD(x_fake): 0.1466\t\n",
            "[25/20][160/300]\tLoss_D_mask: 0.7291\tLoss_G: 1.3675\tD(x_real): 0.9408\tD(x_fake): 0.2438\t\n",
            "[25/20][165/300]\tLoss_D_mask: 0.7338\tLoss_G: 1.6271\tD(x_real): 0.9365\tD(x_fake): 0.2074\t\n",
            "[25/20][170/300]\tLoss_D_mask: 0.5611\tLoss_G: 1.7887\tD(x_real): 0.9326\tD(x_fake): 0.1729\t\n",
            "[25/20][175/300]\tLoss_D_mask: 0.5441\tLoss_G: 1.7981\tD(x_real): 0.9391\tD(x_fake): 0.1669\t\n",
            "[25/20][180/300]\tLoss_D_mask: 0.6405\tLoss_G: 2.1726\tD(x_real): 0.8421\tD(x_fake): 0.1204\t\n",
            "[25/20][185/300]\tLoss_D_mask: 0.6832\tLoss_G: 1.8374\tD(x_real): 0.9004\tD(x_fake): 0.1592\t\n",
            "[25/20][190/300]\tLoss_D_mask: 0.6321\tLoss_G: 1.3692\tD(x_real): 0.9421\tD(x_fake): 0.2250\t\n",
            "[25/20][195/300]\tLoss_D_mask: 0.5643\tLoss_G: 1.5724\tD(x_real): 0.9458\tD(x_fake): 0.2179\t\n",
            "[25/20][200/300]\tLoss_D_mask: 0.5259\tLoss_G: 1.8116\tD(x_real): 0.9357\tD(x_fake): 0.1685\t\n",
            "[25/20][205/300]\tLoss_D_mask: 0.5473\tLoss_G: 1.3819\tD(x_real): 0.9603\tD(x_fake): 0.2665\t\n",
            "[25/20][210/300]\tLoss_D_mask: 0.5880\tLoss_G: 1.6964\tD(x_real): 0.9496\tD(x_fake): 0.1886\t\n",
            "[25/20][215/300]\tLoss_D_mask: 2.9972\tLoss_G: 2.0536\tD(x_real): 0.9442\tD(x_fake): 0.1743\t\n",
            "[25/20][220/300]\tLoss_D_mask: 0.9144\tLoss_G: 2.3489\tD(x_real): 0.6799\tD(x_fake): 0.0964\t\n",
            "[25/20][225/300]\tLoss_D_mask: 0.5895\tLoss_G: 1.8689\tD(x_real): 0.8491\tD(x_fake): 0.1509\t\n",
            "[25/20][230/300]\tLoss_D_mask: 0.6354\tLoss_G: 1.6538\tD(x_real): 0.9092\tD(x_fake): 0.1910\t\n",
            "[25/20][235/300]\tLoss_D_mask: 0.9522\tLoss_G: 1.9310\tD(x_real): 0.9225\tD(x_fake): 0.1526\t\n",
            "[25/20][240/300]\tLoss_D_mask: 0.5130\tLoss_G: 1.8692\tD(x_real): 0.9162\tD(x_fake): 0.1480\t\n",
            "[25/20][245/300]\tLoss_D_mask: 0.5901\tLoss_G: 1.8811\tD(x_real): 0.9296\tD(x_fake): 0.1495\t\n",
            "[25/20][250/300]\tLoss_D_mask: 0.5147\tLoss_G: 1.7678\tD(x_real): 0.9372\tD(x_fake): 0.1659\t\n",
            "[25/20][255/300]\tLoss_D_mask: 0.8015\tLoss_G: 1.4732\tD(x_real): 0.9619\tD(x_fake): 0.2483\t\n",
            "[25/20][260/300]\tLoss_D_mask: 0.5744\tLoss_G: 1.6885\tD(x_real): 0.9555\tD(x_fake): 0.1817\t\n",
            "[25/20][265/300]\tLoss_D_mask: 0.7294\tLoss_G: 1.6804\tD(x_real): 0.9472\tD(x_fake): 0.1965\t\n",
            "[25/20][270/300]\tLoss_D_mask: 0.6924\tLoss_G: 1.7828\tD(x_real): 0.9572\tD(x_fake): 0.1735\t\n",
            "[25/20][275/300]\tLoss_D_mask: 0.5881\tLoss_G: 1.8260\tD(x_real): 0.9485\tD(x_fake): 0.1639\t\n",
            "[25/20][280/300]\tLoss_D_mask: 0.6179\tLoss_G: 1.5026\tD(x_real): 0.9757\tD(x_fake): 0.3856\t\n",
            "[25/20][285/300]\tLoss_D_mask: 0.5431\tLoss_G: 1.5818\tD(x_real): 0.9461\tD(x_fake): 0.2169\t\n",
            "[25/20][290/300]\tLoss_D_mask: 0.6804\tLoss_G: 1.3530\tD(x_real): 0.9437\tD(x_fake): 0.2612\t\n",
            "[25/20][295/300]\tLoss_D_mask: 3.1475\tLoss_G: 1.6963\tD(x_real): 0.9555\tD(x_fake): 0.2370\t\n",
            "[26/20][0/300]\tLoss_D_mask: 1.5391\tLoss_G: 1.1924\tD(x_real): 0.9320\tD(x_fake): 0.2289\t\n",
            "[26/20][5/300]\tLoss_D_mask: 0.5418\tLoss_G: 1.5574\tD(x_real): 0.8793\tD(x_fake): 0.2152\t\n",
            "[26/20][10/300]\tLoss_D_mask: 0.6460\tLoss_G: 1.7073\tD(x_real): 0.9004\tD(x_fake): 0.1867\t\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}